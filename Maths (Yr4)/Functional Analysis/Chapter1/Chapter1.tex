\documentclass[a4paper, openany]{memoir}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage[english]{babel}

\usepackage{fancyhdr}
\usepackage{float}
\usepackage{bm}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage[bookmarksopen=true,bookmarksopenlevel=2]{hyperref}
\usepackage{tikz}
\usepackage{indentfirst}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE]{\leftmark}
\fancyhead[RO]{\rightmark}
\fancyhead[RE, LO]{Functional Analysis}
\fancyfoot[LE, RO]{\thepage}
\fancyfoot[RE, LO]{Pete Gautam}

\renewcommand{\headrulewidth}{1.5pt}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{example}[definition]{Example}

\chapterstyle{thatcher}

\begin{document}
    \chapter{Normed Vector Spaces}

    \section{Review of Vector Spaces}
    In this section, we will review properties of vector spaces with relation to vector spaces.

    \begin{definition}
        A \emph{vector space $(V, +, \cdot)$ (over a field $\mathbb{K}$)} is a set $V$ and functions $(+) \colon V \times V \to V$ and $(\cdot) \colon \mathbb{K} \times V \to V$ such that:
        \begin{itemize}
            \item $(V, +)$ is an abelian group;
            \item $\cdot$ is associative over $+$, i.e. for $a, b \in \mathbb{K}$ and $v \in V$, $a \cdot (b \cdot v) = (ab) \cdot v$;
            \item $\cdot$ left- and right-distributes over $+$, i.e. for $a \in \mathbb{K}$ and $v, w \in V$, $a \cdot (v + w) = a \cdot v + a \cdot w$.
        \end{itemize}
    \end{definition}
    \noindent In this course, we set $\mathbb{K} = \mathbb{R}$ or $\mathbb{K} = \mathbb{C}$. We are familiar with many vector spaces, e.g. $\mathbb{R}^n$ over $\mathbb{R}$ and $\mathbb{C}^n$ over $\mathbb{C}$ (and $\mathbb{R}$). 

    We now review the concept of dimensionality.
    \begin{definition}
        Let $V$ be a vector space and let $S \subseteq V$.
        \begin{itemize}
            \item We say that $S$ \emph{spans} $V$ if for all $v \in V$, there exists a collection of scalars $(c_{v_i})_{v_i \in S}$ such that 
            \[v = \sum_{v_i \in S} c_{v_i} \cdot v_i.\]
            \item We say that $S$ is \emph{linearly independent} if for all linear combinations
            \[\sum_{v_i \in S} c_{v_i} \cdot v_i = 0,\]
            we have $c_{v_i} = 0$ for all $v_i \in S$.
            \item We say that $S$ is a \emph{basis} for $V$ if $S$ spans $V$ and is linearly independent.
        \end{itemize}
    \end{definition}
    \noindent For $\mathbb{R}^n$, a basis is given by $\{e_1, e_2, \dots, e_n\}$,
    with 
    \[e_i(j) = \begin{cases}
        1 & i = j \\
        0 & \textrm{otherwise}
    \end{cases}\]
    for $1 \leq i \leq n$. This basis is not unique, e.g. another basis for $\mathbb{R}^n$ is $\{f_1, f_2, \dots, f_n\}$, with
    \[f_i = \sum_{j=1}^i e_j.\]
    Although the basis is not unique, if it is finite, then any other basis will also be finite and have the same number of elements. This value is defined the \emph{dimension} of the vector space. Vector spaces that have a basis with finitely many elements are called \emph{finite-dimensional}. We know that for a field $\mathbb{K}$, if $V$ is an $n$-dimensional vector space over $\mathbb{K}$, then $V$ is isomorphic to $\mathbb{K}^n$. So, these are all the finite-dimensional vector spaces.

    We can represent the vector space $\mathbb{R}^n$ as a function. In particular, for some set $X = \{x_1, x_2, \dots, x_n\}$, let $\operatorname{Fun}(X, \mathbb{R})$ be the set of functions $f \colon X \to \mathbb{R}$. We claim that $\operatorname{Fun}(X, \mathbb{R})$ is isomorphic to $\mathbb{R}^n$, with the isomorphism map $\varphi \colon \operatorname{Fun}(X, \mathbb{R}) \to \mathbb{R}^n$
    \[\varphi(f) = \begin{bmatrix}
        f(x_1) \\
        f(x_2) \\
        \vdots \\
        f(x_n)
    \end{bmatrix}.\]
    Note however that this format is not limited to finite sets; the space of functions $\operatorname{Fun}(X, \mathbb{R})$ is a vector space even when $X$ is infinite. In particular, we consider the case where $X$ is countable, i.e. $X = \mathbb{Z}_{\geq 1}$. The space $\operatorname{Fun}(X, \mathbb{R})$ in this case is the space of all functions $f \colon \mathbb{Z}_{\geq 1} \to \mathbb{R}$, i.e. sequences in $\mathbb{R}$. We denote this as $\operatorname{Seq}(\mathbb{R})$ as well. The sequences form a vector space with respect to pointwise addition and scalar multiplication. This sequence is infinite-dimensional, i.e. it does not have a finite basis. This is because it has the basis $\{e^{(1)}, e^{(2)}, \dots\}$, with the sequence $(e_n^{(k)})_{n=1}^\infty$ given by
    \[e_n^{(k)} = \begin{cases}
        1 & n = k \\
        0 & \textrm{otherwise}.
    \end{cases}\]
    We know that every basis of a finite-dimensional space is finite, so $\operatorname{Seq}(\mathbb{R})$ is infinite-dimensional.
    %  This space has many interesting subspaces, including:
    % \begin{itemize}
    %     \item the space of bounded sequences $\ell^\infty$;
    %     \item the space of convergent sequences $c$;
    %     \item the space of sequences that converge to 0 $c_0$;
    %     \item the space of sequences $(x_n)_{n=1}^\infty$ such that the series
    %     \[\sum_{n=1}^\infty |x_n|^p\]
    %     converges, denoted $\ell^p$, for some $p \in [1, \infty)$;
    %     \item the space of sequences that are eventually zero $c_{00}$.
    % \end{itemize}
    
    Also, the space of continuous functions from the compact subset $[0, 1]$ to $\mathbb{R}$, denoted by $C[0, 1]$, is a vector space- it forms a vector space over pointwise addition and scalar multiplication, i.e. for $c \in \mathbb{R}$ and $f \in C[0, 1]$, we define the function $c \cdot f \in C[0, 1]$ by $(c \cdot f)(x) = c \cdot f(x)$    for $x \in [0, 1]$. This is also an infinite-dimensional space- it has a subspace consisting of polynomial functions, whose basis is given by
    \[\{f_n \mid n \in \mathbb{Z}_{\geq 1}\},\]
    where $f_n(x) = x^n$ for all $x \in [0, 1]$. Hence, it has an infinite-dimensional subspace, meaning that the entire space must also be infinite-dimensional. We will later see that the space of polynomials is a dense subspace of $C[0, 1]$, i.e. a continuous function can be approximated by a polynomial function arbitrarily well.
    \newpage

    \section{Metrics, Norms and Inner Products}
    In this section, we will expand the algebraic vector space properties and connect them with analytic ones. In particular, we will look at metrics in vector spaces, and then a stronger concept of norms, and finally inner product spaces.

    \begin{definition}[Metric spaces]
        Let $V$ be a set and let $d \colon V \times V \to \mathbb{R}_{\geq 0}$ be a function. We say that $(V, d)$ is a \emph{metric space} if:
        \begin{itemize}
            \item for all $u, v \in V$, $d(u, v) = 0$ if and only if $u = v$;
            \item for all $u, v \in V$, $d(u, v) = d(v, u)$;
            \item for all $u, v, w \in V$, $d(u, w) \leq d(u, v) + d(v, w)$.
        \end{itemize}
        If $(V, d)$ is a metric space, we call $d$ a \emph{metric}.
    \end{definition}
    \noindent The function $d$ represents a distance function; it allows us to measure distance between two values in $V$.

    There are many examples of metric spaces. In $\mathbb{R}^n$, the following are 3 different norms:
    \begin{align*}
        d_1(x, y) &= \sum_{i=1}^n |x_i - y_i| \\
        d_2(x, y) &= \left(\sum_{i=1}^n (x_i - y_i)^2\right)^{1/2} \\
        d_\infty(x, y) &= \max_{i=1}^n |x_i - y_i|.
    \end{align*}
    In general, we can define the $d_p$-metric for $p \in [1, \infty)$ as follows:
    \[d_p(x, y) = \left(\sum_{i=1}^n |x_i - y_i|^p \right)^{1/p}.\]
    We can define a lot more metrics on $\mathbb{R}^n$, such as the discrete metric:
    \[d(x, y) = \begin{cases}
        0 & x = y \\
        1 & \textrm{otherwise}.
    \end{cases}\]
    We would like to consider a structure that behaves better with the structure of a vector space, like the $d_p$-metrics. This gives rise to a norm.
    \begin{definition}[Normed Vector Space]
        Let $V$ be a vector space and let $\lVert \cdot \rVert \colon V \times V \to \mathbb{R}_{\geq 0}$ be a function. We say that $(V, \lVert \cdot \rVert)$ is a \emph{normed vector space} if:
        \begin{itemize}
            \item for all $v \in V$, $\lVert v \rVert = 0$ if and only if $v = 0$;
            \item for all $v \in V$ and $\lambda \in \mathbb{C}$, $\lVert \lambda v \rVert = |\lambda| \lVert v \rVert$;
            \item for all $u, v \in V$, $\lVert u + v \rVert \leq \lVert u \rVert + \lVert v \rVert$.
        \end{itemize}
        If $(V, \lVert \cdot \rVert)$ is a normed vector space, we call $\lVert \cdot \rVert$ a \emph{norm}.
    \end{definition}
    \noindent The norm function allows us to measure the magnitude of a vector.

    In $\mathbb{R}^n$, we have many norms, such as $\lVert \cdot \rVert_1$, $\lVert \cdot \rVert_2$ and $\lVert \cdot \rVert_\infty$ given as follows:
    \begin{align*}
        \lVert x \rVert_1 &= \sum_{i=1}^n |x_i| \\
        \lVert x \rVert_2 &= \left(\sum_{i=1}^n |x_i|^2 \right)^{1/2} \\
        \lVert x \rVert_\infty &= \max_{i=1}^n |x_i|.
a    \end{align*}
    These norms are quite closely related to the $d_1$, $d_2$ and $d_\infty$-metrics respectively. It turns out that every norm induces a metric, given by
    \[d(x, y) = \lVert x - y \rVert.\]
    However, it is not the case that every metric is induced by a metric, e.g. the discrete metric is not induced by a norm.

    We will now look at some norms in infinite-dimensional vector spaces. In particular, if we look at the space of sequences $\operatorname{Seq}(\mathbb{R})$, we can define the norms in a similar manner as above, i.e.
    \begin{align*}
        \lVert (x_n) \rVert_1 &= \sum_{n=1}^\infty |x_n| \\
        \lVert (x_n) \rVert_2 &= \left(\sum_{n=1}^\infty x_n^2\right)^{1/2} \\
        \lVert (x_n) \rVert_\infty &= \sup_{n=1}^\infty |x_n|.
    \end{align*}
    These norms are not defined for all sequences, e.g. the sequence of positive integers has infinite norm with respect to all 3 norms. So, we restrict the norm to those sequences that have a finite value. In particular, we define the following sequence spaces:
    \begin{itemize}
        \item the sequence space $\ell^1$, composed of sequences that converge absolutely;
        \item the sequence space $\ell^2$, composed of sequences $(x_n)_{n=1}^\infty$ such that the series
        \[\sum_{n=1}^\infty x_n^2\]
        converges;
        \item the sequence space $\ell^p$, composed of sequences $(x_n)_{n=1}^\infty$ such that the series
        \[\sum_{n=1}^\infty |x_n|^p\]
        converges (for $p \in [1, \infty)$);
        \item the sequence space $\ell^\infty$, composed of bounded sequences.
    \end{itemize}
    % Note the following relations between the sequence spaces:
    % \begin{itemize}
    %     \item the space $\ell^\infty$ contains all convergent sequences, i.e. a convergent sequence is bounded;
    %     \item the space $\ell^\infty$ contains $\ell^p$ for all $p \in [1, \infty)$\sidefootnote{In fact, we know that a sequence in $\ell^p$ converges to 0.};
    %     \item the space $\ell^p \subseteq \ell^q$ if $p < q$.
    % \end{itemize}

    We can also define norms in $C[0, 1]$, given as follows:
    \begin{align*}
        \lVert f \rVert_1 &= \int_0^1 |f(t)| \ dt \\
        \lVert f \rVert_2 &= \left(\int_0^1 (f(t))^2 \ dt\right)^{1/2} \\
        \lVert f \rVert_\infty &= \sup_0^1 |f(t)|.
    \end{align*}
    
    We will now add even more structure to a vector space, by defining an inner product.
    \begin{definition}[Inner Product Space]
        Let $V$ be a vector space and let $\langle \cdot, \cdot \rangle \colon V \times V \to \mathbb{C}$ be a function. We say that $(V, \langle \cdot, \cdot \rangle)$ is an \emph{inner product space} if:
        \begin{itemize}
            \item for all $v \in V$, $\langle v, v \rangle \in [0, \infty)$ and $\langle v, v \rangle = 0$ if and only if $v = 0$;
            \item for all $u, v \in V$ and $\lambda \in \mathbb{C}$, $\langle \lambda u, v \rangle = \lambda \langle u, v \rangle$;
            \item for all $v, w \in V$, $\langle v, w \rangle = \overline{\langle w, v \rangle}$;
            \item for all $u, v, w \in V$, $\langle u, v + w \rangle = \langle u, v \rangle + \langle u, w \rangle$.
        \end{itemize}
        If $(V, \langle \cdot, \cdot, \rangle)$ is an inner product space, we call $\langle \cdot, \cdot \rangle$ is an \emph{inner product}.
    \end{definition}
    \noindent The inner product allows us to measure angles between two vectors. In particular, the concept of orthogonality gives rise to many powerful results for Hilbert spaces (complete inner product spaces) that do not necessarily hold in Banach spaces (complete normed vector spaces).

    In $\mathbb{R}^n$ and $\mathbb{C}^n$, the dot product is an example of an inner product, which is given by
    \[\langle x, y \rangle = \sum_{i=1}^n x_i \overline{y_i}.\]
    This inner product induces the $\lVert \cdot \rVert_2$ norm. In particular, an inner product induces a metric, given by
    \[\lVert x\rVert = \langle x, x \rangle^{1/2}.\]
    To prove this, we require the Cauchy-Schwartz Inequality.
    \begin{theorem}[Cauchy-Schwartz Inequality]
        Let $(V, \langle \cdot, \cdot \rangle)$ be an inner product space. Then, for all $v, w \in V$, $|\langle v, w \rangle|^2 \leq \langle v, v \rangle \cdot \langle w, w \rangle$.
    \end{theorem}
    \begin{proof}
        Let $v, w \in V$. If $w = 0$, then the statement is trivial. Otherwise,
        \begin{align*}
            \langle v, v \rangle - \frac{|\langle v, w\rangle|^2}{\langle w, w \rangle} &= \langle v, v \rangle - \frac{\langle v, w \rangle \overline{\langle v, w \rangle}}{\langle w, w \rangle} \\
            &= \langle v, v \rangle - \frac{\langle v, w \rangle^2}{\langle w, w \rangle} - \frac{\langle v, w \rangle \langle w, v \rangle}{\langle w, w \rangle} + \frac{\langle v, w \rangle^2}{\langle w, w \rangle} \\
            &= \left\langle v, v - \frac{\langle v, w \rangle}{\langle w, w \rangle} w \right\rangle - \left(\frac{\langle v, w \rangle}{\langle w, w \rangle} \langle w, v \rangle - \frac{\langle v, w \rangle^2}{\langle w, w \rangle^2} \langle w, w \rangle \right) \\
            &= \left\langle v, v - \frac{\langle v, w \rangle}{\langle w, w \rangle} w \right\rangle - \left\langle \frac{\langle v, w \rangle}{\langle w, w \rangle} w, v - \frac{\langle v, w \rangle}{\langle w, w \rangle} w \right\rangle \\
            &= \left\langle v - \frac{\langle v, v\rangle}{\langle w, w \rangle} w, v - \frac{\langle v, v\rangle}{\langle w, w \rangle} w \right\rangle \geq 0.
        \end{align*}
        Hence,
        \[|\langle v, w \rangle|^2 \leq \langle v, v \rangle \cdot \langle w, w \rangle.\]
    \end{proof}
    \noindent It is not the case that every inner product is induced by a norm; this is only true for norms that satisfy the Parallelogram identity.
    \begin{proposition}
        Let $(V, \lVert \cdot \rVert)$ be a normed vector space that satisfies the Parallelogram identity, i.e. for all $u, v \in V$,
        \[2\lVert u \rVert^2 + 2\lVert v \rVert^2 = \lVert u + v \rVert^2 - \lVert u - v \rVert^2.\]
    \end{proposition}
    % \begin{proof}
    %     \hspace*{0pt}
    %     \begin{itemize}
    %         \item Let $v \in V$. We find that
    %         \[\langle v, v \rangle = \lVert 2v \rVert^2 + \lVert 0 \rVert^2 = 4\lVert v \rVert^2 \geq 0.\]
    %         Moreover, $\langle 0, 0 \rangle = 0$, and if $\langle v, v \rangle = 4\lVert v \rVert^2 = 0$, then $v = 0$.

    %         \item Let $u, v \in V$ and $\lambda \in \mathbb{R}$. We find that
    %         \begin{align*}
    %             \lambda \langle u, v \rangle &= \lambda (\lVert u + v \rVert^2 + \lVert u - v \rVert^2) \\
    %             &= 
    %         \end{align*}
            
    %         \item 
            
    %         \item 
    %     \end{itemize}
    % \end{proof}

    For $\operatorname{Seq}(\mathbb{R})$, an inner product is given by
    \[\langle (x_n), (y_n) \rangle = \sum_{n=1}^\infty x_i \overline{y_i}.\]
    In $C[0, 1]$, we have
    \[\langle f, g \rangle = \int_0^1 |f(t) g(t)| \ dt.\]

    We will now highlight the difference in metrics/norms for finite- and infinite-dimensional vector spaces. To do so, we will compare equivalence of metrics.
    \begin{definition}
        Let $(V, d)$ and $(V, d')$ be metric spaces. We say that the metrics $d$ and $d'$ are \emph{equivalent} if there exist $c, C > 0$ such that for all $x, y \in V$,
        \[cd'(x, y) \leq d(x, y) \leq Cd'(x, y).\]
        If $V$ is a vector space with two norms $\lVert \cdot \rVert$ and $\lVert \cdot \rVert'$, we say that the norms are \emph{equivalent} if the induced metrics are equivalent.
    \end{definition}
    
    It turns out that in finite-dimensional vector spaces, all norms are equivalent. We will show that the $p$-norms and the $\infty$-norm are equivalent.
    \begin{proposition}
        Let $n \in \mathbb{Z}_{\geq 1}$, $p \in [1, \infty)$ and $x \in \mathbb{R}^n$. Then,
        \[\lVert x \rVert_\infty \leq \lVert x \rVert_p \leq n^{1/p} \lVert x \rVert_\infty.\]
        In particular, all these norms are equivalent.
    \end{proposition}
    \begin{proof}
        Let $x = [x_1, \dots, x_n]$. So, we have $\lVert x \rVert_\infty = |x_i|$, for some $i \in \{1, \dots, n\}$. Then,
        \[\lVert x \rVert_\infty = |x_i| = \left(|x_i|^p\right)^{1/p} \leq \left(\sum_{i=1}^n |x_i|^p\right)^{1/p} = \lVert x \rVert_p.\]
        Moreover,
        \[\lVert x \rVert_p = \left(\sum_{i=1}^n |x_i|^p \right)^{1/p} \leq \left(\sum_{i=1}^n \lVert x \rVert_\infty^p \right)^{1/p} = n^{1/p} \lVert x \rVert_\infty.\]
        So,
        \[\lVert x \rVert_\infty \leq \lVert x \rVert_p \leq n^{1/p} \lVert x \rVert_\infty.\]
        Hence, for $x, y \in \mathbb{R}^n$, we find that
        \[d_\infty(x, y) \leq d_p(x, y) \leq n^{1/p} d_\infty(x, y).\]
        So, $d_p$ and $d_\infty$ are equivalent norms. Since metric equivalence is an equivalence relation, this implies that $d_p$ and $d_q$ norms are also equivalent. So, all the norms are equivalent.
    \end{proof}

    However, in infinite-dimensional vector spaces, the norms are not equivalent. In fact, in sequence spaces, we know that $\ell^1$, $\ell^2$ and $\ell^\infty$ are different sequence spaces. So, we will focus on $L_1$ and $L_\infty$ norms in $C[0, 1]$, and show that they are not equivalent. To see this, consider the sequence of functions $f_n(x) = t^n$. Then,
    \begin{align*}
        \lVert f_n \rVert_1 &= \int_0^1 |f_n(t)| \ dt = \int_0^1 t^n \ dt = \frac{1}{n+1} \\
        \lVert f_n \rVert_\infty &= \sup_{t \in [0, 1]} |f_n(t)| = 1.
    \end{align*}
    So,
    \[\frac{\lVert f_n \rVert_1}{\lVert f_n \rVert_\infty} = \frac{1}{n+1} \to 0.\]
    This implies that the norms are not equivalent.
    
    \newpage

    \section{Sequence Spaces}
    In this section, we will study sequence spaces in more detail. First, we define more sequence spaces:
    \begin{itemize}
        \item The sequence space $c$ contains all convergent sequences in $\mathbb{R}$;
        \item The sequence space $c_0$ contains all sequences in $\mathbb{R}^n$ that converge to $0$;
        \item The sequence space $c_{00}$ contains all sequences that are eventually zero, i.e. $(x_n)_{n=1}^\infty$ is in $c_{00}$ if and only if there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $n \geq N$, $x_n = 0$.
    \end{itemize}
    We will now prove some containment relations between the sequence spaces.
    \begin{proposition}
        We have
        \[c \subsetneq \ell^\infty.\]
        That is, every convergent sequence is bounded but not every bounded sequence is convergent.
    \end{proposition}
    \begin{proof}
        We first show that $c \subseteq \ell^\infty$. So, let $(x_n)_{n=1}^\infty$ be a sequence in $\mathbb{R}$, with $x_n \to L$. In that case, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $n \geq N$, $|x_n - L| < 1$, i.e. $|x_n| < |L| + 1$. So, set 
        \[K = \max(|x_1|, \dots, |x_{N-1}|, |L| + 1) > 0.\]
        By construction, $|x_n| \leq K$ for all $n < N$. Moreover, for $n \geq N$, $|x_n| < |L| + 1 \leq K$. So, $K$ is a bound for $(x_n)$. That is, $(x_n)$ is bounded. Hence, $c \subseteq \ell^\infty$.

        Now, consider the sequence $(x_n)_{n=1}^\infty$ given by $x_n = (-1)^n$. Although the sequence $(x_n)$ is bounded, it does not converge. Hence, $c \subsetneq \ell^\infty$.
    \end{proof}

    \begin{proposition}
        We have
        \[c_{00} \subsetneq \ell^1.\]
    \end{proposition}
    \begin{proof}
        We first show that $c_{00} \subseteq \ell^1$. So, let $(x_n)_{n=1}^\infty$ be a sequence in $\mathbb{R}$ such that there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $n \geq N$, $x_n = 0$. In that case, the series
        \[\sum_{n=1}^\infty |x_n| = \sum_{n=1}^N |x_n|\]
        converges- it is a finite sum. Hence, $c_{00} \subseteq \ell^1$.

        Now, consider the sequence $(x_n)_{n=1}^\infty$ given by $x_n = \frac{1}{n^2}$. Although the sequence $(x_n)$ is in $\ell^1$, it is not in $c_{00}$ (i.e. for all $n \in \mathbb{Z}_{\geq 1}$, $x_n > 0$). So, $c_{00} \subsetneq \ell^1$.
    \end{proof}

    \begin{proposition}
        Let $p \in [1, \infty)$. Then, $\ell^p \subsetneq c_0$.
    \end{proposition}
    \begin{proof}
        We first show that $\ell^p \subseteq c_0$. So, let $(x_n)_{n=1}^\infty$ be a sequence in $\mathbb{R}$ such that
        \[\sum_{n=1}^\infty |x_n|^p < \infty.\]
        In that case, we find that $|x_n|^p \to 0$ as $n \to \infty$. Hence, $|x_n| \to 0$ as $n \to \infty$, meaning that $x_n \to 0$. So, $\ell^p \subseteq c_0$.

        Now, consider the sequence $(x_n)_{n=1}^\infty$ given by $x_n = \frac{1}{n^p}$. Although the sequence $x_n \to 0$, we find that
        \[\sum_{n=1}^\infty |x_n|^p = \sum_{n=1}^\infty \frac{1}{n}\]
        diverges. Hence, $\ell^p \subsetneq c_0$.
    \end{proof}

    \begin{proposition}
        Let $1 \leq q < p$. Then, $\ell^p \subsetneq \ell^q$.
    \end{proposition}
    \begin{proof}
        We first show that $\ell^p \subseteq \ell^q$. So, let $(x_n)_{n=1}^\infty$ be a sequence in $\mathbb{R}$ such that
        \[\sum_{n=1}^\infty |x_n|^p < \infty.\]
        In that case, for all $n \in \mathbb{Z}_{\geq 1}$, we find that
        \begin{align*}
            \sum_{n=1}^\infty |x_n|^q &= \sum_{n=1}^\infty |x_n|^{q-p} |x_n|^{p} \\
            &\leq \sum_{n=1}^\infty \lVert x \rVert_\infty^{q-p} |x_n|^p \\
            &= \lVert x \rVert_\infty^{q-p} \sum_{n=1}^\infty |x_n|^p.
        \end{align*}
        Since $\ell^p \subseteq \ell^\infty$, we know that $\lVert x \rVert_\infty < \infty$. Hence, 
        \[\sum_{n=1}^\infty |x_n|^q < \infty.\]
        So, $\ell^p \subseteq \ell^q$.

        Now, consider the sequence $(x_n)_{n=1}^\infty$ given by $x_n = \frac{1}{n^{2/q}}$. Then, we have
        \[\sum_{n=1}^\infty |x_n|^q = \sum_{n=1}^\infty \frac{1}{n^2} < \infty,\]
        but
        \[\sum_{n=1}^\infty |x_n|^p = \sum_{n=1}^\infty \frac{1}{n^{2p/q}}\]
        diverges since $2p/q < 2$. So, $\ell^p \subsetneq \ell^q$.
    \end{proof}
    
    In summary, we have the following containment:
    \[c_{00} \subsetneq \ell^1 \subsetneq \ell^2 \subsetneq \dots \subsetneq c_0 \subsetneq c \subsetneq \ell^\infty.\]
    Note that each containment is strict.
    \newpage

    \section{Topology}
    In this section, we will review some topological properties and related them to vector spaces. As we know, the concept of a topological space generalises metric spaces, while preserving open and closed sets.
    \begin{definition}[Open sets]
        Let $(X, d)$ be a metric space and let $U \subseteq X$. We say that $U$ is \emph{open} if for all $x \in U$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d(x, y) < \varepsilon$, then $y \in U$, i.e. $B_\varepsilon(y) \subseteq U$. We say that $U$ is \emph{closed} if its complement is open.
    \end{definition}
    \begin{definition}[Topological space]
        Let $X$ be a set and let $\mathcal{T} \subseteq \mathbb{P}(X)$. We say that $(X, \mathcal{T})$ is a \emph{topological space} if:
        \begin{itemize}
            \item $\varnothing, X \in \mathcal{T}$;
            \item if $(U_i)_{i \in I}$ is a collection of subsets in $\mathcal{T}$, then its union
            \[\bigcup_{i \in I} U_i \in \mathcal{T}.\]
            \item if $(U_i)_{i=1}^n$ is a finite collection of subsets in $\mathcal{T}$, then its intersection
            \[\bigcap_{i=1}^n U_i \in \mathcal{T}.\]
        \end{itemize}
        If $(X, \mathcal{T})$ is a topological space, then we denote $U \in \mathcal{T}$ by an \emph{open set}.
    \end{definition}
    \noindent These topological axioms are satisfied by open sets in a metric space. We can define convergence in a topological space.
    \begin{definition}
        Let $X$ be a topological space, $(x_n)_{n=1}^\infty$ be a sequence in $X$ and $x \in X$. We say that $x_n \to x$ if for all $U \subseteq X$ open, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $x_n \in U$.
    \end{definition}
    \noindent Next, we define the closure of a set.
    \begin{definition}
        Let $X$ be a topological space and let $W \subseteq X$. The \emph{closure of $W$}, denoted $\overline{W}$, is the set
        \[\{x \in X \mid \exists (x_n)_{n=1}^\infty \textrm{ in } W \textrm{ s.t. } x_n \to x\}.\]
        That is, the closure contains all the limit points of $W$ in $X$.
    \end{definition}
    \noindent By construction, the closure of a set is closed. We will now define compactness.
    \begin{definition}[Compact Sets]
        Let $X$ be a topological space and let $C \subseteq X$. We say that $C$ is \emph{compact} if for any open cover of $C$ admits a finite subcover.
    \end{definition}
    \noindent There is another type of compactness- sequential compactness.
    \begin{definition}[Sequentially Compact Sets]
        Let $X$ be a topological space and let $C \subseteq X$. We say that $C$ is \emph{sequentially compact} if any sequence $(x_n)_{n=1}^\infty$ in $C$ has a convergent subsequence.
    \end{definition}
    \noindent For metric spaces, compact and sequentially compact sets are equivalent. Moreover, in $\mathbb{R}^n$, the Heine-Borel theorem characterises compactness.
    \begin{theorem}[Heine-Borel Theorem]
        Let $K \subseteq \mathbb{R}^n$. Then, $J$ is compact if and only if it is closed and bounded.
    \end{theorem}
    
    The Heine-Borel theorem does not hold in infinite-dimensional vector spaces. We know that in a metric space, compactness implies closed and bounded. We will illustrate the converse is not true in infinite-dimensional vector spaces. In particular, we will show that the unit ball in $\ell^\infty$ is not compact. This set is by definition closed, and bounded since it has sequences with norm at most 1. To do so, we will construct a sequence which has no convergent subsequence. So, define the sequence $(e^{(i)})_{i=1}^n$ in the unit ball given by
    \[e^{(i)}_n = \begin{cases}
        1 & n = i \\
        0 & \textrm{otherwise}.
    \end{cases}\]
    We know that for any $i, j \in \mathbb{Z}_{\geq 1}$, with $i \neq j$, $\lVert e^{(i)} - e^{(j)} \rVert_\infty = 1$. Hence, the sequence cannot have a convergent subsequence- the distance is always bounded above by $1$. So, the unit ball cannot be (sequentially) compact.
    % TODO: Example in $C[0, 1]$

    We aim to characterise compact sets in $C[0, 1]$. To do so, we first consider pointwise and uniform convergence.
    \begin{definition}
        Let $(f_n)_{n=1}^\infty$ be a sequence of functions in $f \colon [0, 1] \to \mathbb{R}$, and let $f \colon [0, 1] \to \mathbb{R}$. 
        \begin{itemize}
            \item We say that $f_n \to f$ pointwise if for any $\varepsilon > 0$ and $t \in [0, 1]$, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|f_n(t) - f(t)| < \varepsilon$;
            \item We say that $f_n \to f$ uniformly if for any $\varepsilon > 0$, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $t \in [0, 1]$ and $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|f_n(t) - f(t)| < \varepsilon$.
        \end{itemize}
    \end{definition}
    \noindent The difference between pointwise and uniform convergence is the choice of $N$- in pointwise convergence, the value $N$ can depend on $t \in [0, 1]$, but in uniform convergence, the value $N$ cannot. Hence, if $(f_n)_{n=1}^\infty$ is a sequence of functions that converge uniformly to some function $f$, then it also converges pointwise to the same function $f$.
    % In particular, the sequence of functions $f_n(x) = x^n$ in $C[0, 1]$ converges pointwise to some limit function $f$, but does not in 

    Uniform convergence in $C[0, 1]$ implies that the limit also lies in $C[0, 1]$.
    \begin{proposition}
        Let $(f_n)_{n=1}^\infty$ be a sequence of functions in $C[0, 1]$ that converge uniformly to the function $f \colon [0, 1] \to \mathbb{R}$. Then, $f \in C[0, 1]$.
    \end{proposition}
    \begin{proof}
        Let $\varepsilon > 0$. Since $f_n \to f$ uniformly, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $t \in [0, 1]$ and $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|f_n(t) - f(t)| < \frac{\varepsilon}{3}$. Set $N = n$. Since $f_n$ is continuous, there exists a $\delta > 0$ such that for $s, t \in [0, 1]$ if $|s - t| < \delta$, then $|f_n(s) - f_n(t)| < \frac{\varepsilon}{3}$. Then, for $s, t \in [0, 1]$, if $|s - t| < \delta$, then
        \begin{align*}
            |f(s) - f(t)| &\leq |f(s) - f_n(s)| + |f_n(s) - f_n(t)| + |f_n(t) - f(t)| \\
            &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
        \end{align*}
    \end{proof}
    \noindent Moreover, we can define the concept of uniform Cauchy, which we shall use in the proof.
    \begin{definition}
        Let $(g_n)_{n=1}^\infty$ be a sequence in $C[0, 1]$. We say that $(g_n)$ is \emph{uniformly Cauchy} if for every $\varepsilon > 0$, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$ and $t \in [0, 1]$, if $m, n \geq N$, then $|g_m(t) - g_n(t)| < \varepsilon$.
    \end{definition}
    \begin{lemma}
        Let $(g_n)_{n=1}^\infty$ be a sequence in $C[0, 1]$ that is uniformly Cauchy. Then, $(g_n)_{n=1}^\infty$ is uniformly convergent.
    \end{lemma}
    \begin{proof}
        Let $t \in [0, 1]$ and $\varepsilon > 0$. Since $(g_n)$ is uniformly Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $|g_m(t) - g_n(t)| < \varepsilon$. Hence, the sequence $(g_n(t))_{n=1}^\infty$ is Cauchy in $\mathbb{R}$. Since $\mathbb{R}$ is complete, there exists a $g_t \in \mathbb{R}$ such that $g_n(t) \to g_t$. So, define the function $g \colon [0, 1] \to \mathbb{R}$ by $g(t) = g_t$. We show that $g_n \to g$ uniformly.

        Let $\varepsilon > 0$. Since $(g_n)$ is uniformly Cauchy, there exists a $K \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$ and $t \in [0, 1]$, if $m, n \geq K$, then $|g_m(t) - g_n(t)| < \frac{\varepsilon}{2}$. Now let $t \in [0, 1]$. Since $g_k(t) \to g(t)$, there exists a $K' \in \mathbb{Z}_{\geq 1}$ such that for $k \in \mathbb{Z}_{\geq 1}$, if $k \geq K'$, then $|g_k(t) - g(t)| < \frac{\varepsilon}{2}$. Now, fix $N = \max(K, K')$. Hence, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq K$, then
        \[|g_n(t) - g(t)| \leq |g_n(t) - g_N(t)| + |g_N(t) - g(t)| < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.\]
        Hence, $g_n \to g$ uniformly.
    \end{proof}

    Now, we consider the concept of equi-continuity, which will allow us to characterise compactness in $C[0, 1]$. 
    \begin{definition}
        Let $K \subseteq C[0, 1]$. We say that $K$ is \emph{equi-continuous} if for every $\varepsilon > 0$, there exists a $\delta > 0$ such that for $f \in K$ and $s, t \in [0, 1]$, if $|s - t| < \delta$, then $|f(s) - f(t)| < \varepsilon$.
    \end{definition}
    \noindent The concept of equi-continuous functions is a generalisation of continuity- it establishes that functions in $K$ are continuous in a `similar' manner. We will now characterise compactness in $C[0, 1]$.

    \begin{theorem}[Arzela-Ascoli Theorem]
        Let $K \subseteq C[0, 1]$. Then, $K$ is compact if and only if $K$ is closed, bounded and equi-continuous.
    \end{theorem}
    \begin{proof}
        Assume that $K$ is compact. We know that $K$ is closed and bounded. So, we show that $K$ is equi-continuous. Let $\varepsilon > 0$. We know that $(B_{\varepsilon/3}(f))_{f \in K}$ is an open cover of $K$, so it has a finite subcover $(B_{\varepsilon/3}(f_i))_{i=1}^n$. Now, let $\delta > 0$ such that for $s, t \in [0, 1]$, if $|s - t| < \delta$, then $|f_i(s) - f_i(t)| < \frac{\varepsilon}{3}$ for $i \in \{1, \dots, n\}$. Now, let $f \in K$. Let $i \in \{1, \dots, n\}$ such that $\lVert f - f_i \rVert_\infty < \frac{\varepsilon}{3}$. Then, for $s, t \in [0, 1]$ with $|s - t| < \delta$, then
        \begin{align*}
            |f(s) - f(t)| &\leq |f(s) - f_i(s)| + |f_i(s) - f_i(t)| + |f_i(t) - f(t)| \\
            &\leq \lVert f - f_i \rVert_\infty + |f_i(s) - f_i(t)| + \lVert f_i - f \rVert_\infty \\
            &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
        \end{align*}
        Hence, $K$ is equi-continuous.

        Now, assume that $K$ is closed, bounded and equi-continuous. We show that $K$ is (sequentially) compact. So, let $(f_n)_{n=1}^\infty$ be a sequence in $K$. Enumerate 
        \[\mathbb{Q} = \{r_1, r_2, \dots\}.\]
        Consider the sequence $(f_n(r_1))_{n=1}^\infty$ in $[0, 1]$. By Bolzano-Weierstrass, we know that the sequence has a convergent subsequence $(f_{1, n}(r_1))_{n=1}^\infty$. Now, consider the sequence $(f_{1, n}(r_2))_{n=1}^\infty$ in $[0, 1]$. By Bolzano-Weierstrass again, we know that the sequence has a convergent subsequence $(f_{2, n}(r_2))_{n=1}^\infty$. Since $(f_2)$ is a subsequence of $(f_1)$, we know that $(f_2(r_1))_{n=1}^\infty$ is still convergent. We can continue this for every $k \in \mathbb{Z}_{\geq 1}$, to define the sequences $(f_{k, n})_{n=1}^\infty$. Now, define the sequence $(g_n)_{n=1}^\infty$ in $K$ by $g_n = f_{n, n}$. This is a subsequence of $(f_n)_{n=1}^\infty$ by construction. Moreover, for $r_j \in \mathbb{Q}$, the sequence $(f_{j, n}(r_j))_{n=1}^\infty$ is convergent, and since $(g_n)_{n=j}^\infty$ is a subsequence of $(f_{j, n})_{n=1}^\infty$, we find that $(g_n(r_j))_{n=1}^\infty$ is convergent. 

        Next, we show that $(g_n)$ is uniformly Cauchy. Let $\varepsilon > 0$. Since $K$ is equi-continuous, there exists a $\delta > 0$ such that for all $k \in \{1, \dots, n\}$ and $s, t \in [0, 1]$, if $|s - t| < \delta$, then $|g_k(s) - g_k(t)| < \frac{\varepsilon}{3}$. Now, partition $[0, 1]$ into intervals $(I_k)_{k=1}^n$ of length $< \delta$. For each $k \in \{1, \dots, n\}$, there exists an $N_k \in \mathbb{Z}_{\geq 1}$ such that for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N_k$, then $|g_m(r_k) - g_n(r_k)| < \frac{\varepsilon}{3}$. Now, let $N = \max(N_1, \dots, N_n)$. Now, let $t \in [0, 1]$ and $m, n \in \mathbb{Z}_{\geq 1}$. We have $t \in I_k$ for some $k \in \{1, \dots, n\}$. Moreover, since $\mathbb{Q}$ is dense, there exists an $r_k \in I_k$ with $r_k \in \mathbb{Q}$. By construction, we have $|r_k - t| < \delta$. Hence, if $m, n \geq N$, then
        \begin{align*}
            |g_m(t) - g_n(t)| &\leq |g_m(t) - g_m(r_k)| + |g_m(r_k) - g_n(r_k)| + |g_n(r_k) - g_n(t)| \\
            &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
        \end{align*}
        So, $(g_n)$ is uniformly Cauchy. This implies that $(g_n)$ is uniformly convergent. This means that $g_n \to g$, for some $g \in C[0, 1]$. Since $K$ is closed, we have $g \in K$. Therefore, $(f_n)_{n=1}^\infty$ has a subsequence $(g_n)_{n=1}^\infty$ such that $g_n \to g$. Hence, $K$ is compact.
    \end{proof}


% \section{Introduction to norms}
% \subsection{Distance in vector spaces}
% In $\mathbb{R}^n$, we have seen the following metrics:
% \begin{itemize}
%     \item $d_1$, which is defined by
%     \[d_1(\bm{x}, \bm{y}) = \sum_{i=1}^n |x_i - y_i|;\]
%     \item $d_2$, which is defined by
%     \[d_1(\bm{x}, \bm{y}) = \left(\sum_{i=1}^n |x_i - y_i|^2\right)^{1/2};\]
%     \item $d_\infty$, which is defined by
%     \[d_\infty(\bm{x}, \bm{y}) = \sup_{i=1}^n |x_i - y_i|;\]
% \end{itemize}
% In general, for $p \in [1, \infty)$, we can define the metric $d_p$, given by
% \[d_p(\bm{x}, \bm{y}) = \left(\sum_{i=1}^n |x_i - y_i|^2\right)^{1/p}.\]

% % TODO: Minkowski inequality to show triangle inequality holds

% We can define metrics on other vector spaces, such as the space of sequences in $\mathbb{R}$ (or any field $\mathbb{K}$). The space of sequences in some field $\mathbb{K}$ is denoted by $\operatorname{Seq}(\mathbb{K})$. For each $p \in [1, \infty)$, we define the set $\ell^p$ to be a subspace of $\operatorname{Seq}(\mathbb{R})$ for which the distance function $d_p$ is defined. That is, the set $\ell^p$ contains of all sequences $(x_n)_{n=1}^\infty$ in $\mathbb{R}$ such that the series
% \[\sum_{i=1}^\infty |x_i|^p \]
% converges- if so, we define the distance between $x^{(n)}$ and $y^{(n)}$ in $\ell^p$ to be:
% \[d_p(x^{(n)}, y^{(n)}) = \left(\sum_{i=1}^\infty |x_i - y_i|^p \right)^{1/p}.\]
% % TODO: Prove the series converges
% % The series
% % \[\sum_{i=1}^\infty |x_i - y_i|^p\]
% % converges- for all $i \in \mathbb{Z}_{\geq 1}$,
% % \[|x_i - y_i|^p \leq (|x_i| + |y_i|)^p \leq |x_i|^p + |y_i|^p.\]
% % Since $x^{(n)}$ and $y^{(n)}$ are in $\ell^p$, we find that the series
% % \[\sum_{n=1}^\infty |x_i|^p + |y_i|^p = \sum_{n=1}^\infty |x_i|^p + \sum_{n=1}^\infty |y_i|^p\]
% % converges. That is, the distance function is well-defined. 
% We also define $\ell^\infty$ to be the set of all bounded sequences in $\mathbb{R}$, with
% \[d_\infty(x^{(n)}, y^{(n)}) = \sup_{i=1}^n |x_i - y_i|.\]

% Further, we can define norms on the set of continuous functions $C[0, 1]$. The distance between two functions $f, g \in C[0, 1]$ is defined to be:
% \[d_p(f, g) = \left(\int_0^1 |f(x) - g(x)|^p \ dx\right)^{1/p}.\]
% The value is always finite for $f, g$ continuous, since $|f - g|^p$ is a continuous function.

% \subsection{Norms}
% We now define a norm for vector spaces.
% \begin{definition}
%     Let $V$ be a real vector space and let $\lVert . \rVert\colon V \to \mathbb{R}$ be a function. We say that $\lVert . \rVert$ is a \emph{norm} if
%     \begin{enumerate}[label=\textbf{N\arabic*.}]
%         \item for all $\bm{v} \in V$, $\lVert \bm{v} \rVert \geq 0$, and $\lVert \bm{v} \rVert = 0$ if and only if $\bm{v} = \bm{0}$;
%         \item for all $c \in \mathbb{R}$ and $\bm{v} \in V$, $\lVert c \bm{v} \rVert = |c| \lVert \bm{v} \rVert$;
%         \item for all $\bm{u}, \bm{v} \in V$, 
%         \[\lVert \bm{u} + \bm{v} \rVert \leq \lVert \bm{u} \rVert + \lVert \bm{v} \rVert.\]
%     \end{enumerate}
% \end{definition}

% For every norm, there exists a metric; every norm induces a metric.
% \begin{proposition}
%     Let $V$ be a real vector space and let $\lVert . \rVert$ be a norm. Define the function $d\colon V \times V \to \mathbb{R}$ by $d(\bm{u}, \bm{v}) = \lVert \bm{u} - \bm{v} \rVert$. Then, $(V, d)$ is a metric space.
% \end{proposition}
% \begin{proof}
%     We check this directly from the axioms of a metric space:
%     \begin{enumerate}[label=\textbf{M\arabic*.}]
%         \item Let $\bm{x}, \bm{y} \in V$. We find that
%         \[d(\bm{x}, \bm{y}) = \lVert \bm{x} - \bm{y} \rVert \geq 0.\]
%         Moreover, $d(\bm{x}, \bm{y}) = 0$ if and only if $\bm{x} - \bm{y} = \bm{0}$, i.e. $\bm{x} = \bm{y}$.
%         \item Let $\bm{x}, \bm{y} \in V$. We find that
%         \[d(\bm{x}, \bm{y}) = \lVert \bm{x} - \bm{y} \rVert = \lVert -(\bm{y} - \bm{x}) \rVert = |-1| \lVert \bm{y} - \bm{x} \rVert = \lVert \bm{y} - \bm{x} \rVert = d(\bm{y}, \bm{x}).\]
%         \item Let $\bm{x}, \bm{y}, \bm{z} \in V$. We find that
%         \begin{align*}
%             d(\bm{x}, \bm{z}) &= \lVert \bm{x} - \bm{z} \rVert \\
%             &= \lVert (\bm{x} - \bm{y}) + (\bm{y} - \bm{z}) \rVert \\
%             &\leq \lVert \bm{x} - \bm{y} \rVert + \lVert \bm{y} - \bm{z} \rVert \\
%             &= d(\bm{x}, \bm{y}) + d(\bm{y}, \bm{z}).
%         \end{align*}
%     \end{enumerate}
%     So, $(V, d)$ is a metric space.
% \end{proof}
% However, the converse is not true- not every distance function corresponds to a norm. Before proving this, we characterise the relationship between the distance and the norm in the other direction.
% \begin{proposition}
%     Let $V$ be a real vector space and let $d$ be a metric induced by some norm $\lVert . \rVert\colon V \to \mathbb{R}$. Then, for all $\bm{v} \in V$, $\lVert \bm{v} \rVert = d(\bm{0}, \bm{v})$.
% \end{proposition}
% \begin{proof}
%     Since the norm $\lVert . \rVert$ induces the metric $d$, we know that for all $\bm{u}, \bm{v} \in V$, $d(\bm{u}, \bm{v}) = \lVert \bm{u} - \bm{v} \rVert$. In that case, for $\bm{v} \in V$,
%     \[\lVert \bm{v} \rVert = \lVert \bm{v} - \bm{0} \rVert = d(\bm{v}, \bm{0}) = d(\bm{0}, \bm{v}).\]
% \end{proof}
% Now, we give a counterexample to show that not every metric is induced by some norm. Let $d$ be the discrete metric on $\mathbb{R}$. We claim that $(\mathbb{R}, d)$ is not induced by a norm. Assume, for a contradiction, that there exists a norm $\lVert . \rVert\colon \mathbb{R} \to \mathbb{R}$ such that for all $x, y \in \mathbb{R}$, $d(x, y) = \lVert x - y \rVert$. In that case,
% \[2 = 2d(1, 0) = 2\lVert 1 \rVert = \lVert 2 \rVert = d(2, 0) = 1.\]
% This is a contradiction. So, $(\mathbb{R}, d)$ is not induced by a norm. 

% \subsection{Strong equivalence of norms}
% For a real vector space, we say that two norms on it are strongly equivalent if the induced metrics are strongly equivalent. We know that in $\mathbb{R}^n$, all the $\ell^p$ norms are strongly equivalent. However, this is not true for sequence and function spaces.

% For sequence spaces, the sets $\ell^p$ are not equal for distinct $p$. In particular, $\ell^1 \neq \ell^2$. To see this, consider the sequence $(x_n)_{n=1}^\infty$ in $\mathbb{R}$ given by $x_n = 1/n$. Since the harmonic series diverges, we know that $(x_n)$ is not in $\ell^1$. However, since the series
% \[\sum_{n=1}^\infty \frac{1}{n^2}\]
% converges, the sequence is in $\ell^2$. So, $\ell^1 \neq \ell^2$. 

% Nonetheless, we do have $\ell^1 \subseteq \ell^2$. Let $(x_n)_{n=1}^\infty$ be a sequence in $\mathbb{R}$ with $(x_n)$ in $\ell^1$. In that case, the series
% \[\sum_{n=1}^\infty x_n\]
% converges. Therefore, we must have that $x_n \to 0$, i.e. $(x_n)$ is convergent. So, there exists a $K > 0$ such that $|x_n| \leq K$ for all $n \in \mathbb{Z}_{\geq 1}$. In that case, for $n \in \mathbb{Z}_{\geq 1}$,
% \[0 \leq |x_n|^2 \leq K|x_n|.\]
% So, the comparison test tells us that the series
% \[\sum_{n=1}^\infty x_n^2\]
% converges. This implies that $(x_n)$ is in $\ell^2$. Therefore, $\ell^1 \subseteq \ell^2$. \sidefootnote{Can we use this approach to show that $\ell^2 \subseteq \ell^3$?}

% Using the result above, we show that $\ell_1$ and $\ell_2$ are not equivalent in $\ell^1$.\sidefootnote{We refer to the set of sequences by $\ell^p$, and the corresponding norm by $\ell_p$.} To see this, define the sequence $(x^{(k)})_{k=1}^\infty$ in $\ell^2$ by
% \[x^{(k)} = (1, \tfrac{1}{2}, \tfrac{1}{3}, \dots, \tfrac{1}{k}, 0, 0, \dots).\]
% For $k \in \mathbb{Z}_{\geq 1}$, we have
% \[\lVert x^{(k)} \rVert_1 = \sum_{n=1}^k \frac{1}{n}.\]
% Since the sum is finite, we know that $x^{(k)}$ is in $\ell^1$. Now, define also the sequence $(x_n)_{n=1}^\infty$ by $x_n = \frac{1}{n}$. We have $(x_n)$ in $\ell^2$. Moreover, under the $\ell_2$ norm,
% \[\lVert x^{(k)} - x \rVert_2 = \sum_{n=k+1}^\infty \frac{1}{n^2} \to 0\]
% as $k \to \infty$. This implies that $(x^{(k)})$ is Cauchy in $(\ell^1, d_1)$. Now, we show that $(x^{(k)})$ is not Cauchy in $(\ell^1, d_2)$. Let $N \in \mathbb{Z}_{\geq 1}$. Since the harmonic series diverges, we must have
% \[\sum_{n=N}^\infty \frac{1}{n} \to \infty.\]
% So, there exists an $M \in \mathbb{Z}_{> N}$ such that
% \[\sum_{n=N}^M \frac{1}{n} > 1.\]
% In that case,
% \[\lVert x^{(N)}, x^{(M+1)} \rVert_1 = \sum_{n=N}^\infty \frac{1}{n} - \sum_{n=M+1}^\infty \frac{1}{n} = \sum_{n=N}^M \frac{1}{n} \geq 1.\]
% Therefore, $(x^{(k)})$ is not Cauchy in $(\ell^1, d_2)$. This implies that $\ell_1$ and $\ell_2$ are not equivalent in $\ell^1$.

% Similarly, the norms on the function space $C[0, 1]$ are not strongly equivalent. For example, consider the sequence $(f_n(x))_{n=1}^\infty$ given by $f_n(x) = x^n$. We know that $x^n$ is increasing on $[0, 1]$. So,
% \[\lVert f_n \rVert_\infty = \sup_{x \in [0, 1]} |f_n(x)| = f_n(1) = 1.\]
% Moreover,
% \[\lVert f_n \rVert_1 = \int_0^1 f_n(x) \ dx = \int_0^1 x^n \ dx = \left[\frac{1}{n+1} x^{n+1}\right]_0^1 = \frac{1}{n + 1} \to 0\]
% as $n \to \infty$. This implies that the two norms are not strongly equivalent.

% % TODO: Show d_1 and d_2 aren't strongly equivalent in B[0, 1] with the same example as for sequences f_n(x) = 1/sqrt(x) for [1/n, 1] and 0 otherwise
% \newpage

% \section{Introduction to inner products}

% \begin{definition}
%     Let $V$ be a real vector space and let $\langle ., . \rangle\colon V \times V \to \mathbb{R}$ be a function. Then, $\langle ., . \rangle$ is an \emph{inner product} if:
%     \begin{enumerate}[label=\textbf{I\arabic*.}]
%         \item for all $\bm{v} \in V$, $\langle \bm{v}, \bm{v} \rangle \geq 0$, with $\langle \bm{v}, \bm{v} \rangle = 0$ if and only if $\bm{v} = \bm{0}$;
%         \item for all $\lambda \in \mathbb{R}$ and $\bm{v}, \bm{w} \in V$, $\langle \lambda \bm{v}, \bm{w} \rangle = \lambda \langle \bm{v}, \bm{w} \rangle$;
%         \item for all $\bm{v}, \bm{w} \in V$, $\langle \bm{v}, \bm{w} \rangle = \langle \bm{w}, \bm{v} \rangle$;
%         \item for all $\bm{u}, \bm{v}, \bm{w} \in V$,
%         \[\langle \bm{u} + \bm{v}, \bm{w} \rangle = \langle \bm{u}, \bm{w} \rangle + \langle \bm{v}, \bm{w} \rangle.\]
%     \end{enumerate}
% \end{definition}

% In $\mathbb{R}^n$, the inner product is the dot product, given by
% \[\langle \bm{x}, \bm{y} \rangle = \sum_{k=1}^n x_k y_k\]
% for $\bm{x}, \bm{y} \in \mathbb{R}^n$. For sequences, the inner product is the generalisation of the dot product, given by
% \[\langle x^{(n)}, y^{(n)} \rangle = \sum_{n=1}^\infty x_ny_n.\]
% The sequence space where this series is convergent is precisely $\ell^2$. In $C[0, 1]$, the inner product is given by
% \[\langle f, g \rangle = \int_0^1 f(x) g(x) \ dx.\]
% We can define this not just on $C[0, 1]$, but also on functions $f$ and $g$ where $fg$ is integrable- this set is called $L^2[0, 1]$. In all cases, this follows from the Cauchy-Schwarz inequality.

% \begin{proposition}[Cauchy-Schwarz inequality]
%     Let $V$ be a real vector space and let $\langle ., . \rangle\colon V \times V \to \mathbb{R}$ be an inner product on $V$. Then, for all $\bm{v}, \bm{w} \in V$,
%     \[|\langle \bm{v}, \bm{w} \rangle|^2 \leq \langle \bm{v}, \bm{v} \rangle \cdot \langle \bm{w}, \bm{w} \rangle.\]
% \end{proposition}
% \begin{proof}
%     Let $\lambda = \frac{\langle \bm{v}, \bm{w} \rangle}{\langle \bm{w}, \bm{w} \rangle}$. We know that
%     \[\langle \bm{v} - \lambda \bm{w}, \bm{v} - \lambda \bm{w} \rangle \geq 0.\]
%     We also have
%     \[\langle \bm{v} - \lambda \bm{w}, \bm{v} - \lambda \bm{w} \rangle = \langle \bm{v}, \bm{v} \rangle - 2\lambda \langle \bm{v}, \bm{w} \rangle + \lambda^2 \langle \bm{w}, \bm{w} \rangle.\]
%     Treating this as a quadratic on $\lambda$, we know that it has at most one real root. So, the discriminant is non-positive. That is,
%     \begin{align*}
%         (2\langle \bm{v}, \bm{w} \rangle)^2 - 4\langle \bm{w}, \bm{w} \rangle \cdot \langle \bm{v}, \bm{v} \rangle &\leq 0 \\
%         4\langle \bm{v}, \bm{w} \rangle^2 &\leq 4\langle \bm{w}, \bm{w} \rangle \cdot \langle \bm{v}, \bm{v} \rangle \\
%         |\langle \bm{v}, \bm{w} \rangle|^2 &\leq \langle \bm{w}, \bm{w} \rangle \cdot \langle \bm{v}, \bm{v} \rangle.
%     \end{align*}
% \end{proof}

% An inner product induces a norm.
% \begin{proposition}
%     Let $V$ be a real vector space and let $\langle ., . \rangle\colon V \times V \to \mathbb{R}$ be an inner product on $V$. Then, define the function $\lVert . \rVert\colon V \to \mathbb{R}$ by 
%     \[\lVert \bm{v} \rVert = \langle \bm{v}, \bm{v} \rangle^{1/2}.\]
%     Then, $\lVert . \rVert$ defines a norm on $V$.
% \end{proposition}
% \begin{proof}
%     \hspace*{0pt}
%     \begin{enumerate}[label=\textbf{N\arabic*.}]
%         \item Let $\bm{v} \in V$. We know that $\lVert \bm{v} \rVert \geq 0$ for all $\bm{v} \in V$. Moreover, if $\lVert \bm{v} \rVert = \langle \bm{v}, \bm{v} \rangle = 0$, then $\bm{v} = \bm{0}$.
%         \item Let $c \in \mathbb{R}$ and $\bm{v} \in V$. We find that
%         \[\lVert c\bm{v} \rVert^2 = \langle c\bm{v}, c\bm{v} \rangle = c^2 \langle \bm{v}, \bm{v} \rangle = c^2 \lVert \bm{v} \rVert^2.\]
%         So, $\lVert c\bm{v} \rVert = |c| \lVert \bm{v} \rVert$.
%         \item Let $\bm{u}, \bm{v} \in V$. We find that
%         \begin{align*}
%             \lVert \bm{u} + \bm{v} \rVert^2 &= \langle \bm{u} + \bm{v}, \bm{u} + \bm{v} \rangle \\
%             &= \langle \bm{u}, \bm{u} \rangle + 2\langle \bm{v}, \bm{u} \rangle + \langle \bm{v}, \bm{v} \rangle \\
%             &\leq \lVert \bm{u} \rVert^2 + 2\lVert \bm{u} \rVert\lVert \bm{v} \rVert + \lVert \bm{v} \rVert^2 \\
%             &\leq (\lVert \bm{u} \rVert + \lVert \bm{v} \rVert)^2.
%         \end{align*}
%         This implies that $\lVert \bm{u} + \bm{v} \rVert \leq \lVert \bm{u} \rVert + \lVert \bm{v} \rVert$.
%     \end{enumerate}
%     So, $\lVert . \rVert$ is a norm on $V$.
% \end{proof}

% \begin{definition}
%     Let $V$ be a real vector space with inner product $\langle ., . \rangle$. Then, for $\bm{v}, \bm{w} \in V$, we say that $\bm{v}$ and $\bm{w}$ are \emph{orthogonal} if $\langle \bm{v}, \bm{w} \rangle = 0$.
% \end{definition}

% \begin{proposition}[Pythagoras' Theorem]
%     Let $V$ be a real vector space with inner product $\langle ., . \rangle$, let $\lVert . \rVert$ be the norm induced by the inner product, and let $\bm{v}, \bm{w} \in V$ be orthogonal. Then,
%     \[\lVert \bm{v} + \bm{w} \rVert^2 = \lVert \bm{v} \rVert^2 + \lVert \bm{w} \rVert^2.\]
% \end{proposition}
% \begin{proof}
%     We find that
%     \begin{align*}
%         \lVert \bm{v} + \bm{w} \rVert^2 &= \langle \bm{v} + \bm{w}, \bm{v} + \bm{w} \rangle \\
%         &= \langle \bm{v}, \bm{v} \rangle + \langle \bm{v}, \bm{w} \rangle + \langle \bm{w}, \bm{v} \rangle + \langle \bm{w}, \bm{w} \rangle \\
%         &= \langle \bm{v}, \bm{v} \rangle + \langle \bm{w}, \bm{w} \rangle \\
%         &= \lVert \bm{v} \rVert^2 + \lVert \bm{w} \rVert^2.
%     \end{align*}
% \end{proof}

% \begin{proposition}[Parallelogram Law]
%     Let $V$ be a real vector space with inner product $\langle ., \rangle$, and let $\lVert . \rVert$ be the norm induced by the inner product. Then, for all $\bm{v}, \bm{w} \in V$,
%     \[\lVert \bm{v} + \bm{w} \rVert^2 + \lVert \bm{v} - \bm{w} \rVert^2 = 2\lVert \bm{v} \rVert^2 + 2\lVert \bm{w} \rVert^2.\]
%     Conversely, if a norm satisfies the equality above for all $\bm{v}, \bm{w} \in V$, then it is induced by an inner product.
% \end{proposition}
% \begin{proof}
%     \hspace*{0pt}
%     \begin{itemize}
%         \item First, assume that $\lVert . \rVert$ is induced by an inner product. Let $\bm{v}, \bm{w} \in V$. Then,
%         \begin{align*}
%             \lVert \bm{v} + \bm{w} \rVert^2 + \lVert \bm{v} - \bm{w} \rVert^2 &= \langle \bm{v} + \bm{w}, \bm{v} + \bm{w} \rangle + \langle \bm{v} - \bm{w}, \bm{v} - \bm{w} \rangle \\
%             &= \langle \bm{v}, \bm{v} \rangle + \langle \bm{v}, \bm{w} \rangle + \langle \bm{w}, \bm{v} \rangle + \langle \bm{w}, \bm{w} \rangle \\
%             &+\langle \bm{v}, \bm{v} \rangle - \langle \bm{v}, \bm{w} \rangle - \langle \bm{w}, \bm{v} \rangle + \langle \bm{w}, \bm{w} \rangle \\
%             &= 2\langle \bm{v}, \bm{v} \rangle + 2\langle \bm{w}, \bm{w} \rangle \\
%             &= 2\lVert \bm{v} \rVert^2 + 2\lVert \bm{w} \rVert^2.
%         \end{align*}

%         \item Now, assume that for all $\bm{v}, \bm{w} \in V$, 
%         \[\lVert \bm{v} + \bm{w} \rVert^2 + \lVert \bm{v} - \bm{w} \rVert^2 = 2\lVert \bm{v} \rVert^2 + 2\lVert \bm{w} \rVert^2.\]
%         Define the function $\langle ., . \rangle\colon V \times V \to \mathbb{R}$ by
%         \[\langle \bm{v}, \bm{w} \rangle = \frac{1}{4} (\lVert \bm{v} + \bm{w} \rVert^2 - \lVert \bm{v} - \bm{w} \rVert^2).\]
%         We claim that $\langle ., . \rangle$ is an inner product on $V$ and that the inner product induces the norm $\lVert . \rVert$.
%         \begin{enumerate}[label=\textbf{I\arabic*.}]
%             \item Let $\bm{v} \in V$. We have
%             \[\langle \bm{v}, \bm{v} \rangle = \frac{1}{4} \cdot \lVert 2\bm{v} \rVert^2 = \lVert \bm{v} \rVert^2 \geq 0.\]
%             Moreover, if $\langle \bm{v}, \bm{v} \rangle = 0$, then $\bm{v} = \bm{0}$.
%             \item Let $\lambda \in \mathbb{R}$ and $\bm{v}, \bm{w} \in V$. Then,
%             \begin{align*}
%                 \langle \lambda \bm{v}, \bm{w} \rangle &= \frac{1}{4} (\lVert \lambda \bm{v} - \bm{w} \rVert^2 - \lVert \lambda \bm{v} - \bm{w} \rVert^2) \\
%                 &= \frac{1}{4}(2\lVert \lambda \bm{v} \rVert^2 + 2\lVert \bm{w} \rVert^2 - 2\lVert \lambda \bm{v} - \bm{w} \rVert^2) 
%             \end{align*}
%             % TODO: Finish
%             \item Let $\bm{v}, \bm{w} \in V$. Then,
%             \begin{align*}
%                 \langle \bm{v}, \bm{w} \rangle &= \frac{1}{4}(\lVert \bm{v} + \bm{w} \rVert^2 - \lVert \bm{v} - \bm{w} \rVert^2) \\
%                 &= \frac{1}{4}(\lVert \bm{w} + \bm{v} \rVert^2 - \lVert \bm{w} - \bm{v} \rVert^2) \\
%                 &= \langle \bm{w}, \bm{v} \rangle.
%             \end{align*}
%             \item Let $\bm{u}, \bm{v}, \bm{w} \in V$. Then,
%             \begin{align*}
%                 \langle \bm{u} + \bm{v}, \bm{w} \rangle &= 
%             \end{align*}
%             % TODO: Finish
%         \end{enumerate}
%     \end{itemize}
% \end{proof}

% Using this result, we can show that the norm $\lVert . \rVert_1$ on $\mathbb{R}^2$ is not induced by a norm. Let $\bm{v} = [1, 0]$ and $\bm{w} = [0, 1]$. Then, we have
% \[\lVert \bm{v} + \bm{w} \rVert_1^2 + \lVert \bm{v} - \bm{w} \rVert_1^2 = \lVert [1, 1] \rVert_1^2 + \lVert [1, -1] \rVert_1^2 = 4 + 4 = 8,\]
% but
% \[2\lVert \bm{v} \rVert_1 + 2\lVert \bm{w} \rVert_1 = 2\lVert [1, 0] \rVert_1^2 + 2\lVert [0, 1] \rVert_1^2 = 2 + 2 = 4.\]
% We can use the same values to show that $\lVert . \rVert_\infty$ on $\mathbb{R}^2$ is not induced by a norm.

% \newpage

% \section{Sequence spaces}
% In this section, we will have a look at sequence spaces in more detail- we will show that they are vector spaces and characterise the containment of sequence spaces. First, we will consider the sequence spaces:
% \begin{itemize}
%     \item For $p \in [1, \infty)$, the sequence space $\ell^p$ contains sequences $(x_n)_{n=1}^\infty$ in $\mathbb{R}$ such that the series
%     \[\sum_{k=1}^\infty |x_k|^p\]
%     converges. We show that $\ell^p$ is a vector space.
%     \begin{itemize}
%         \item Let $(x_n)_{n=1}^\infty$ be in $\ell^p$ and $\lambda \in \mathbb{R}$. Since $(x_n)$ is in $\ell^p$, the series
%         \[\sum_{n=1}^\infty |x_n|^p\]
%         converges. In that case,
%         \[\sum_{n=1}^\infty |\lambda x_n|^p = |\lambda|^p \sum_{n=1}^\infty |x_n|^p.\]
%         So, the series $(\lambda x_n)$ is in $\ell^p$.

%         \item Let $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ be in $\ell^p$. Since $(x_n)$ and $(y_n)$ are in $\ell^p$, the series
%         \[\sum_{n=1}^\infty |x_n|^p, \qquad \sum_{n=1}^\infty |y_n|^p\]
%         converge. In that case, for all $n \in \mathbb{Z}_{\geq 1}$,
%         % TODO: Show some comparison
%         \[(|x_n| + |y_n|)^p = |x_n|^p + \dots + |y_n|^p \]
%         So, the comparison test tells us that
%         \[\sum_{n=1}^\infty |x_n + y_n|^p \]
%         converges. So, the series $(x_n + y_n)$ is in $\ell^p$.
%     \end{itemize}

%     \item The sequence space $\ell^\infty$ is the set where the infinity norm is defined, i.e. for a sequence $(x_n)_{n=1}^\infty$ in $\mathbb{R}$, the supremum
%     \[\sup_{k=1}^\infty |x_n|\]
%     exists. Therefore, the space is precisely the set of all bounded sequences. We show that $\ell^\infty$ is a vector space.
%     \begin{itemize}
%         \item Let $(x_n)_{n=1}^\infty$ be in $\ell^\infty$ and $\lambda \in \mathbb{R}$. Since $(x_n)$ is in $\ell^\infty$, there exists a $K > 0$ such that for all $n \in \mathbb{Z}_{\geq 1}$, $|x_n| \leq K$. In that case, for all $n \in \mathbb{Z}_{\geq 1}$, $|\lambda x_n| \leq |\lambda| K$. So, the sequence $(\lambda x_n)$ is in $\ell^\infty$.
%         \item Let $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ be in $\ell^\infty$. In that case, there exist $K_1, K_2 > 0$ such that for all $n \in \mathbb{Z}_{\geq 1}$, $|x_n| \leq K_1$ and $|y_n| \leq K_2$. In that case, for all $n \in \mathbb{Z}_{\geq 1}$, 
%         \[|x_n + y_n| \leq |x_n| + |y_n| \leq K_1 + K_2.\]
%         So, the sequence $(x_n + y_n)$ is in $\ell^\infty$.
%     \end{itemize}

%     \item The sequence space $c$ is the set of convergent sequences. We show that $c$ is a vector space.
%     \begin{itemize}
%         \item Let $(x_n)_{n=1}^\infty$ be in $c$ and $\lambda \in \mathbb{R}$. In that case, the sequence $x_n \to L$, for some $L \in \mathbb{R}$. Therefore, $\lambda x_n \to \lambda L$. This implies that $(\lambda x_n)$ is in $c$.
%         \item Let $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ be in $c$. In that case, we have $x_n \to L_1$ and $y_n \to L_2$, for some $L_1, L_2 \in \mathbb{R}$. Therefore, $x_n + y_n \to L_1 + L_2$. This implies that $(x_n + y_n)$ is in $c$.
%     \end{itemize}

%     \item The sequence space $c_0$ is the set of convergent sequences that converge to $0$. We show that $c_0$ is a vector space.
%     \begin{itemize}
%         \item Let $(x_n)_{n=1}^\infty$ be in $c_0$ and $\lambda \in \mathbb{R}$. In that case, the sequence $x_n \to 0$. Therefore, $\lambda x_n \to 0$. This implies that $(\lambda x_n)$ is in $c_0$.
%         \item Let $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ be in $c$. In that case, we have $x_n \to 0$ and $y_n \to 0$. Therefore, $x_n + y_n \to 0$. This implies that $(x_n + y_n)$ is in $c_0$.
%     \end{itemize}

%     \item Finally, the sequence space $c_{00}$ is the set of convergent sequences $(x_n)_{n=1}^\infty$ such that there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $x_n = 0$.\sidefootnote{That is, it is the set of sequences that eventually become 0.} We show that $c_{00}$ is a vector space.
%     \begin{itemize}
%         \item Let $(x_n)_{n=1}^\infty$ be in $c_{00}$ and $\lambda \in \mathbb{R}$. In that case, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $x_n = 0$. So, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $\lambda x_n = 0$. So, $(\lambda x_n)$ is in $c_{00}$.
%         \item Let $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ be in $c_{00}$. In that case, there exist $N_1, N_2 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_1$, then $x_n = 0$, and if $n \geq N_2$, then $y_n = 0$. So, set $N = \max(N_1, N_2)$. Then, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $x_n + y_n = 0$. This implies that $(x_n + y_n)$ is in $c_{00}$.
%     \end{itemize}
% \end{itemize}

% The following is the containment relationship between the sequence spaces:
% \[c_{00} \subseteq c_0 \subseteq c \subseteq \ell^\infty.\]
% Moreover, the quotient vector space $c/c_0$ is isomorphic to $\mathbb{R}$- this is because the relation $\sim$ on $c$ given by 
% \[(x_n) \sim (y_n) \iff (x_n) \text{ and } (y_n) \text{ converge to the same limit}\]
% corresponds to $x_n - y_n \to 0$, i.e. $(x_n - y_n)$ in $c_0$. In other words, it is the kernel of the surjective vector space homomorphism $v\colon c \to \mathbb{R}$ where $v(x) = L$, with $x_n \to L$. Then, the result follows from the first isomorphism theorem.

% Now, let $p \in [1, \infty)$. We will place $\ell^p$ in the containment relationship. Let $(x_n)_{n=1}^\infty$ be in $\ell^p$. We know that the series
% \[\sum_{n=1}^\infty |x_n|^p\]
% converges. In that case, we have $|x_n|^p \to 0$. Therefore, $x_n \to 0$. So, $\ell^p \subseteq c_0$. However, $\ell^p \not\subseteq c_{00}$ since there are infinite sums that converge. So, we have $c_{00} \subseteq \ell^p \subseteq c_0$.

% Next, let $p, q \in [1, \infty)$ with $p < q$. We show that $\ell^p \subseteq \ell^q$. We start with a lemma.
% \begin{lemma}
%     Let $p \in [1, \infty)$, and let $(x_n)_{n=1}^\infty$ be in $\ell^p$. Then, $\lVert x \rVert_\infty \leq \lVert x \rVert_p$.
% \end{lemma}
% \begin{proof}
%     Let $\varepsilon > 0$. Since
%     \[\lVert x \rVert_\infty = \sup_{n=1}^\infty |x_n|,\]
%     we can find a $k \in \mathbb{Z}_{\geq 1}$ such that $|x_k| \geq \lVert x \rVert_\infty - \varepsilon$. In that case,
%     \[\lVert x \rVert_p = \left(\sum_{n=1}^\infty |x_n|^p\right)^{1/p} \geq (|x_k|^p)^{1/p} = |x_k| \geq \lVert x \rVert_\infty - \varepsilon.\]
%     So, for all $\varepsilon > 0$, $\lVert x \rVert_p \geq \lVert x \rVert_\infty - \varepsilon$. In that case, we must have $\lVert x \rVert_\infty \leq \lVert x \rVert_p$.
% \end{proof}
% Now, we prove that $\ell^p \subseteq \ell^q$.
% \begin{proposition}
%     Let $p, q \in [1, \infty)$ with $p < q$. Then, $\ell^p \subseteq \ell^q$.
% \end{proposition}
% \begin{proof}
%     Let $(x_n)_{n=1}^\infty$ be in $\ell^p$. We find that
%     \begin{align*}
%         \lVert x \rVert_q^q &= \sum_{n=1}^\infty |x_n|^q \\
%         &= \sum_{n=1}^\infty |x_k|^p \cdot |x_n|^{q-p} \\
%         &\leq \sum_{n=1}^\infty |x_n|^p \cdot \lVert x \rVert_\infty^{q-p} \\
%         &= \lVert x \rVert_\infty^{q-p} \sum_{n=1}^\infty |x_n|^p \\
%         &= \lVert x \rVert_\infty^{q-p} \lVert x \rVert_p^p \\ 
%         &= \lVert x \rVert_p^{q-p} \lVert x \rVert_p^p \\
%         &= \lVert x \rVert_p^q.
%     \end{align*}
%     This implies that $\lVert x \rVert_q \leq \lVert x \rVert_p$. So, $(x_n)$ is in $\ell^q$. Therefore, $\ell^p \subseteq \ell^q$.
% \end{proof}
% Finally, we have the complete characterisation of the containment:
% \[c_{00} \subseteq \ell^1 \subseteq \ell^2 \subseteq \dots \subseteq c_0 \subseteq c \subseteq \ell^\infty.\]
% At each level, the containment is strict.
% \newpage

% \section{Topology of vector spaces}
% \subsection{Compactness}
% We know that a subspace $A \subseteq \mathbb{R}^n$ is compact if and only if $A$ is closed and bounded. This does not hold in sequence spaces, under any norm. First, we consider the $\ell_\infty$ norm. Let
% \[A = \{(x_n) \in \ell^\infty \mid \lVert x \rVert_\infty \leq 1\}.\]
% This is a closed space since the norm map is continuous. Moreover, it is bounded by the triangle inequality. However, we claim that the space is not compact. To see this, let $(e_k)_{k=1}^\infty$ be a sequence in $\ell^\infty$ given by
% \[e_k = \begin{cases}
%     0 & n \neq k \\
%     1 & n = k
% \end{cases}.\]
% By definition, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m \neq n$, then $\lVert e_m - e_n \rVert_\infty = 1$. This implies that any subsequence cannot be Cauchy, and so is not convergent. Therefore, $A$ is not sequentially compact. Since the topology on $A$ is induced by a metric, this further implies that $A$ is not compact. This is true for other norms as well.
% % TODO: Give counterexample in \ell^p for p \in [1, \infty)


% \begin{definition}
%     Let $X$ be a real vector space, and let $(f_n)_{n=1}^\infty$ be a sequence of functions $f_n\colon X \to \mathbb{R}$, and let $f\colon X \to \mathbb{R}$. We say that \emph{$(f_n)$ converges to $f$ pointwise} if for all $x \in X$, $f_n(x) \to f(x)$. In other words, for every $x \in X$ and $\varepsilon > 0$, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|f_n(x) - f(x)| < \varepsilon$.
% \end{definition}

% \begin{definition}
%     Let $X$ be a real vector space, and let $(f_n)_{n=1}^\infty$ be a sequence of functions $f_n\colon X \to \mathbb{R}$, and let $f\colon X \to \mathbb{R}$. We say that \emph{$(f_n)$ converges to $f$ uniformly} if for every $\varepsilon > 0$, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $x \in X$ and $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|f_n(x) - f(x)| < \varepsilon$.
% \end{definition}

% \begin{proposition}
%     Let $X$ be a normed vector space, and let $(f_n)_{n=1}^\infty$ be a sequence of continuous functions $f_n\colon X \to \mathbb{R}$, and let $f\colon X \to \mathbb{R}$ such that $f_n \to f$ uniformly. Then, $f$ is continuous.
% \end{proposition}
% \begin{proof}
%     Let $x \in X$ and $\varepsilon > 0$. Since $f_n \to f$ uniformly, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$ and $a \in X$, if $n \geq N$, then $|f_n(a) - f(a)| < \frac{\varepsilon}{3}$. Moreover, since $f_N$ is continuous, we can find a $\delta > 0$ such that for $y \in X$, if $\lVert x - y \rVert < \delta$, then $|f_N(x) - f_N(y)| < \frac{\varepsilon}{3}$. In that case, for $y \in X$, if $\lVert x - y \rVert < \delta$, then
%     \begin{align*}
%         |f(x) - f(y)| &\leq |f(x) - f_N(x)| + |f_N(x) - f_N(y)| + |f_N(y) - f(y)| \\
%         &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
%     \end{align*}
%     This implies that $f$ is continuous.
% \end{proof}

% % TODO: Counterexample for pointwise convergence- f_n(x) = x^n

% \begin{definition}
%     Let $K \subseteq C[0, 1]$. We say that $K$ is \emph{equi-continuous} if for all $\varepsilon > 0$, there exists a $\delta > 0$ such that for all $f \in K$ and $s, t \in [0, 1]$, if $|s - t| < \delta$, then $|f(s) - f(t)| < \varepsilon$.
% \end{definition}

% \begin{theorem}[Arzela-Ascoli]
%     Let $K \subseteq C[0, 1]$. Then, $K$ is compact if and only if $K$ is closed, bounded and equi-continuous, under the $L_\infty$ norm.
% \end{theorem}
% \begin{proof}
%     \hspace*{0pt}
%     \begin{itemize}
%         \item First, assume that $K$ is compact. We know that $K$ is closed and bounded. We show that $K$ is equi-continuous. So, let $\varepsilon > 0$. We know that $(B_K(f, \frac{\varepsilon}{3}))_{f \in K}$ is an open cover of $K$. So, it has a finite subcover $(B_K(f_i, \frac{\varepsilon}{3}))_{i=1}^n$. For $i \in \{1, 2, \dots, n\}$, we can find a $\delta_i > 0$ such that for $s, t \in [0, 1]$, if $|s - t| < \delta$, then $|f_i(s) - f_i(t)| < \frac{\varepsilon}{3}$. Set $\delta = \min_{i=1}^n \delta_i$. Now, let $g \in K$. We can find a $j \in \{1, 2, \dots, n\}$ such that
%         \[g \in B_K(f_j, \tfrac{\varepsilon}{3}).\]
%         In that case, $\lVert f_j - g \rVert_\infty < \frac{\varepsilon}{3}$. So, for all $x \in [0, 1]$, $|f_j(x) - g(x)| < \frac{\varepsilon}{3}$. Now, for $s, t \in [0, 1]$, if $|s - t| < \delta$, then
%         \begin{align*}
%             |g(s) - g(t)| &\leq |g(s) - f_j(s)| + |f_j(s) - f_j(t)| + |f_j(t) - g(s)| \\
%             &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
%         \end{align*}
%         So, $K$ is equi-continuous.
        
%         \item Now, assume that $K$ is closed, bounded and equi-continuous. Let $(f_n)_{n=1}^\infty$ be a sequence in $K$. We show that $(f_n)$ has a convergent subsequence. 
%         % TODO: Write up (at some pt)
%     \end{itemize}
% \end{proof}

% \subsection{Separability}
% \begin{definition}
%     Let $X$ be a metric space. We say that $X$ is \emph{separable} if it contains a countable dense subset.
% \end{definition}

% We know that $\mathbb{R}$ is separable- $\mathbb{Q}$ is a countable dense subset of $\mathbb{R}$. In general, $\mathbb{Q}^n$ is a countable dense subset of $\mathbb{R}^n$.

% \begin{proposition}
%     The sequence space $\ell^\infty$ is not separable.
% \end{proposition}
% \begin{proof}
%     Let $C \subseteq \mathbb{Z}_{\geq 1}$. Define the sequence $(x^C_n)_{n=1}^\infty$ in $\mathbb{R}$ by 
%     \[x^C_n = \begin{cases}
%         1 & n \in C \\
%         0 & n \not\in C
%     \end{cases}.\]
%     We have $(x_n)$ in $\ell^\infty$. Moreover, for $P, Q \subseteq \mathbb{N}$ with $P \neq Q$, $\lVert x^P - x^Q \rVert_\infty = 1$. In that case,
%     \[B_{\ell^\infty}(x^P, \tfrac{1}{2}) \cap B_{\ell^\infty}(x^Q, \tfrac{1}{2}) = \varnothing.\]
%     So, the set
%     \[S = \{x^C \mid C \subseteq \mathbb{Z}_{\geq 1}\}\]
%     is not dense in $\ell^\infty$- 
%     % TODO: Show that there exists an open set in \ell^\infty such that \ell^\infty \cap S is empty- give a sequence that is halfway?
%     % TODO: Understand better the proof
% \end{proof}

% % TODO: X_1, X_2 separable => X_1 * X_2 separable 
% % TODO: X countable union of separable spaces => separable (e.g. c00 separable)
% % TODO: Subset of separable metric space => separable (e.g. [0, 1])
% % TODO: Closure of separable is separable (e.g. c0 separable)

% % TODO: C[0, 1] is separable
% \begin{proposition}
%     The function space $C[0, 1]$ is separable.
% \end{proposition}
% \begin{proof}
%     We show that polynomials is a countable subset in $C[0, 1]$. The space of polynomials is the union of polynomials of degree $n$, for all $n \in \mathbb{Z}_{\geq 1}$. The polynomials of degree $n$ are isomorphic to $\mathbb{R}^{n+1}$ as vector spaces. So, the space of polynomials is countable. Moreover, the space of polynomials is dense- we will not prove this. For this reason, $C[0, 1]$ is separable.
% \end{proof}
% % \begin{proof}[Alternate Proof]
%     % TODO: ADD
% % \end{proof}

% \subsection{Completeness}
% \begin{definition}
%     Let $V$ be a normed vector space such that the metric induced by the norm is complete. Then, we say that $V$ is a \emph{Banach space}.
% \end{definition}

% \begin{definition}
%     Let $V$ be a inner product space such that the metric induced by the norm is complete. Then, we say that $V$ is a \emph{Hilbert space}.
% \end{definition}

% The sequence space $c_{00}$ is not complete. Consider the sequence $(x^{(n)})_{n=1}^\infty$ in $c_{00}$, given by
% \[x^{(n)} = (1, \tfrac{1}{2}, \tfrac{1}{3}, \dots, \tfrac{1}{n}, 0, 0, \dots).\]
% Under the $\ell_\infty$ norm, this sequence converges to
% \[x = (1, \tfrac{1}{2}, \tfrac{1}{3}, \dots)\]
% since
% \[\lVert x^{(n)} - x \rVert_\infty = \lVert (0, 0, \dots, 0, -\tfrac{1}{n+1}, -\tfrac{1}{n+2}, \dots) \rVert_\infty = \tfrac{1}{n+1} \to 0.\]
% But, the sequence $x$ is not in $c_{00}$ since it is not eventually $0$. So, $(x^{(n)})$ is Cauchy in $c_{00}$ but not convergent- it is not complete.

% However, this is not the case for $\ell^\infty$.
% \begin{proposition}
%     The sequence space $\ell^\infty$ is complete.
% \end{proposition}
% \begin{proof}
%     Let $(x^{(n)})_{n=1}^\infty$ be a Cauchy sequence in $\ell^\infty$. For $k \in \mathbb{Z}_{\geq 1}$, we have the sequence $(x^{(n)}_k)_{n=1}^\infty$ in $\mathbb{R}$. We claim that $(x^{(n)}_k)$ is Cauchy in $\mathbb{R}$. Let $\varepsilon > 0$. Since $(x^{(n)})$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then
%     \[\lVert x^{(n)} - x^{(m)} \rVert_\infty < \varepsilon.\]
%     In that case,
%     \[|x_k^{(n)} - x_k^{(m)}| \leq \sup_{i=1}^\infty |x_i^{(n)} - x_i^{(m)}| = \lVert x^{(n)} - x^{(m)} \rVert_\infty < \varepsilon.\]
%     So, $(x_k^{(n)})$ is Cauchy in $\mathbb{R}$. Since $\mathbb{R}$ is complete, there exists an $x_k \in \mathbb{R}$ such that $x_k^{(n)} \to x_k$. So, we can construct the sequence $(x_k)_{k=1}^\infty$ in $\mathbb{R}$, where $x_k^{(n)} \to x_k$ for $k \in \mathbb{Z}_{\geq 1}$.

%     \noindent First, we claim that $(x_k)$ is in $\ell^\infty$. Since $(x^{(n)})$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert x^{(m)} - x^{(n)} \rVert_\infty < 1$. In particular, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $|x^{(m)}_k - x^{(n)}_k| < 1$ for all $k \in \mathbb{Z}_{\geq 1}$. Since $x^{(N)}$ is in $\ell^\infty$, there exists a $K > 0$ such that for all $k \in \mathbb{Z}_{\geq 1}$, $|x_k^{(N)}| \leq K$. Now, let $k \in \mathbb{Z}_{\geq 1}$. Since $x_k^{(n)} \to x_k$, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N'$, then $|x_k - x_k^{(n)}| < 1$. Now, fix $n = \max(N, N')$. In that case,
%     \[|x_k| \leq |x_k - x_k^{(n)}| + |x_k^{(n)} - x_k^{(N)}| + |x_k^{(N)}| \leq 2 + K.\]
%     So, $(x_k)$ is in $\ell^\infty$.

%     \noindent Now, we claim that $x^{(n)} \to x$ under the $\ell_\infty$ metric. Let $\varepsilon > 0$. Since $(x^{(n)})$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert x^{(m)} - x^{(n)} \rVert_\infty < \frac{\varepsilon}{3}$. In particular, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $|x^{(m)}_k - x^{(n)}_k| < \frac{\varepsilon}{3}$ for all $k \in \mathbb{Z}_{\geq 1}$. Now, let $n \in \mathbb{Z}_{\geq 1}$ with $n \geq N$. Moreover, let $k \in \mathbb{Z}_{\geq 1}$. Since $x_k^{(n)} \to x_k$, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N'$, then $|x_k^{(n)} - x_k| < \frac{\varepsilon}{3}$. Now, fix $m = \max(N, N')$. Then, 
%     \[|x_k^{(n)} - x_k| \leq |x_k^{(n)} - x_k^{(m)}| + |x_k^{(m)} - x_k| < \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \frac{2}{3}\varepsilon.\]
%     Therefore, for all $k \in \mathbb{Z}_{\geq 1}$, $|x_k^{(n)} - x_k| < \frac{2}{3}\varepsilon$. By the supremum property, this implies that
%     \[\lVert x^{(n)} - x \rVert_\infty \leq \frac{2}{3}\varepsilon < \varepsilon.\]
%     So, for all $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%     \[\lVert x^{(n)} - x \rVert_\infty < \varepsilon.\]
%     This implies that $x^{(n)} \to x$. Therefore, $\ell^\infty$ is complete.
% \end{proof}
% \noindent Using this, we can show that $c$ is complete.
% \begin{proposition}
%     The sequence space $c \subseteq \ell^\infty$ is closed.
% \end{proposition}
% \begin{proof}
%     Let $(x^{(n)})_{n=1}^\infty$ be a convergent sequence in $c$ with $x^{(n)} \to x$, for some $x$ in $\ell^\infty$. We show that $x$ is Cauchy. Let $\varepsilon > 0$. Since $x^{(n)} \to x$, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $\lVert x^{(n)} - x \rVert_\infty < \frac{\varepsilon}{3}$. In particular, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|x^{(n)}_k - x_k| < \frac{\varepsilon}{3}$ for all $k \in \mathbb{Z}_{\geq 1}$. Since $x^{(N)}$ is in $c$, we know that $x^{(N)}$ is Cauchy. In that case, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N'$, then $|x^{(N)}_m - x^{(N)}_n| < \frac{\varepsilon}{3}$. Therefore, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N'$, then 
%     \[|x_m - x_n| \leq |x_m - x_m^{(N)}| + |x_m^{(N)} - x_n^{(N)}| + |x_n^{(N)} - x_n| < \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.\]
%     This implies that $x$ is Cauchy. Since $x$ is a sequence in $\mathbb{R}$, we find that $x$ is in $c$. So, $c$ is closed.
% \end{proof}
% \noindent This shows that $c$ is complete- it is a closed subset of a complete space. 

% We use a similar approach to show that $c_0$ is complete.
% \begin{proposition}
%     The sequence space $c_0 \subseteq c$ is closed.
% \end{proposition}
% \begin{proof}
%     Let $(x^{(n)})_{n=1}^\infty$ be a convergent sequence in $c_0$ with $x^{(n)} \to x$, for some $x$ in $c$. We show that $x_k \to 0$. Let $\varepsilon > 0$. Since $x^{(n)} \to x$, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $\lVert x^{(n)} - x \rVert_\infty < \frac{\varepsilon}{2}$. In particular, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then $|x^{(n)}_k - x_k| < \frac{\varepsilon}{2}$ for all $k \in \mathbb{Z}_{\geq 1}$. Since $x^{(N)}$ is in $c_0$, we find that $x^{(N)} \to 0$. In that case, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $k \in \mathbb{Z}_{\geq 1}$, if $k \geq N'$, then $|x^{(N)}_k| < \frac{\varepsilon}{2}$. In that case, for all $k \in \mathbb{Z}_{\geq 1}$, if $k \geq N'$, then
%     \[|x_k| \leq |x_k - x_k^{(N)}| + |x_k^{(N)}| < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.\]
%     This implies that $x_k \to 0$. So, $x$ is in $c_0$, i.e. $c_0$ is closed.
% \end{proof}

% Finally, we show that $C[0, 1]$ is complete.
% \begin{proposition}
%     The function space $C[0, 1]$ is complete.
% \end{proposition}
% \begin{proof}
%     Let $(f_n)_{n=1}^\infty$ be a Cauchy sequence in $C[0, 1]$. For $x \in [0, 1]$, the sequence $(f_n(x))_{n=1}^\infty$ is a sequence in $\mathbb{R}$. We show that $(f_n(x))$ is Cauchy. Let $\varepsilon > 0$. Since $(f_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert f_m - f_n \rVert_\infty < \varepsilon$. In that case, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then 
%     \[|f_m(x) - f_n(x)| \leq \sup_{y \in [0, 1]} |f_m(y) - f_n(y)| = \lVert f_m - f_n \rVert_\infty < \varepsilon.\]
%     This implies that $(f_n(x))$ is Cauchy in $\mathbb{R}$. Since $\mathbb{R}$ is complete, there exists an $f_x \in \mathbb{R}$ such that $f_n(x) \to f_x$. So, we can construct the function $f\colon [0, 1] \to \mathbb{R}$ by $f(x) = f_x$.

%     \noindent First, we claim that $f$ is in $C[0, 1]$. Let $x \in [0, 1]$, and $\varepsilon > 0$. Since $(f_n)$ is Cauchy, we can find an $N_1 \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N_1$, then $\lVert f_m - f_n \rVert_\infty < \frac{\varepsilon}{5}$. In particular, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N_1$, then $|f_m(y) - f_n(y)| < \frac{\varepsilon}{5}$ for all $y \in [0, 1]$. Since $f_{N_1}$ is in $C[0, 1]$, we can find a $\delta > 0$ such that for $y \in [0, 1]$, if $|x - y| < \delta$, then $|f_{N_1}(x) - f_{N_1}(y)| < \frac{\varepsilon}{5}$. Since $f_n(x) \to f(x)$, we can find an $N_2 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_2$, then $|f_n(x) - f(x)| < \frac{\varepsilon}{5}$. Set $N = \max(N_1, N_2)$. Next, let $y \in [0, 1]$ with $|x - y| < \delta$. Since $f_n(y) \to f(y)$, we can find an $N_3 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_3$, then $|f_n(y) - f(y)| < \frac{\varepsilon}{5}$. Set $M = \max(N_1, N_3)$. Therefore,
%     \begin{align*}
%         |f(x) - f(y)| &\leq |f(x) - f_N(x)| + |f_N(x) - f_{N_1}(x)| + |f_{N_1}(x) - f_{N_1}(y)| \\
%         &+ |f_{N_1}(y) - f_M(y)| + |f_M(y) - f(y)| \\
%         &< \frac{\varepsilon}{5} + \frac{\varepsilon}{5} + \frac{\varepsilon}{5} + \frac{\varepsilon}{5} + \frac{\varepsilon}{5} = \varepsilon.
%     \end{align*}
%     That is, for all $y \in [0, 1]$, if $|x - y| < \delta$, then $|f(x) - f(y)| < \varepsilon$. This implies that $f$ is in $C[0, 1]$.

%     \noindent Now, we claim that $f_n \to f$ under the $\ell_\infty$ metric. Let $\varepsilon > 0$. Since $(f_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, then $\lVert f_m - f_n \rVert_\infty < \frac{\varepsilon}{3}$. In particular, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $|f_m(x) - f_n(x)| < \frac{\varepsilon}{3}$ for all $x \in [0, 1]$. Now, let $n \in \mathbb{Z}_{\geq 1}$ with $n \geq N$. Moreover, let $x \in [0, 1]$. Since $f_n(x) \to f(x)$, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N'$, then $|f_n(x) - f(x)| < \frac{\varepsilon}{3}$. Now, fix $m = \max(N, N')$. Then,
%     \[|f_n(x) - f(x)| \leq |f_n(x) - f_m(x)| + |f_m(x) - f(x)| < \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \frac{2}{3} \varepsilon.\]
%     Therefore, for all $x \in [0, 1]$, $|f_n(x) - f(x)| < \frac{2}{3} \varepsilon$. By the supremum property, this implies that
%     \[\lVert f_n - f \rVert_\infty \leq \frac{2}{3} \varepsilon < \varepsilon.\]
%     So, for all $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%     \[\lVert f_n - f \rVert_\infty < \varepsilon.\]
%     This implies that $f_n \to f$ in $\ell^\infty$. Therefore, $C[0, 1]$ is complete.
% \end{proof}

\end{document}
