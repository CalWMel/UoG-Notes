\documentclass[a4paper, openany]{memoir}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage[english]{babel}

\usepackage{fancyhdr}
\usepackage{float}
\usepackage{bm}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage[bookmarksopen=true,bookmarksopenlevel=2]{hyperref}
\usepackage{tikz}
\usepackage{indentfirst}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE]{\leftmark}
\fancyhead[RO]{\rightmark}
\fancyhead[RE, LO]{Functional Analysis}
\fancyfoot[LE, RO]{\thepage}
\fancyfoot[RE, LO]{Pete Gautam}

\renewcommand{\headrulewidth}{1.5pt}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{example}[definition]{Example}

\chapterstyle{thatcher}
\setcounter{chapter}{2}

\begin{document}
    \chapter{Functional Analysis Proper}
    \section{More on $L^p$ spaces}
    In this section, we will consider $L^p$ spaces again and show that they are Banach spaces. Moreover, we show that $L^2$ is a Hilbert space.

    First, we characterise completeness in terms of absolute convergence.
    \begin{definition}
        Let $(V, \lVert \cdot \rVert)$ be a normed vector space, and let $(x_n)_{n=1}^\infty$ be a sequence in $V$. We say that the series $\sum x_n$ is \emph{absolutely convergent} if the series $\sum \lVert x_n \rVert$ converges.
    \end{definition}
    \begin{proposition}
        Let $(V, \lVert \cdot \rVert)$ be a normed vector space. Then, $V$ is complete if and only if every absolutely convergent series $\sum x_n$ in $V$ is convergent.
    \end{proposition}
    \begin{proof}
        First, assume that $V$ is complete. Let $(x_n)_{n=1}^\infty$ be a sequence in $V$ such that the series $\sum x_n$ is absolutely convergent. We show that the series $\sum x_n$ is Cauchy. Let $\varepsilon > 0$. Since the series $\sum \lVert x_n \rVert$ is convergent, it is Cauchy. Hence, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
        \[\left|\sum_{k=1}^{m} \lVert x_k \rVert - \sum_{k=1}^{n} \lVert x_k \rVert \right| = \sum_{n=k}^{l} \lVert x_n \rVert < \varepsilon.\]
        So, for $k, l \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
        \[\left\lVert\sum_{k=1}^{m} x_k - \sum_{k=1}^{n} x_k\right\rVert = \left\lVert \sum_{k=m}^{n} x_k \right\rVert \leq \sum_{k=m}^{n} \lVert x_n \rVert < \varepsilon.\]
        Hence, the series $\sum x_n$ is Cauchy. Since $V$ is complete, this implies that $\sum x_n$ is convergent.

        Now, assume that every absolutely convergent series is convergent. Let $(x_n)_{n=1}^\infty$ be a Cauchy sequence in $V$. We show that $(x_n)$ has a convergent subsequence. Since $(x_n)$ is Cauchy, for each $j \in \mathbb{Z}_{\geq 0}$, we can find an $n_j \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq n_j$, then 
        \[\lVert x_m - x_n \rVert < 2^{-j}.\]
        We can choose $n_{j+1} > n_j$ for all $j \in \mathbb{Z}_{\geq 1}$. Then, $(x_{n_j})_{j=1}^\infty$ is a subsequence of $(x_n)$. Next, define the sequence $(y_k)_{k=1}^\infty$ in $V$ by $y_1 = x_{n_1}$ and $y_k = x_{n_k} - x_{n_{k-1}}$ for $k \geq 2$. Then, for $l \in \mathbb{Z}_{\geq 1}$, we have
        \[\sum_{k=1}^l y_k = x_{n_1} + (x_{n_2} - x_{n_1}) + \dots + (x_{n_l} - x_{n_l-1}) = x_{n_l}.\]
        Moreover,
        \[\left\lVert \sum_{k=1}^\infty y_k \right\rVert = \lVert x_1 \rVert + \sum_{j=1}^\infty \lVert x_{n_j} - x_{n_{j-1}} \rVert \leq \lVert x_1 \rVert + \sum_{j=1}^{\infty} 2^{-j} = 1 + \lVert x_1 \rVert,\]
        meaning that $\sum y_k$ is absolutely convergent. By assumption, this implies that $\sum y_k$ is convergent. Hence, the subsequence $(x_{n_j})_{j=1}^\infty$ is convergent. Since the sequence $(x_n)$ is Cauchy, we conclude that $(x_n)$ converges. Hence, $V$ is complete.
    \end{proof}
    \begin{proposition}
        Let $p \in [1, \infty)$. Then, the $L^p$ space is complete.
    \end{proposition}
    \begin{proof}
        Let $(f_n)_{n=1}^\infty$ be sequence in $L^p$ such that the series $\sum f_n$ is absolutely convergent, to some $B \in \mathbb{R}$. Define the sequence of functions $(F_n)_{n=1}^\infty$ in $L^p$ by
        \[G_n = \sum_{k=1}^n |f_k|,\]
        and let $G = \sum_{k=1}^{\infty} |f_k|$. We have $G_n \geq 0$ and measurable since $f_k$ are measurable, with $G_n \to G$ pointwise. Moreover,
        \[\lVert G_n \rVert_p^p = \sum_{k=1}^\infty |f|^p \leq \sum_{k=1}^n \lVert f_k \rVert_p^p \leq B^p < \infty.\]
        This implies that $G_n \in L^p$. Now, Monotone Convergence Theorem tells us that 
        \[\int_{\mathbb{R}} |G|^p \ d\mu = \lim_{n \to \infty} \int_{\mathbb{R}} |G_n|^p \ d\mu \leq B^p < \infty.\]
        Hence, $G \in L^p$. So, $G(x)$ is finite for almost all $x \in \mathbb{R}$. That is, the series
        \[\sum_{k=1}^\infty f_k(x) = G(x)\]
        converges for almost all $x \in \mathbb{R}$. Since $\mathbb{R}$ is complete, we can find a function $F$ such that $\sum_{k=1}^\infty f_k \to F$ pointwise. Since $|F| \leq G$ and $G \in L^p$, we find that $F \in L^p$.

        Now, we note that $|F| \leq G^p$ and $\sum_{k=1}^{n} f_k \leq G^p$, meaning that
        \[\left|F - \sum_{k=1}^{n} f_k\right|^p \leq (2G)^p\]
        for all $n \in \mathbb{Z}_{\geq 1}$. We know that $G \in L^p$, meaning that
        \[\int_{\mathbb{R}} G^p \ d\mu < \infty.\]
        So, $G^p \in L^1$. So, we can apply Dominated Convergence Theorem to conclude that
        \[\lim_{n \to \infty} \int_{\mathbb{R}} \left|F - \sum_{k=1}^{n} f_k\right|^p \ d\mu = \int_{\mathbb{R}} \lim_{n \to \infty} \left|F - \sum_{k=1}^{n} f_k\right|^p \ d\mu.\]
        By construction, we have $\sum_{k=1}^\infty f_k \to F$ pointwise, so
        \[\int_{\mathbb{R}} \lim_{n \to \infty} \left|F - \sum_{k=1}^{n} f_k\right|^p \ d\mu = 0.\]
        This means that $\sum_{k=1}^\infty f_k \to F$ in $L^p$. Hence, every absolutely convergent sequence is convergent. We conclude that $L^p$ space is complete.
    \end{proof}

    We can consider measures on probability spaces as well. We say that a measure space on $[0, 1]$ is a probability, then $\mu [0, 1] = 1$. Then, we have $L^p[0, 1] \subseteq L^1[0, 1]$. More generally, for $p > 1$, $L^p[0, 1] \subseteq L[0, 1]$. This follows from Holder's Inequality: 

    \begin{proposition}
        Let $P$ be a probability space.
        % TODO: Finish
    \end{proposition}
    \begin{proof}
        Let $f \in L^p[0, 1]$ and $g = 1$ on $[0, 1]$. Then, by Holder Inequality, we find that 
        \[\lVert f \rVert_1 = \lVert f \cdot 1 \rVert_1 \leq \lVert f \rVert_p \lVert 1 \rVert_p = \lVert f \rVert_p.\]
        Hence, if $f \in L^p[0, 1]$, $f \in L^1[0, 1]$.
    \end{proof}
    \noindent Note that the result does not follow in $\mathbb{R}$, since $\lVert 1 \rVert_p = \infty$. Also, each inclusion is strict, e.g. $\frac{1}{\sqrt{x}}$ is in $L^2[0, 1]$ but not in $L^1[0, 1]$. We can generalise this to show that for $1 \leq p \leq q$, $L^q[0, 1] \subseteq L^p[0, 1]$, and the inclusion is strict if $p < q$.
    % \begin{align*}
    %     \lVert f \rVert_p^p &= \int_{[0, 1]} |f|^p \lVert  \rVert_1 \\
    %     &\leq \lVert f \rVert^p_{q/p} \cdot \lVert 1 \rVert_{q/(q - p)} \\
    %     &= \left(\int_{[0, 1]} |f|^{p} \ d\mu \right)^{q/p} \\
    %     &= \left(\int_{[0, 1]} |f|^q\right)^{1/q\cdot p}.
    % \end{align*}
    \newpage

    \section{Linear Operators}
    In this section, we will consider linear operators in more detail and do analysis on them. The concept of a linear operator is the same as a linear function, but being bounded as a linear operator has a different meaning.
    \begin{definition}
        Let $V$ and $W$ be normed spaces, and let $T \colon V \to W$ be a function. We say that $T$ is \emph{linear} (or an \emph{operator}) if for all $v_1, v_2 \in V$ and $T(v_1 + v_2) = T(v_1) + T(v_2)$ and for all $v \in V$ and $c \in \mathbb{R}$, $T(cv) = cTv$. We say that $T$ is \emph{bounded} if there exists a $c \geq 0$ such that for all $v \in V$, $\lVert Tv \rVert_V \leq c\lVert v \rVert_W$. The set of bounded functions $V \to W$ is denoted by the set $L(V, W)$.
    \end{definition}

    In finite dimensions, every linear function is bounded.
    \begin{proposition}
        Let $V$ and $W$ be vector spaces such that $V$ is finite-dimensional, and let $T \colon V \to W$ be linear. Then, $T$ is bounded.
    \end{proposition}
    \begin{proof}
        Let the basis of $V$ be: $\{v_1, v_2, \dots, v_n\}$. For each $1 \leq i \leq n$, there exists a $c_i > 0$ such that $\lVert Tv_i \rVert \leq c_i \lVert v_i \rVert$. Set $c = \min(c_1, c_2, \dots, c_n)$. By construction, we have $\lVert Tv_i \rVert \leq c \lVert v_i \rVert$ for $1 \leq i \leq n$. Now, let $v \in V$. In that case, there exist $\alpha_i \in \mathbb{R}$ for $1 \leq i \leq n$ such that 
        \[v = \alpha_1 v_1 + \alpha_2 v_2 + \dots + \alpha_n v_n.\]
        Hence,
        % TODO: Complete
        % \begin{align*}
        %     \lVert Tv \rVert &= \lVert T (\alpha_1 v_1) + T (\alpha_2 v_2) + \dots + T (\alpha_n v_n) \rVert \\
        %     &\leq \lVert \alpha_1 T v_1 \rVert + \lVert \alpha_2 T v_2 \rVert + \dots + \lVert \alpha_n T v_n \rVert \\
        %     &\leq |\alpha_1| \lVert T v_1 \rVert + |\alpha_2| \lVert T v_2 \rVert + \dots + |\alpha_n| \lVert T v_n \rVert \\
        %     &\leq c \cdot |\alpha_1| \lVert v_1 \rVert + c \cdot |\alpha_2| \lVert v_2 \rVert + \dots + c \cdot |\alpha_n| \lVert v_n \rVert \\
        %     &= 
        % \end{align*}
    \end{proof}
    % TODO: Infinite dimension => not bounded

    This result does not hold in infinite dimensions. To see this, define the function $T \colon \ell^\infty \to \ell^\infty$ by $T(e_n) = ne_n$ extended linearly. This is linear, but not bounded. In particular, for all $n \in \mathbb{Z}_{\geq 1}$,
    \[\lVert Te_{n+1} \rVert = (n+1) \lVert e_{n+1} \rVert > n+1 = (n + 1) \lVert e_{n+1} \rVert.\]

    We can define isomorphisms and isometries like in metric spaces for linear operators.
    \begin{definition}
        Let $V$ and $W$ be vector spaces, and let $T \colon V \to W$ be a bounded function. We say that $T$ is an \emph{isomorphism} if $T$ is a bijection with $T^{-1}$ also bounded. We say that $T$ is an \emph{isometry} if for all $v \in V$, $\lVert Tv \rVert = \lVert v \rVert$. If $T$ is both an isometry and isomorphism, then it is called an \emph{isometric isomorphism}.
    \end{definition}
    \begin{lemma}
        Let $V$ and $W$ be vector spaces, and let $T \colon V \to W$ be an isometry. Then, $T$ is injective.
    \end{lemma}
    \begin{proof}
        Let $v_1, v_2 \in V$ with $Tv_1 = Tv_2$. In that case,
        \[\lVert v_1 - v_2 \rVert = \lVert T(v_1 - v_2) \rVert = \lVert Tv_1 - Tv_2 \rVert = 0.\]
        Hence, $v_1 = v_2$. So, $T$ is injective.
    \end{proof}
    \begin{proposition}
        Let $V$ and $W$ be vector spaces, and let $T \colon V \to W$ be a surjective isometry. Then, $T$ is an isometric isomorphism.
    \end{proposition}
    \begin{proof}
        Since $T$ is an isometry, we know that it is injective. So, $T$ is a bijection. Hence, it suffices to show that $T^{-1}$ is bounded. We know that for all $v \in V$,
        \[\lVert Tv \rVert = \lVert v \rVert.\]
        So, for all $w \in W$ with $T^{-1}(w) = v$, we find that
        \[\lVert w \rVert =  \lVert Tv \rVert = \lVert v \rVert = \lVert T^{-1}(w) \rVert.\]
        Hence, $T^{-1}$ is bounded. So, $T$ is an isometric isomorphism.
    \end{proof}

    It turns out that continuity and boundedness are equivalent for linear operators.
    \begin{proposition}
        Let $V$ and $W$ be normed spaces and let $T \colon V \to W$ be a linear operator. Then, the following are equivalent:
        \begin{enumerate}
            \item $T$ is continuous;
            \item $T$ is continuous at $0 \in V$;
            \item $T$ is bounded.
        \end{enumerate}
    \end{proposition}
    \begin{proof}
        \hspace*{0pt}
        \begin{itemize}
            \item[$(1) \implies (2)$] Trivial.
            
            \item[$(2) \implies (3)$] Assume that $T$ is continuous at $0$. In that case, there exists a $\delta > 0$ such that for $v \in V$, if $\lVert v \rVert_V < \delta$, then $\lVert Tv \rVert_W < \varepsilon$. Now, let $v \in V$. If $v = 0$, then 
            \[\lVert Tv \rVert_W = 0 < \frac{2 \varepsilon}{\delta} \lVert v \rVert_V.\]
            Otherwise, let $v' = \frac{\delta}{2 \lVert v \rVert_V} v$. Then,
            \[\lVert v' \rVert_V = \frac{\delta}{2 \lVert v \rVert_V} \lVert v \rVert_v = \frac{\delta}{2} < \delta.\]
            Hence,
            \[\lVert Tv' \rVert_W < \varepsilon \iff \frac{\delta}{2 \lVert v \rVert_V} \lVert Tv \rVert_W < \varepsilon \iff \lVert Tv \rVert_V < \frac{2\varepsilon}{\delta} \lVert v \rVert_V.\]
            So, $T$ is bounded.
            
            \item[$(3) \implies (1)$] Now, assume that $T$ is bounded. In that case, there exists a $c \geq 0$ such that for $v \in V$, $\lVert Tv \rVert_W \leq c \lVert v \rVert_V$. If $c = 0$, then we find that $\lVert Tv \rVert_V = 0$ for all $v \in V$, i.e. $T = 0$. This is a continuous function. Otherwise, let $\varepsilon > 0$. Set $\delta = \varepsilon/c$. In that case, for $v, w \in V$, if $\lVert v - w \rVert_V < \delta$, then 
            \[\lVert Tv - Tw \rVert_W = \lVert T(v - w) \rVert_W \leq c \lVert v - w \rVert_V = \varepsilon.\]
            Hence, $T$ is (uniformly) continuous.
        \end{itemize}
    \end{proof}

    With this result, we can show that the set of bounded functions is a (normed) vector space.
    \begin{proposition}
        Let $V$ and $W$ be normed spaces. Define the function $\lVert \cdot \rVert \colon L(V, W) \to \mathbb{R}_{\geq 0}$ by 
        \[\lVert T \rVert = \sup_{\lVert v \rVert = 1} \lVert Tv \rVert.\]
        Then, $(L(V, W), \lVert \cdot \rVert)$ is a normed vector space.
    \end{proposition}
    \begin{proof}
        We know that the sum and the scalar product of bounded functions is still bounded, so $L(V, W)$ is a vector space. Now, let $T \in L(V, W)$ such that $\lVert T \rVert = 0$. Then, let $v \in V$. If $v = 0$, then we know that $Tv = 0$. Otherwise, we know that $w = v/\lVert v \rVert$ has norm $1$, meaning that $Tw = 0$. Hence, $Tv = 0$, so $T = 0$. Moreover, 
        \[\lVert 0 \rVert = \sup \{0\} = 0.\]
        Now, let $c \in \mathbb{R}$ and $T \in L(V, W)$. Then,
        \[\lVert cT \rVert = \sup_{\lVert v \rVert = 1} \lVert cTv \rVert = \sup_{\lVert v \rVert = 1} |c| \cdot \lVert Tv \rVert = |c| \lVert T \rVert.\]
        Finally, let $T_1, T_2 \in L(V, W)$. Then,
        \begin{align*}
            \lVert T_1 + T_2 \rVert &= \sup_{\lVert v \rVert = 1} \lVert T_1(v) + T_2(v) \rVert \\
            &\leq \sup_{\lVert v \rVert = 1} (\lVert T_1(v) \rVert + \lVert T_2(v) \rVert) \\
            &\leq \sup_{\lVert v \rVert = 1} \lVert T_1(v) \rVert + \sup_{\lVert v \rVert = 1} \lVert T_2(v) \rVert = \lVert T_1 \rVert + \lVert T_2 \rVert.
        \end{align*}
        So, $L(V, W)$ is a normed vector space.
    \end{proof}
    \noindent Moreover, there are many equivalent definitions for the operator norm.
    \begin{proposition}
        Let $V$ and $W$ be vector spaces, and let $T \colon V \to W$ be a bounded function. Then, all of the following expressions are equal to the operator norm $\lVert T \rVert$:
        \begin{enumerate}
            \item $\sup_{\lVert v \rVert = 1} \lVert Tv \rVert$;
            \item $\sup_{\lVert v \rVert \leq 1} \lVert Tv \rVert$;
            \item $\sup_{v \neq 0} \lVert Tv \rVert/\lVert v \rVert$;
            \item $\inf \{c \geq 0 \mid \lVert Tv \rVert \leq c \lVert v \rVert \ \forall v \in V\}$.
        \end{enumerate}
    \end{proposition}
    \begin{proof}
        \hspace*{0pt}
        \begin{enumerate}
            \item[$(1) = (2)$] We know that 
            \[\{\lVert Tv \rVert \mid \lVert v \rVert = 1\} \subseteq \{\lVert Tv \rVert \mid \lVert v \rVert \leq 1\},\]
            in which case 
            \[\sup_{\lVert v \rVert = 1} \lVert Tv \rVert \leq \sup_{\lVert v \rVert \leq 1} \lVert Tv \rVert.\]
            Now, let $v \in V$ with $\lVert v \rVert \leq 1$. If $v = 0$, then $\lVert Tv \rVert = 0 \leq \sup_{\lVert v \rVert = 1} \lVert Tv \rVert$. Otherwise, if $v \neq 0$, then there exists a $c > 0$ such that $\lVert cv \rVert = 1$. Since $\lVert v \rVert \leq 1$, we can further assume that $c \geq 1$. Hence,
            \[\lVert Tv \rVert = \frac{1}{c} \lVert T(cv) \rVert \leq \lVert T(cv) \rVert.\]
            Hence, 
            \[\sup_{\lVert v \rVert \leq 1} \lVert Tv \rVert \leq \sup_{\lVert v \rVert = 1} \lVert Tv \rVert,\]
            meaning that the two values are equal.
            
            \item[$(1) = (3)$] We show that 
            \[\{\lVert Tv \rVert \mid \lVert v \rVert = 1\} = \{\lVert Tv \rVert/\lVert v \rVert \mid v \neq 0\}.\]
            Clearly, if $\lVert v \rVert = 1$, then $\lVert Tv \rVert/\lVert v \rVert = \lVert Tv \rVert$. Hence,
            \[\{\lVert Tv \rVert \mid \lVert v \rVert = 1\} \subseteq \{\lVert Tv \rVert/\lVert v \rVert \mid v \neq 0\}.\]
            Now, let $v \in V$ be non-zero. In that case, let $c = \frac{1}{\lVert v \rVert}$. Then, $\lVert cv \rVert = 1$, with 
            \[\lVert T(cv) \rVert = \lVert Tv \rVert/\lVert v \rVert.\]
            Hence, 
            \[\{\lVert Tv \rVert/\lVert v \rVert \mid v \neq 0\} \subseteq \{\lVert Tv \rVert \mid \lVert v \rVert = 1\}.\]
            So, the sets are equal, meaning that the supremum values agree too.
            
            \item[$(3) = (4)$] The set 
            \[\{c \geq 0 \mid \lVert Tv \rVert \leq c\lVert v \rVert \ \forall v \in V\}\]
            is the set of upper bounds of the set 
            \[\{\lVert Tv \rVert/\lVert v \rVert \mid v \in V\} \cup \{0\}.\]
            So, we find that the infimum of the upper bounds equals the supremum of the set.
        \end{enumerate}
    \end{proof}
    \noindent Using these definitions, we can show the following key lemma.
    \begin{lemma}
        Let $V$ and $W$ be vector spaces, and let $T \colon V \to W$ be a bounded function. Then, for any $v \in V$, $\lVert Tv \rVert \leq \lVert T \rVert \lVert v \rVert$.
    \end{lemma}
    \begin{proof}
        We know that 
        \[\lVert T \rVert = \sup_{v \neq 0 } \lVert Tv \rVert/\lVert v \rVert.\]
        Hence, for all $v \in V$ non-zero,
        \[\lVert T \rVert \geq \lVert Tv \rVert/\lVert v \rVert \iff \lVert T \rVert \lVert v \rVert \geq \lVert Tv \rVert.\]
        Next, if $v = 0$, then we know that $\lVert Tv \rVert = 0 \leq 0 = \lVert T \rVert \lVert v \rVert$. So, the result follows.
    \end{proof}

    \begin{proposition}
        Let $V$ and $W$ be vector spaces, and let $W$ be complete. Then, $L(V, W)$ is complete.
    \end{proposition}
    \begin{proof}
        Let $(T_n)_{n=1}^\infty$ be a Cauchy sequence in $L(V, W)$. For $v \in V$ non-zero, consider the sequence $(T_n(v))_{n=1}^\infty$. We show that the sequence is Cauchy. So, let $\varepsilon > 0$. Since $(T_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m - T_n \rVert < \frac{\varepsilon}{\lVert v \rVert}$. Hence, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then 
        \[\lVert T_m (v) - T_n (v)\rVert = \lVert (T_m - T_n)(v) \rVert \leq \lVert T_m - T_n \rVert \lVert v \rVert < \varepsilon.\]
        Hence, $(T_n(v))$ is Cauchy in $W$. Since $W$ is complete, there exists a $t_v \in W$ such that $T_n(v) \to t_v$. Now, define the function $T \colon V \to W$ by $T(v) = t_v$. We show that $T_n \to T$ in $L(V, W)$.

        First, we show that $T \in L(V, W)$. Let $v_1, v_2 \in V$. We know that for all $n \in \mathbb{Z}_{\geq 1}$, $T_n(v_1 + v_2) = T_n(v_1) + T_n(v_2)$. Hence, $T(v_1 + v_2) = T(v_1) + T(v_2)$. Now, let $v \in V$ and $c \in \mathbb{R}$. We know that for all $n \in \mathbb{Z}_{\geq 1}$, $T_n(cv) = cT_n(v)$. Hence, $T(cv) = cT(v)$. This implies that $T \in L(V, W)$.

        Now, we show that $T_n \to T$. So, let $\varepsilon > 0$. Since $(T_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m - T_n \rVert < \frac{\varepsilon}{3}$. Next, let $v \in V$ with $\lVert v \rVert = 1$. Since $T_n(v) \to T(v)$, we can find a $K \in \mathbb{Z}_{\geq 1}$ such that for $k \in \mathbb{Z}_{\geq 1}$, if $k \geq K$, then $\lVert T(v) - T_m(v) \rVert < \frac{\varepsilon}{3}$. Then, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then 
        \begin{align*}
            \lVert (T - T_n)(v) \rVert &\leq \lVert T(v) - T_n(v) \rVert \\
            &\leq \lVert T(v) - T_K(v) \rVert + \lVert T_K(v) - T_n(v) \rVert \\
            &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \frac{2\varepsilon}{3}.
        \end{align*}
        So, $\lVert T - T_n \rVert \leq \frac{2\varepsilon}{3} < \varepsilon$. This means that $T_n \to T$. Hence, $L(V, W)$ is complete.
    \end{proof}

    We now define the dual space.
    \begin{definition}
        Let $X$ be a $K$-normed vector space. We say that a function $T \colon X \to K$ is \emph{functional} if it is linear, and the \emph{dual space} $X^*$ is the set of bounded functionals.
    \end{definition}
    \noindent It turns out that for $1 < p < \infty$, we have an isometric isomorphism
    \[(L^p)^* \cong L^q,\]
    where $q$ is the dual number of $p$, i.e. $1/p + 1/q = 1$. In particular, if $p = 2$, then $(L^2)^* \cong L^2$. 
    % Moreover, $(L^1)^* \cong L^\infty$.

    \begin{theorem}
        The sequence spaces $\ell^\infty$ and $(\ell^1)^*$ are isometrically isomorphic.
    \end{theorem}
    \begin{proof}
        Define the map $T \colon \ell^\infty \to (\ell^1)^*$ by $T(x) = f_x$, where $f_x \colon \ell^1 \to \mathbb{C}$ is given by 
        \[f_x(y) = \sum_{n=1}^\infty x_n y_n.\]
        We first show that $f_x$ is well-defined, i.e. $f_x(y) \in (\ell^1)^*$. By construction, $f_x$ is linear. Now, let $y \in \ell^1$. We know that $|x_n| \leq \lVert x \rVert_\infty$ for all $n \in \mathbb{Z}_{\geq 1}$, meaning that
        \[|f_x(y)| = \left| \sum_{n=1}^\infty x_n y_n \right| \leq \sum_{n=1}^{\infty} |x_n y_n| \leq \lVert x \rVert_\infty \sum_{n=1}^\infty |y_n|.\]
        Since $y \in \ell^1$, this implies that $f_x(y) \in \ell^1$. So, $f_k$ is well-defined. Now, we show that $T$ is bounded. So, let $y \in \ell^1$. Then,
        \[\lVert f_x(y) \rVert_1 = \sum_{n=1}^\infty |x_n y_n| \leq \lVert x \rVert_\infty \sum_{n=1}^\infty |y_n| = \lVert x \rVert_\infty \lVert y \rVert_1.\]
        Hence, $f_x$ is bounded with $\lVert f_x \rVert \leq \lVert x \rVert_\infty$

        We now show that $T$ is an isometry. So, let $x = (x_n)_{n=1}^\infty \in \ell^\infty$. Define the sequences $(r_n)_{n=1}^\infty, (\theta_n)_{n=1}^\infty$ by the polar decomposition of $x_n$, i.e. $x_n = r_n e^{i \theta_n}$. For each $k \in \mathbb{Z}_{\geq 1}$, define the sequence $(y^{(k)}_n)_{n=1}^\infty$
        \[y^{(k)}_n = \begin{cases}
            e^{-i\theta_n} & n = k \\
            0 & \textrm{otherwise}.
        \end{cases}\]
        Then, $\lVert y^{(k)} \rVert_\infty = 1$, with
        \[\lVert f_x(y^{(k)}) \rVert_1 = \sum_{n=1}^\infty |x_n y_n| = |x_n e^{-i \theta_n}| = r_n = |x_n|.\]
        So, we find that 
        \[\{|x_n| \mid n \in \mathbb{Z}_{\geq 1}\} \subseteq \{\lVert f_x(y) \rVert_1 \mid \lVert y \rVert_1 = 1\}.\]
        So, the supremum property tells us that 
        \[\lVert x \rVert_\infty = \sup_{n = 1}^\infty |x_n| \leq \sup_{\lVert y \rVert_1 = 1} \lVert f_x(y) \rVert_1 = \lVert f_x \rVert.\]
        Hence, it follows that 
        \[\lVert f_x \rVert = \lVert x \rVert_\infty.\]
        This implies that $T$ is isometric.

        Finally, we show that $T$ is surjective. So, let $f \in (\ell^1)^*$. Define the sequence $x = (x_n)_{n=1}^\infty$ in $\mathbb{C}$ by $x_n = f(e_n)$. Then, for all $n \in \mathbb{Z}_{\geq 1}$, we find that 
        \[|x_n| = |f(e_n)| \leq \lVert f \rVert \lVert e_n \rVert_1 = \lVert f \rVert.\]
        Hence, $x \in \ell^\infty$. Moreover, for all $y \in \ell^1$, we find that
        \[f(y) = \sum_{n=1}^{^\infty} f(y_n e_n) = \sum_{n=1}^{\infty} y_n f(e_n) = \sum_{n=1}^{\infty} y_n x_n = f_x(y).\]
        So, $T(x) = f_x = f$, meaning that $T$ is surjective. Hence, $T$ is an isometric isomorphism.
    \end{proof}
    \newpage

    \section{Hahn-Banach}
    In this section, we define Hahn-Banach theorem, which allows us to extend linear functions. To prove this, we first need to consider partial order and then Zorn's Lemma.
    \begin{definition}
        Let $X$ be a set, and let $\leq$ be a relation on $X$. We say that $(X, \leq)$ is a \emph{partial order} if:
        \begin{itemize}
            \item for all $x \in X$, $x \leq x$;
            \item for all $x, y, z \in X$, if $x \leq y$ and $y \leq z$, then $x \leq z$; and
            \item for all $x, y \in X$, if $x \leq y$ and $y \leq x$, then $x = y$.
        \end{itemize}
    \end{definition}
    \noindent Examples of partial order include $(\mathbb{R}, \leq)$ and $(\mathcal{P}(X), \subseteq)$ for some set $X$. The relation does not require every element to be related- not any 2 subset of $X$ needs to satisfy the condition that one is the subset of the other. However, this is satisfied in $(\mathbb{R}, \leq)$, which gives rise to a total order.
    \begin{definition}
        Let $X$ be a set, and let $\leq$ be a partial order on $X$. Then, we say that $(X, \leq)$ is a \emph{total order} if for all $x, y \in X$, either $x \leq y$ or $y \leq x$.
    \end{definition}
    \noindent Now, in partial order, we can define a maximal element in the set.
    \begin{definition}
        Let $X$ be a set with partial order $\leq$, and let $x \in X$. We say that $x$ is a \emph{maximal element} if for all $y \in X$ such that $x \leq y$, we have $y = x$.
    \end{definition}
    \noindent It is not necessarily the case that a partial order has a maximal element, or that it is unique. We now consider upper bounds.
    \begin{definition}
        Let $X$ be a set with partial order $\leq$, $E \subseteq X$ and $x \in X$. We say that $x$ is an \emph{upper bound} of $E$ if for all $e \in E$, $e \leq x$.
    \end{definition}
    \noindent The upper bound need not lie in $E$, or be unique. Finally, we define well-orderedness.
    \begin{definition}
        Let $X$ be a set with partial order $\leq$. We say that it is \emph{well-ordered} if for every $E \subseteq X$, $E$ has a minimal element.
    \end{definition}
    \noindent For example, $\mathbb{R}$ is not well-ordered using the normal ordering. We now consider Zorn's Lemma.
    \begin{lemma}[Zorn's Lemma]
        Let $X$ be a non-empty set with partial order $\leq$, and let $E \subseteq X$ be a non-empty totally ordered with respect to $\leq$ that has an upper bound. Then, $X$ has a maximal element.
    \end{lemma}
    \noindent This lemma is equivalent to the axiom of choice (ZFC).

    We will now look at Hahn-Banach Theorem. Before doing so, we define a sublinear functional.
    \begin{definition}
        Let $V$ be a normed vector space and let $p \colon X \to \mathbb{R}$ be a function. We say that $p$ is \emph{sublinear} if 
        \begin{itemize}
            \item for all $x, y \in X$, $p(x + y) \leq p(x) + p(y)$; and 
            \item for all $x \in X$ and $c \geq 0$, $p(cx) = cp(x)$.
        \end{itemize}
    \end{definition}
    \begin{theorem}[Hahn-Banach]
        Let $V$ be a real normed vector space and let $p \colon V \to \mathbb{R}$ be a sublinear function, $M \subseteq V$ be a subspace and let $f \colon M \to \mathbb{R}$ be a linear functional, and $f \leq p$. Then, there exists an $F \colon V \to \mathbb{R}$ such that $F|_M = f$ and $f \leq p$.
    \end{theorem}
    \begin{proof}
        If $M = X$, then there is nothing to show. So, assume that $M \subsetneq X$. We prove this using Zorn's Lemma. So, define the set 
        \[X = \{F \colon Y \to \mathbb{R} \mid F \subsetneq M, F|_M = f, F \leq p\}.\]
        We can define the partial order $\leq$ on $X$ by inclusion of domains, and extensionality, i.e. for $F_1$ and $F_2$ in $X$ with domains $Y_1$ and $Y_2$, we say that $F_1 \leq F_2$ if $Y_1 \subseteq Y_2$, and $F_2|_{Y_1} = F_1$.

        First, we show that $X$ is non-empty. Let $x \in X \setminus M$. For $y_1, y_2 \in M$, we find that 
        \begin{align*}
            f(y_1) + f(y_2) &= f(y_1 + y_2) \\
            &\leq p(y_1 + y_2) \\
            &= p(y_1 - x + x + y_2) \\
            &\leq p(y_1 - x) + p(x + y_2).
        \end{align*}
        So, we find that
        \[f(y_1) - p(y_1 - x) \leq p(x + y_2) - f(y_2)\]
        for all $y_1, y_2 \in M$. Hence,
        \[\sup_{y \in M} f(y) - p(y - x) \leq \inf_{y \in M} p(x + y) - f(y).\]
        So, we can find an $\alpha \in \mathbb{R}$ such that
        \[\sup_{y \in M} f(y) - p(y - x) \leq \alpha \leq \inf_{y \in M} p(x + y) - f(y).\]
        Now, define $F \colon M + \mathbb{R}x \to \mathbb{R}$ by $F(y + \lambda x) = f(y) + \lambda \alpha$. We claim that $F \in X$. Since $x \not\in M$, we find that $M + \mathbb{R}x \subsetneq M$, and that $F$ extends $f$. Moreover, for all $y + \lambda x \in M + x \mathbb{R}$, if $\lambda \neq 0$, then 
        \begin{align*}
            F(y + \lambda x) &= f(y) + \lambda \alpha \\
            &= \lambda(f(y/\lambda) + \alpha) \\
            &\leq \lambda(f(y/\lambda) + p(x + y/\lambda) - f(y/\lambda)) \\
            &= \lambda(p(x + y/\lambda)) \\
            &= p(y + \lambda x).
        \end{align*}
        So, $F \leq p$, meaning that $F \in X$.
        
        We now show that every totally ordered set $E \subseteq X$ has a upper bound, with 
        \[E = \{F_i \colon Y_i \to \mathbb{R} \in X \mid i \in I\},\]
        for some indexing set $I$. Now, define the set 
        \[Y = \bigcup_{i \in I} Y_i\]
        and the map $F \colon Y \to \mathbb{R}$ by $F(y) = F_i(y)$, where $y \in Y_i$. Since the order assumes extensionality, it is well-defined. We claim that $F$ is an upper bound for $E$. By construction, $F$ extends each $F_i \in E$, and $Y \subseteq Y_i$ for all $i \in I$. So, $F$ is an upper bound for $E$.

        Finally, we can apply Zorn's Lemma to find a maximal element $F \colon V \to \mathbb{R}$.
    \end{proof}
    \noindent The Hahn-Banach theorem can be generalised for complex functions as well.
    \begin{theorem}[Hahn-Banach for complex functions]
        Let $V$ be a complex normed vector space and let $p \colon V \to \mathbb{C}$ be a sublinear function, $M \subseteq V$ be a subspace and let $f \colon M \to \mathbb{R}$ be a seminorm, and $|f| \leq p$. Then, there exists an $F \colon V \to \mathbb{C}$ such that $F|_M = f$ and $|f| \leq p$.
    \end{theorem}
    \noindent A seminorm is a norm such that $\lVert x \rVert = 0$ does not imply that $x = 0$.

    We will now look at some consequences of the Hahn-Banach Theorem.
    \begin{corollary}
        Let $V$ be a normed vector space, $M \subseteq V$ be a subspace and let $f \in M^*$. Then, there exists a linear functional $F \in V^*$ such that $F$ extends $f$, with $\lVert F \rVert = \lVert f \rVert$.
    \end{corollary}
    \begin{proof}
        Note that for any extension $F$ of $f$, we have $\lVert F \rVert \geq \lVert f \rVert$ by the supremum property. Now, define the map $p \colon X \to \mathbb{C}$ by $p(x) = \lVert f \rVert \lVert x \rVert$. By construction, we find that for all $y \in M$, 
        \[|f(y)| \leq \lVert f \rVert \lVert y \rVert = p(y),\]
        meaning that $|f| \leq p$. We now show that $p$ is a seminorm. For all $\lambda \in \mathbb{C}$ and $y \in M$, we find that
        \[p(\lambda y) = \lVert f \rVert \lVert \lambda y \rVert = |\lambda| \lVert f \rVert \lVert y \rVert = |\lambda| p(y).\]
        Moreover, for all $y_1, y_2 \in M$,
        \begin{align*}
            p(y_1 + y_2) &= \lVert f \rVert \lVert y_1 + y_2 \rVert \\
            &\leq \lVert f \rVert (\lVert y_1 \rVert + \lVert y_2 \rVert) \\
            &= \lVert f \rVert \lVert y_1 \rVert + \lVert f \rVert \lVert y_2 \rVert \\
            &= p(y_1) + p(y_2).
        \end{align*}
        Hence, $p$ is a seminorm. So, Hahn-Banach allows us to extend $f$ into a function $F \in V^*$. Moreover, since $F \leq p$, we find that for all $v \in V$,
        \[|F(v)| \leq p(v) = \lVert f \rVert \lVert v \rVert.\]
        So, $\lVert F \rVert \leq \lVert f \rVert$, meaning that $\lVert F \rVert = \lVert f \rVert$.
    \end{proof}

    \begin{corollary}
        Let $V$ be a normed vector space, $M \subsetneq V$ be closed and let $x \in M \setminus V$, and denote 
        \[\delta = \inf_{y \in M} \lVert x - y \rVert.\]
        Then, there exists an $F \in V^*$ such that $\lVert F \rVert = 1$, $F(x) = \delta$ and $M \subseteq \ker F$.
    \end{corollary}
    \begin{proof}
        Define the map $f \colon M + \mathbb{C}x \to \mathbb{C}$ by $f(y + \lambda x) = \lambda \delta$. This is a linear functional by definition. Next, define the function $p \colon V \to \mathbb{R}$ by $p(x) = \lVert x \rVert$. Since this is a norm, it is a seminorm. Moreover, for all $y + \lambda x \in M + \mathbb{C}x$, if $\lambda = 0$, then $f(y + \lambda x) = 0 \leq \lVert y + \lambda x \rVert$, and if $\lambda \neq 0$, then
        \[|f(y + \lambda x)| = |\lambda| \delta \leq |\lambda| \left\lVert \frac{1}{\lambda} y + x \right\rVert = \lVert y + \lambda x \rVert.\]
        So, $|f| \leq p$. Applying Hahn-Banach, we can find a function $F \in V^*$ that extends $f$. In particular, we still have $M \subseteq \ker F$ and $F(x) = \delta$. Finally, for all $v \in V$, we have 
        \[|F(v)| \leq p(v) = \lVert F \rVert \lVert v \rVert,\]
        meaning that $\lVert F \rVert \leq 1$.
        % TODO: Show the other side of inequality
    \end{proof}

    \begin{corollary}
        Let $V$ be a normed vector space and let $v \in V$ be non-zero. Then, there exists a functional $f \in V^*$ such that $\lVert f \rVert = 1$ and $f(v) = \lVert v \rVert$.
    \end{corollary}
    \begin{proof}
        Let $M = \{0\}$. Then, it is a closed proper subset of $V$, with 
        \[\delta = \inf_{y \in M} \lVert x - y \rVert = \lVert v \rVert.\]
        Hence, there exists a functional $f \in V^*$ such that $\lVert f \rVert = 1$ and $F(v) = \lVert v \rVert$.
    \end{proof}

    \begin{corollary}
        Let $V$ be a normed vector space and let $x, y \in V$ be distinct. Then, there exists a functional $f \in V^*$ such that $f(x) \neq f(y)$. In particular, linear functionals separate the vector space.
    \end{corollary}
    \begin{proof}
        Since $x$ and $y$ are distinct, we find that $x - y \neq 0$. Hence, there exists a functional $f \in V^*$ such that $f(x - y) = \lVert x - y \rVert \neq 0$. So, $f(x) \neq f(y)$.
    \end{proof}

    Now, we show that the double dual of a vector space always has an isometry from the vector space.
    \begin{proposition}
        Let $V$ be a vector space, $v \in V$ and consider the evaluation map $\hat{v} \colon V^* \to \mathbb{C}$ given by $\overline{v}(f) = f(v)$. Then, the map $T \colon V \to V^{**}$ given by $T(v) = \hat{v}$ is an isometry.
    \end{proposition}
    \begin{proof}
        Let $v \in V$. We show that $\lVert v \rVert = \lVert \hat{v} \rVert$ for all $v \in V$. So, let $f \in V^*$. Then,
        \[\lVert \hat{v}(f) \rVert = \lVert f(v) \rVert \leq \lVert f \rVert \lVert v \rVert.\]
        This implies that $\lVert \hat{v} \rVert \leq \lVert v \rVert$. Now, consider the identity map $f \in V^*$. We know that $\lVert f \rVert = 1$, with 
        \[\lVert \hat{v}(f) \rVert = \lVert f(v) \rVert = \lVert v \rVert.\]
        Hence, we find that $\lVert \hat{v} \rVert = \lVert v \rVert$.
    \end{proof}
    \noindent This is a key result- assuming that the field is complete (which is true for $\mathbb{R}$ and $\mathbb{C}$), we have found an embedding of $V$ into a complete space $V^{**}$. Hence, we can identify its completion as a concrete subspace of $V^{**}$. There are cases when $V^{**}$ is also isometrically isometric, e.g. $L^p$ for $p > 1$, in which case we say that the vector space is \emph{reflexive}.

    % (\ell^\infty)^* includes \ell^1, but (\ell^\infty)^* strictly includes \ell^1
    % c \subseteq \ell^\infty; limit is a functional on c + Hahn-Banach to extend limit to \ell^\infty
    % this cannot be an image of \ell^1

    \newpage

    \section{Baire-Category Theorem}
    \begin{definition}
        Let $X$ be a topological space and let $E \subseteq X$.
        \begin{itemize}
            \item We say that $E$ is \emph{open dense} if $E$ is open with closure $X$.
            \item We say that $E$ is \emph{nowhere dense} if the complement of its closure $\overline{E}^c$ is open dense.
            \item $E$ is a \emph{meagre} (or \emph{first category}) if it is a countable union of nowhere dense sets.
            \item $E$ is of \emph{second category} if it is not of first category.
        \end{itemize}
    \end{definition}
    
    \begin{theorem}[Baire-Category Theorem]
        Let $X$ be a complete metric space, and let $(U_n)_{n=1}^\infty$ be a sequence of open dense sets in $X$. Then, the intersection
        \[\bigcap_{n=1}^\infty U_n\]
        is dense in $X$.
    \end{theorem}
    \begin{proof}
        Let $W \subseteq X$ be open. We show that for all $n \in \mathbb{Z}_{\geq 1}$, $U_n \cap W$ is non-empty. Since $U_1$ is open dense, we know that $U_1 \cap W$ is a non-empty open set. Hence, there exists an open ball $B_{r_0}(x_0) \subseteq U_1 \cap W$. Without loss of generality, assume that $r_0 \leq 1$. Now, since $U_2$ is open dense, we can find an open ball $B_{r_1}(x_1)$ such that $\overline{B_{r_1}(x_1)} \subseteq U_1 \cap B_{r_0}(x_0)$, with $r_1 < 2^{-1}$. We can continue on finding open balls $(B_{r_n}(x_n))_{n=0}^\infty$ such that $\overline{B_{r_n}(x_n)} \subseteq U_n \cap B_{r_{n-1}}(x_{n-1})$ for $n \geq 1$. 
        
        We now claim that the sequence $(x_n)_{n=0}^\infty$ is a Cauchy sequence. Let $\varepsilon > 0$. Select an $N \in \mathbb{Z}_{\geq 1}$ such that $2^{N+1} > \frac{1}{\varepsilon}$. In that case, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then we know that $x_m, x_n \in U_{N+1} \cap B_{r_N}(x_N)$, in which case
        \[|x_m - x_n| \leq |x_m - x_N| + |x_N - x_n| < r_N + r_N = 2 \cdot \frac{\varepsilon}{2} = \varepsilon.\]
        So, $(x_n)$ is Cauchy.
        
        Since $X$ is complete, $x_n \to x$ for some $x \in X$. By construction, we have 
        \[x \in \bigcap_{n=1}^\infty \overline{B}_{r_n}(x_n) \subseteq \bigcap_{n=0}^\infty U_n \cap B_{r_{n-1}}(x_{n-1}) \subseteq \bigcap_{n=0}^\infty U_n \cap W.\]
        So, the intersection is non-empty, meaning that it is dense in $X$.
    \end{proof}
    
    \begin{corollary}
        Let $X$ be a complete metric space. Then, it is of second category.
    \end{corollary}
    \begin{proof}
        Let $(E_1)_{n=1}^\infty$ be a sequence of nowhere dense sets. We show that the union
        \[\bigcup_{n=1}^\infty E_n \subsetneq X.\]
        We know that $(\overline{E}_n^c)$ is a sequence of open dense sets. By Baire-Category Theorem, we know that the intersection
        \[\bigcap_{n=1}^\infty \overline{E}_n^c\]
        is dense in $X$. In particular, the intersection is non-empty, meaning that its complement
        \[\bigcup_{n=1}^\infty E_n \subseteq \bigcup_{n=1}^\infty \overline{E}_n \neq X.\]
        So, $X$ cannot be of first category.
    \end{proof}
    \newpage

    \section{Open Mapping Theorem}

    \begin{definition}
        Let $X$ and $Y$ be topological spaces and let $f \colon X \to Y$ be a map. We say that $f$ is \emph{open} if for all $U \subseteq X$ open, $f(U) \subseteq Y$ is open.
    \end{definition}

    % \begin{proposition}
    %     Let $V$ and $W$ be normed vector spaces and let $T \colon V \to W$ be a linear map. Then, $T$ is open if and only if $T(U)$ is open, where $U \subseteq V$ is the unit open ball.
    % \end{proposition}
    % \begin{proof}
    %     If $T$ is open, then we know that $T(U)$ is open. So, now, assume that $T(U)$ is open, and let $A \subseteq V$ be open. We show that $T(A) \subseteq V$ is open. So, let $x \in T(A)$. In that case, there exists an $a \in A$ such that $x = T(a)$. Since $A$ is open, we can find a $r > 0$ such that $B_r(x) \subseteq A$. In that case, 
    % \end{proof}

    \begin{proposition}
        Let $X$ and $Y$ be metric spaces and let $f: X \to Y$ be a function. Then, $f$ is an open map if and only if for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$.
    \end{proposition}
    \begin{proof}
        \hspace*{0pt}
        \begin{itemize}
            \item Assume that $f$ is an open map. Let $x \in X$ and $\delta > 0$. Let
            \[U = B_X(x, \delta).\]
            Since $f$ is an open map, we know that $f(U)$ is open. We have $f(x) \in f(U)$. In that case, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then $f(y) \in f(B_X(x, \delta))$. So, there exists a $z \in X$ with $d_X(x, z) < \delta$ with $f(y) = f(z)$. That is, for all $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$.
            
            \item Assume that for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$. Let $U \subseteq X$ be open. We show that $f(U)$ is open. So, let $x \in U$. Since $U$ is open, there exists a $\delta_x > 0$ such that for all $y \in X$, if $d_X(x, y) < \delta_x$, then $y \in U$. Now, we can find an $\varepsilon_x > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon_x$, then there exists a $z \in X$ such that $d_X(x, z) < \delta_x$ with $f(y) = f(z)$. This implies that $z \in U$. So, $f(y) = f(z) \in f(U)$. In that case, for all $x \in X$, there exists an $\varepsilon_x$ such that for all $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon_x$, then $f(y) \in f(U)$. This implies that $f(U)$ is open. In other words, $f$ is an open map.
        \end{itemize}
    \end{proof}
    \noindent Another way of writing this is the following- $f: X \to Y$ is an open map if and only if for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that
    \[B_Y(f(x), \varepsilon) \subseteq f(B_X(x, \delta)).\]

    \begin{proposition}
        Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a linear operator. Then, $T$ is an open map if and only if there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$.
    \end{proposition}
    \begin{proof}
        \hspace*{0pt}
        \begin{itemize}
            \item Assume that $T$ is an open map. Set $\bm{x} = \bm{0}$ and $\delta = 1$. In that case, there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) - T(\bm{x}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} - \bm{x} \rVert_V < \delta$ with $T(\bm{u}) = T(\bm{v})$. That is, there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$.
            
            \item Assume that there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$. We show that $T$ is an open map. Let $\bm{x} \in V$ and $\delta > 0$. We can find an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v} - \bm{x}) \rVert_W < \frac{\varepsilon}{\delta}$, then there exists a $\bm{u} \in V$ such that $\lVert \frac{1}{\delta}\bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v} - \bm{x})$. Using linearity and replacing $\bm{u}$ with $\bm{u} + \delta\bm{x}$; $\bm{v}$ with $\delta \bm{v}$; $\bm{x}$ with $\delta \bm{x}$, we find that for $\bm{v} \in V$, if $\lVert T(\bm{v}) - T(\bm{x}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} - \bm{x} \rVert_V < \delta$ with $T(\bm{u}) = T(\bm{v})$. So, $T$ is an open map.
        \end{itemize}
    \end{proof}
    % \noindent Another way of writing this is the following- $T: V \to W$ is an open map if and only if there exists an $\varepsilon > 0$ such that
    % \[B_W(0, \varepsilon) \subseteq f(B_V(0, 1)).\]

    \begin{theorem}[Open Mapping Theorem]
        Let $V$ and $W$ be Banach spaces and let $T \colon V \to W$ be a surjective linear operator. Then, $T$ is open.
    \end{theorem}
    \begin{proof}
        
    \end{proof}

    \begin{corollary}
        Let $V$ and $W$ be Banach spaces and let $T \colon V \to W$ be a bijective linear operator. Then, $T$ is an isomorphism.
    \end{corollary}
    \begin{proof}
        Since $T$ is surjective, we know that $T$ is an open map. We know that $T^{-1} \colon W \to V$ is a linear operator, so we show that $T^{-1}$ is continuous. So, let $U \subseteq V$ be open. Since $T$ is an open map, we know that $T(U) \subseteq W$ is open. Now, we know that for $w \in W$,
        \[w \in (T^{-1})^{-1}(U) \iff T^{-1}(w) \in U \iff w \in T(U).\]
        Hence, we find that $(T^{-1})^{-1}(U) = T(U)$ is open. So, $T^{-1}$ is bounded operator, meaning that $T$ is an isomorphism.
    \end{proof}
    \newpage

    \section{Closed Graph Theorem}
    In this section, we will be proving the closed graph theorem. We begin by defining graphs.
    \begin{definition}
        Let $V$ and $W$ be sets and $T \colon V \to W$ be a function. Then, the \emph{graph} of $T$ is the set
        \[\operatorname{Graph}(T) = \{(v, Tv) \mid v \in V\} \subseteq V \times W.\]
    \end{definition}
    \noindent If $V$ and $W$ have structure, then this structure can be easily extended to $V \times W$. In particular, 
    \begin{itemize}
        \item if $V$ and $W$ are vector spaces, then $\operatorname{Graph}(T)$ is a subspace of $V \times W$;
        \item if $V$ and $W$ are normed vector spaces, then the function $\lVert \cdot \rVert \colon V \times W \to [0, \infty)$ given by $\lVert (v, w) \rVert = \max(\lVert v \rVert_V, \lVert w \rVert_W)$ is a norm on $V \times W$; and 
        \item if $V$ and $W$ are complete (metric) spaces, then $V \times W$ is a complete (metric) space.
    \end{itemize}
    
    We can show that in metric spaces, $\operatorname{Graph}(T)$ is closed in $V \times W$.
    \begin{proposition}
        Let $V$ and $W$ be metric spaces and let $T \colon V \to W$ be continuous. Then, $\operatorname{Graph}(T)$ is closed in $V \times W$.
    \end{proposition}
    \begin{proof}
        Let $(v_n, Tv_n)_{n=1}^\infty$ be a sequence in $\operatorname{Graph}(T)$ that converges to $(v, w) \in V \times W$. We show that $(v, w) \in \operatorname{Graph}(T)$, i.e. $w = Tv$. By the definition of the product metric, we know that $v_n \to v$ and $Tv_n \to w$. Since $T$ is continuous, it follows that $Tv_n \to Tv$. Since limits are unique, we find that $w = Tv$, meaning that $(v, w) \in \operatorname{Graph}(T)$. So, $\operatorname{Graph}(T)$ is closed.
    \end{proof}
    \noindent We can now ask the converse- if $\operatorname{Graph}(T)$ is closed, then does this imply that $T$ is bounded. This is what the closed graph theorem answers.
    \begin{theorem}[Closed Graph Theorem]
        Let $V$ and $W$ be Banach spaces and let $T \colon V \to W$ be a linear operator such that $\operatorname{Graph}(T)$ is closed. Then, $T$ is bounded.
    \end{theorem}
    \begin{proof}
        Since $V$ and $W$ are complete, we find that $V \times W$ is complete. Hence, $\operatorname{Graph}(T)$ is a Banach space. Now, consider the projection maps $\pi_V \colon V \times W \to V$ and $\pi_W \colon V \times W \to W$ given by $\pi_V(v, w) = v$ and $\pi_W(v, w) = w$. By definition, $\pi_V$ and $\pi_W$ are linear operators. Moreover, for all $(v, w) \in V$,
        \[\lVert \pi_V(v, w) \rVert_V = \lVert v \rVert_V \leq \lVert (v, w) \rVert,\]
        meaning that $\pi_V$ is bounded. Similarly, $\pi_W$ is bounded. Now, consider the restriction $\pi_V \colon \operatorname{Graph}(T) \to V$. This is a bijection, with inverse $\pi_V^{-1}(v) = (v, Tv)$. Since $\operatorname{Graph}(T)$ is a Banach space, the Open Mapping Theorem tells us that $\pi_V^{-1}$ is bounded. Now, for all $v \in V$, we find that 
        \[\pi_W(\pi_V^{-1}(v)) = \pi_W(v, Tv) = Tv.\]
        So, $\pi_W \circ \pi_V^{-1} = T$. Since both $\pi_W$ and $\pi_V^{-1}$ are bounded, it follows that $T$ is bounded.
    \end{proof}

\end{document}

% \begin{document}
%     \chapter{Functional Analysis}
%     \section{Function spaces}
%     For $p \in [1, \infty)$, we define
%     \[L^{p}[0, 1] = \{f: [0, 1] \to \mathbb{R} \cup \{\pm \infty\} \mid |f|^p \text{ (Lebesgue) integrable}\}.\]
%     Moreover, we have the norm
%     \[\lVert f \rVert_p = \left(\int_0^1 |f|^p \ dm\right)^{1/p}.\]
    
%     For the $L_\infty$ norm, we define the concept of essential supremum.
%     \begin{definition}
%         Let $f: [0, 1] \to \mathbb{R} \cup \{\pm \infty\}$ be a function. Then, the \emph{essential supremum} of $f$ is the set
%         \[\esup (f) = \inf \{a \in [0, 1] \mid m(f(x) > a) = 0\}.\]
%     \end{definition}
%     % TODO: Example = f(x) = 1 but is huge for some values, then ess sup is still 1
    
%     Then, we define 
%     \[L^\infty [0, 1] = \{f: [0, 1] \to \mathbb{R} \cup \{\pm \infty\} \mid \esup |f| \text{ exists}\}.\]
%     Moreover, we have the norm
%     \[\lVert f \rVert_\infty = \esup |f|.\]

%     % TODO: This is generalisation of sequence spaces

%     We will now prove Holder's Inequality. First, we start with a lemma.
%     \begin{lemma}
%         Let $a, b \in [0, \infty)$, and $\lambda \in (0, 1)$. Then,
%         \[a^\lambda b^{1-\lambda} \leq \lambda a + (1 - \lambda) b.\]
%         Moreover, we have equality if and only if $a = b$.
%     \end{lemma}
%     \begin{proof}
%         If $b = 0$, then 
%         \[a^\lambda b^{1 - \lambda} = 0 \leq \lambda a.\]
%         Instead, assume that $b \neq 0$. In that case, define the function $f: (0, \infty) \to \mathbb{R}$ given by
%         \[f(t) = \lambda t + 1 -\lambda - t^\lambda.\]
%         We have
%         \[f'(t) = \lambda - \lambda t^{\lambda -1}, \qquad f''(t) = -(\lambda - 1)\lambda t^{\lambda-2}.\]
%         So, $f'(t) = 0$ if and only if $t = 1$, with $f''(1) = -(\lambda - 1)\lambda > 0$. In that case, $f$ has a global minimum at $t = 1$. Therefore, for all $t \in (0, \infty)$, $f(t) \geq f(1)$. Setting $t = \frac{a}{b}$, we find that
%         \[\lambda \frac{a}{b} + 1 - \lambda - \frac{a^\lambda}{b^\lambda} \geq 0 \implies a^\lambda b^{1-\lambda} \leq \lambda a + (1 - \lambda) b.\]
%     \end{proof}

%     \begin{proposition}[Holder's Inequality]
%         Let $p \in (1, \infty)$ and $q \in (1, \infty)$ such that
%         \[\frac{1}{p} + \frac{1}{q} = 1.\]
%         Let $f, g: [0, 1] \to \mathbb{R} \cup \{\pm \infty\}$ be measurable functions. Then,
%         \[\lVert fg \rVert_1 \leq \lVert f \rVert_p \lVert g \rVert_q.\]
%         In particular, if $f \in L^p[0, 1]$ and $g \in L^q[0, 1]$, then $fg \in L^1[0, 1]$. Moreover, we have equality if and only if $\alpha |f|^p = \beta |g|^q$ almost everywhere in $[0, 1]$, for some $\alpha, \beta \in \mathbb{R}^\times$.
%     \end{proposition}
%     \begin{proof}
%         If $\lVert f \rVert_p = 0$ or $\lVert g \rVert_q = 0$, then the function is equal to $0$ almost everywhere in $[0, 1]$. In that case, $fg = 0$ almost everywhere, meaning that $\lVert fg \rVert_1 = 0$.

%         \noindent Instead, if $\lVert f \rVert_p = \infty$ or $\lVert g \rVert_q = \infty$, then we must have $\lVert fg \rVert_1 \leq \lVert f \rVert_p \lVert g \rVert_q$.

%         \noindent Otherwise, assume that $\lVert f \rVert_p$ and $\lVert g \rVert_p$ are finite are non-zero. Without loss of generality, assume that $\lVert f \rVert_p = 1$ and $\lVert g \rVert_q = 1$.\sidefootnote{This is possible since a (non-negative) scalar multiple does not affect the inequality.} In that case, set $a = |f(x)|^p$, $b = |g(x)|^q$ and $\lambda = \frac{1}{p}$. Then, the lemma above tells us that
%         \begin{align*}
%             f(x) g(x) &= (|f(x)|^p)^{1/p} (|g(x)|^q)^{1/q} \\
%             &= a^{\lambda} b^{1 - \lambda} \\
%             &\leq \lambda a + (1 - \lambda)b \\
%             &= \frac{1}{p} |f(x)|^p + \frac{1}{q} |g(x)|^q.
%         \end{align*}
%         Integrating the inequality, we find that
%         \begin{align*}
%             \lVert fg \rVert_1 &= \int_0^1 |fg| \ dm \\
%             &\leq \int_0^1 \frac{1}{p} |f|^p + \frac{1}{q} |g|^q \ dm \\
%             &= \frac{1}{p} \lVert f \rVert^p_p + \frac{1}{q} \lVert g \rVert^q_q \\
%             &= \frac{1}{p} + \frac{1}{q} \\
%             &= 1 = \lVert f \rVert_p \lVert g \rVert_q.
%         \end{align*}
%     \end{proof}

%     Now, we show that $L^p$ are truly norms, by proving it satisfies the Triangle Inequality.
%     \begin{proposition}[Minkowski Inequality]
%         Let $p \in [1, \infty)$ and $f, g \in L^p$. Then,
%         \[\lVert f + g \rVert_p \leq \lVert f \rVert_p + \lVert g \rVert_p.\]
%     \end{proposition}
%     \begin{proof}
%         If $p = 1$, then the result follows from the Triangle Inequality in $\mathbb{R}$. Otherwise, we have $p \in (1, \infty)$. In that case,
%         \[|f + g|^p \leq (|f| + |g|)|f + g|^{p-1}\]
%         using the Triangle Inequality on $\mathbb{R}$. Let $q \in (1, \infty)$ such that
%         \[\frac{1}{p} + \frac{1}{q} = 1 \iff (p - 1)q = p.\]
%         Integrating the inequality, we find that
%         \[\int |f + g|^p \ dm \leq \int |f| |f + g|^{p-1} \ dm + \int |g| |f + g|^{p-1} \ dm.\]
%         Using Holder's Inequality now, we find that
%         \begin{align*}
%             \int |f| |f + g|^{p-1} \ dm = \lVert |f| \cdot |f + g|^{p-1} \rVert_1 &\leq \lVert f \rVert_p \lVert (f + g)^{p-1} \rVert_q \\
%             \int |g| |f + g|^{p-1} \ dm = \lVert |g| \cdot |f + g|^{p-1} \rVert_1 &\leq \lVert g \rVert_p \lVert (f + g)^{p-1} \rVert_q.
%         \end{align*}
%         We have
%         \[\lVert (f + g)^{p-1} \rVert_q = \left(\int (|f + g|^{p-1})^q \ dm\right)^{1/q} = \left(\int |f+g|^p \ dm\right)^{1/q}.\]
%         Putting this together, we find that
%         \[\int |f + g|^p \ dm \leq (\lVert f \rVert_p + \lVert g \rVert_p)\left(\int |f+g|^p \ dm\right)^{1/q}.\]
%         This implies that
%         \[\left(\int |f + g|^p \ dm\right)^{1-1/q} \leq \lVert f \rVert_p + \lVert g \rVert_p.\]
%         We have $1 - \frac{1}{q} = \frac{1}{p}$. So,
%         \[\lVert f + g \rVert_p \leq \lVert f \rVert_p + \lVert g \rVert_p.\]
%     \end{proof}
%     \newpage

%     \section{Completeness of $L^p$}
%     \begin{definition}
%         Let $V$ be a normed vector space over $\mathbb{R}$, and let $(x_n)_{n=1}^\infty$ be a sequence in $V$. We say that the series
%         \[\sum_{k=1}^\infty x_k\]
%         converges if the sequence of partial sums $(s_n)_{n=1}^\infty$ in $V$ given by
%         \[s_n = \sum_{k=1}^n x_k\]
%         converges. Further, we say that the series converges absolutely if the sequence of partial sums $(y_n)_{n=1}^\infty$ in $\mathbb{R}$ given by 
%         \[y_n = \sum_{k=1}^n \lVert x_k \rVert\]
%         converges.
%     \end{definition}

%     \begin{proposition}
%         Let $V$ be a normed vector space over $\mathbb{R}$. Then, $V$ is complete if and only if every absolutely convergent series is convergent.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item First, assume that $V$ is complete. Let $(x_k)_{k=1}^\infty$ be a sequence such that the series $\sum x_k$ is absolutely convergent. In that case, the series $\sum \lVert x_k \rVert$ is Cauchy. Now, define the partial sums $(s_n)_{n=1}^\infty$ and $(t_n)_{n=1}^\infty$ by
%             \[s_n = \sum_{k=1}^n x_k, \qquad t_n = \sum_{k=1}^n \lVert x_k \rVert.\]
%             Next, let $\varepsilon > 0$. We can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$ with $m \geq n$, if $m, n \geq N$, then 
%             \[|t_m - t_n| = \sum_{k=n+1}^m \lVert x_k \rVert < \varepsilon.\]
%             In that case, for $m, n \in \mathbb{Z}_{\geq 1}$ with $m \geq n$, if $m, n \geq N$, then
%             \[\lVert s_m - s_n \rVert = \left\lVert \sum_{k=n+1}^m x_k \right\rVert \leq \sum_{k=n+1}^m \lVert x_k \rVert < \varepsilon.\]
%             Therefore, the series $\sum x_k$ is Cauchy. Since $V$ is complete, this implies that $\sum x_k$ is convergent. So, every absolutely convergent series is convergent.
            
%             \item Now, assume that every absolutely convergent series is convergent. Let $(x_n)_{n=1}^\infty$ be a Cauchy sequence in $V$. In that case, for each $k \in \mathbb{Z}_{\geq 1}$, we can find an $N_k \in \mathbb{Z}_{\geq 1}$, with $N_k \geq N_{k-1}$ for $k \geq 2$, such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert x_m - x_n \rVert < \frac{1}{2^{k-1}}$. Now, define the sequence $(y_n)_{n=1}^\infty$ by $y_1 = x_{N_1}$ and $y_n = x_{N_n} - x_{N_{n-1}}$ for $n \geq 2$. We show that $\sum y_n$ is absolutely convergent. Let $\varepsilon > 0$. We find that
%             \[\sum_{j=1}^\infty \lVert y_j \rVert \leq \lVert x_{N_1} \rVert + \sum_{j=2}^\infty \lVert x_{N_j} - x_{N_{j-1}}\rVert \lVert x_{N_1} \rVert + \sum_{j=2}^\infty \frac{1}{2^j} = x_{N_1} + 1.\]
%             This implies that $\sum y_n$ is absolutely convergent. Since every absolutely convergent series is convergent, we find that $\sum y_n$ is convergent. In that case, the sequence of partial sums $(s_n)_{n=1}^\infty$ 
%             \[s_n = \sum_{k=1}^n y_n = x_{N_n}\]
%             converges. So, the subsequence $(x_{N_n})_{n=1}^\infty$ converges. Since $(x_n)$ is Cauchy, this implies that $(x_n)_{n=1}^\infty$ converges. Therefore, $V$ is complete.
%         \end{itemize}
%     \end{proof}

%     \begin{proposition}
%         Let $p \in [1, \infty)$. Then, $L^p[0, 1]$ is a Banach space, i.e. the function space is complete.
%     \end{proposition}
%     \begin{proof}
%         Let $(f_n)_{n=1}^\infty$ be a sequence in $L^p[0, 1]$ such that $\sum f_n$ is absolutely convergent.
%         % TODO: Complete
%     \end{proof}

%     % TODO: L^p \subseteq L^q if p >= q 
%     % TODO: 1/sqrtx is in L2 but not in L1 (generalise to show it is a proper subset)
%     \newpage

%     \section{Linear Operators}
%     \begin{definition}
%         Let $V, W$ be normed vector spaces, and let $T: V \to W$ be a function. We say that $T$ is a \emph{linear operator} if 
%         \begin{itemize}
%             \item $T{\lambda \bm{v}} = \lambda T(\bm{v})$ for all $\lambda \in \mathbb{R}$ and $\bm{v} \in V$;
%             \item $T(\bm{v} + \bm{w}) = T(\bm{v}) + t(\bm{w})$ for all $\bm{v}, \bm{w} \in V$.
%         \end{itemize}
%     \end{definition}

%     \begin{definition}
%         Let $V, W$ be normed vector spaces, and let $T: V \to W$ be a linear operator. Then, $T$ is \emph{bounded} if there exists a $c > 0$ such that for all $\bm{v} \in V$, $\lVert T(\bm{v}) \rVert_W \leq c \lVert \bm{v} \rVert_V$.
%     \end{definition}

%     \subsection{Dimensional and linear operators}
%     If $V$ and $W$ are both finite dimensional, then $T$ can be represented by a matrix. Let the basis of $V$ be
%     \[\{\bm{v}_1, \bm{v}_2, \dots, \bm{v}_n\},\]
%     and the basis for $W$ be
%     \[\{\bm{w}_1, \bm{w}_2, \dots, \bm{w}_m\}.\]
%     Then, for all $i \in \{1, 2, \dots, n\}$,
%     \[T(\bm{v}_i) = a_{1i} \bm{w}_1 + a_{2i} \bm{w}_2 + \dots + a_{mi} \bm{w}_m.\]
%     Now, define
%     \[A = \begin{bmatrix}
%         a_{11} & a_{12} & \dots & a_{1n} \\
%         a_{21} & a_{22} & \dots & a_{2n} \\
%         \vdots & \vdots & \ddots & \vdots \\
%         a_{m1} & a_{m2} & \dots & a_{mn} 
%     \end{bmatrix}.\]
%     Let $\bm{x} \in V$. We have
%     \[\bm{x} = b_1\bm{v}_1 + b_2\bm{v}_2 + \dots b_n\bm{v}_n.\]
%     Then,
%     \begin{align*}
%         T(\bm{x}) &= b_1(a_{11} \bm{w}_1 + a_{21} \bm{w}_2 + \dots + a_{m1} \bm{w}_m) \\
%         &+ b_2(a_{12} \bm{w}_1 + a_{22} \bm{w}_2 + \dots + a_{m2} \bm{w}_m) + \dots \\
%         &+ b_n(a_{1n} \bm{w}_1 + a_{2n} \bm{w}_2 + \dots + a_{mn} \bm{w}_m) \\
%         &= \begin{bmatrix}
%             a_{11} & a_{12} & \dots & a_{1n} \\
%             a_{21} & a_{22} & \dots & a_{2n} \\
%             \vdots & \vdots & \ddots & \vdots \\
%             a_{m1} & a_{m2} & \dots & a_{mn} 
%         \end{bmatrix} \begin{bmatrix}
%             b_1 \\ b_2 \\ \vdots \\ b_n
%         \end{bmatrix} \\
%         &= A \bm{x}.
%     \end{align*}

%     Moreover, linear operators in finite dimensions are always bounded. To see this, define the set
%     \[S^n = \{\bm{v} \in V \mid \lVert \bm{v} \rVert_V = 1\}.\]
%     Since $V$ is finite-dimensional, Heine-Borel theorem tells us that the set $S^n$ is compact. Moreover, the function $f: S^n \to \mathbb{R}$ given by $f(\bm{v}) = \lVert T(\bm{v}) \rVert_V$ is continuous. So, by the Extreme Value Theorem, the function attains a maximum. That is, for all $\bm{v} \in V$, if $\lVert \bm{v} \rVert_V = 1$, then $\lVert T(\bm{v}) \rVert_W \leq K$, for some $K > 0$. Now, let $\bm{v} \in V$. If $\bm{v} = 0$, then we have 
%     \[\lVert \bm{v} \rVert_V = 0 \leq 0 = K\lVert T(\bm{v}) \rVert_W.\]
%     Otherwise, if $\bm{v} \neq \bm{0}$, then we have
%     \[\left\lVert \frac{1}{\lVert \bm{v} \rVert_V} \bm{v} \right\rVert_V = \frac{1}{\lVert \bm{v} \rVert_V} \lVert \bm{v} \rVert_V = 1.\]
%     So, we have $\frac{1}{\lVert \bm{v} \rVert_V} \bm{v} \in S^n$. In that case,
%     \[\left\lVert T\left(\frac{1}{\lVert \bm{v} \rVert_V} \bm{v}\right) \right\rVert_W \leq K.\]
%     This implies that
%     \[\lVert T(\bm{v}) \rVert_W \leq K \lVert \bm{v} \rVert_V.\]
%     So, for all $\bm{v} \in V$,
%     \[\lVert T(\bm{v}) \rVert_W \leq K \lVert \bm{v} \rVert_V.\]
%     Therefore, the linear operator is bounded.

%     In infinite dimensions, linear operators need not be bounded. To see this, define the function $T: \ell^\infty \to \ell^\infty$ by
%     \[T(x_1, x_2, x_3, \dots) = (x_1, 2x_2, 3x_3, \dots).\]
%     This is a linear function. But, it is not bounded- for all $n \in \mathbb{Z}_{\geq 1}$, let
%     \[e_n^{(k)} = \begin{cases}
%         1 & n = k \\
%         0 & n \neq k
%     \end{cases}.\]
%     We have $\lVert e^{(k)} \rVert_\infty = 1$, but $\lVert T(e^{(k)}) \rVert_\infty = n$. So, for all $n \in \mathbb{Z}_{\geq 1}$,
%     \[\lVert T(e^{(k)}) \rVert_\infty \geq n \lVert e^{(k)} \rVert_\infty.\]
%     Therefore, the operator cannot be bounded.

%     \subsection{Bounded linear operator space}
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a linear operator. Then, the following are equivalent:
%         \begin{enumerate}
%             \item $T$ is continuous;
%             \item $T$ is continuous at $\bm{0}$;
%             \item $T$ is bounded.
%         \end{enumerate}
%     \end{proposition}
%     \begin{proof}
%         We show $(1) \implies (2) \implies (3) \implies (1)$.
%         \begin{itemize}
%             \item We know that $(1) \implies (2)$.
            
%             \item We show that $(2) \implies (3)$. Since $T$ is continuous at $\bm{0}$, there exists a $\delta > 0$ such that for $\bm{x} \in V$, if $\lVert \bm{x} \rVert_V < \delta$, then $\lVert T(\bm{x}) \rVert_W < 1$. Now, let $\bm{x} \in V$. If $\bm{x} = \bm{0}$, then 
%             \[\lVert T(\bm{x}) \rVert_W = 0 \leq 0 = \frac{2}{\delta} \lVert \bm{x} \rVert_V.\]
%             Now, if $\bm{x} \neq \bm{0}$, then we have
%             \[\left\lVert\frac{\delta}{2 \lVert \bm{x} \rVert_V} \bm{x} \right\rVert_V = \frac{\delta}{2\lVert \bm{x} \rVert_V} \lVert \bm{x} \rVert_V = \frac{\delta}{2} < \delta.\]
%             So,
%             \[\left\lVert T\left(\frac{\delta}{2 \lVert \bm{x} \rVert_V} \bm{x}\right) \right\rVert_W < 1.\]
%             We have
%             \[\left\lVert T\left(\frac{\delta}{2 \lVert \bm{x} \rVert_V} \bm{x}\right) \right\rVert_W = \left\lVert \frac{\delta}{2 \lVert \bm{x} \rVert_V} T(\bm{x}) \right\rVert_W = \frac{\delta}{2 \lVert \bm{x} \rVert_V} \left\lVert T(\bm{x}) \right\rVert_W.\]
%             This implies that
%             \[\left\lVert T(\bm{x}) \right\rVert_W < \frac{2}{\delta} \lVert \bm{x} \rVert_V.\]
%             So, for all $\bm{x} \in V$,
%             \[\left\lVert T(\bm{x}) \right\rVert_W \leq \frac{2}{\delta} \lVert \bm{x} \rVert_V.\]
%             In that case, $T$ is bounded.
            
%             \item We show that $(3) \implies (1)$. Since $T$ is bounded, there exists a $c > 0$ such that for all $\bm{v} \in V$, $\lVert T(\bm{v}) \rVert_W \leq c \lVert \bm{v} \rVert_V$. Let $\bm{v} \in V$. Let $\bm{u} \in V$ and $\varepsilon > 0$. Set $\delta = \frac{\varepsilon}{c}$. In that case, for $\bm{v} \in V$, if $\lVert \bm{u} - \bm{v} \rVert_V < \delta$, then
%             \begin{align*}
%                 \lVert T(\bm{u}) - T(\bm{v}) \rVert_W &= \lVert T(\bm{u} - \bm{v}) \rVert_W \\
%                 &\leq c \lVert \bm{u} - \bm{v} \rVert_V \\
%                 &< c \cdot \delta = \varepsilon.
%             \end{align*}
%             In that case, $T$ is continuous.
%         \end{itemize}
%         So, the statements are equivalent.
%     \end{proof}
%     Using properties of continuity, this implies that:
%     \begin{itemize}
%         \item if $T: V \to W$ is linear and $\lambda \in \mathbb{R}$, then $\lambda T$ is bounded; and
%         \item if $T, U: V \to W$ are linear, then $T + U$ is bounded.
%     \end{itemize}
%     So, the set of bounded linear operators from $T$ to $V$ is a vector space. It is denoted by $L(V, W)$. Moreover, we can define a norm on the vector space.
%     \begin{definition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a bounded linear operator. We define the \emph{operator norm} of $T$ to be:
%         \[\lVert T \rVert = \sup_{\substack{\bm{v} \in V \\ \lVert \bm{v} \rVert_V = 1}} \lVert T(\bm{v}) \rVert_W.\]
%     \end{definition}
%     \noindent The value $\lVert T \rVert$ is the smallest bound $c \geq 0$ that satisfies $\lVert T(\bm{x}) \rVert_W \leq c \lVert \bm{x} \rVert_V$.

%     We will prove the inequality relating $\lVert T \rVert$ and $\lVert T(\bm{v}) \rVert_W$.
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a bounded linear operator. Then,
%         \[\lVert T(\bm{x}) \rVert_W \leq \lVert T \rVert \lVert \bm{x} \rVert_V.\]
%     \end{proposition}
%     \begin{proof}
%         Let $\bm{v} \in V$. If $\bm{v} = \bm{0}$, then
%         \[\lVert T(\bm{v}) \rVert_W = 0 \leq 0 = \lVert T \rVert \lVert \bm{v} \rVert_V.\]
%         Otherwise, we have $\bm{v} \neq \bm{0}$. We know that
%         \[\left\lVert \frac{1}{\lVert \bm{v} \rVert_V} \bm{v} \right\rVert_V = \frac{1}{\lVert \bm{v} \rVert_V} \lVert \bm{v} \rVert_V = 1.\]
%         So,
%         \[\left\lVert T\left( \frac{1}{\lVert \bm{v} \rVert_V} \bm{v} \right) \right\rVert_W \leq \lVert T \rVert.\]
%         This implies that $\lVert T(\bm{v}) \rVert_W \leq \lVert T \rVert \lVert \bm{v} \rVert_V$.
%     \end{proof}
%     \noindent Using this result, we characterise the operator norm as the supremum of all non-zero values.
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a bounded linear operator. Then,
%         \[\lVert T \rVert = \sup_{\substack{\bm{v} \in V \\ \bm{v} \neq \bm{0}}} \frac{\lVert T(\bm{v}) \rVert_W}{\lVert \bm{v} \rVert_V}.\]
%     \end{proposition}
%     \begin{proof}
%         Let $\bm{v} \in V$ with $\bm{v} \neq \bm{0}$. We know that $\lVert T(\bm{v}) \rVert_W \leq \lVert T \rVert \lVert \bm{v} \rVert_V$. So,
%         \[\lVert T \rVert \geq \sup_{\substack{\bm{v} \in V \\ \bm{v} \neq \bm{0}}} \frac{\lVert T(\bm{v}) \rVert_W}{\lVert \bm{v} \rVert_V}.\]
%         Now, let $\varepsilon > 0$. Since
%         \[\lVert T \rVert = \sup_{\substack{\bm{v} \in V \\ \lVert\bm{v}\rVert_V = 1}} \lVert T(\bm{v}) \rVert_W,\]
%         we can find a $\bm{v} \in V$ with $\lVert \bm{v} \rVert_V = 1$ such that $\lVert T(\bm{v}) \rVert_W  > \lVert T \rVert + \varepsilon$. In that case, $\frac{\lVert T(\bm{v}) \rVert_W}{\lVert \bm{v} \rVert_V} > \lVert T \rVert + \varepsilon$. So, we have
%         \[\lVert T \rVert = \sup_{\substack{\bm{v} \in V \\ \bm{v} \neq \bm{0}}} \frac{\lVert T(\bm{v}) \rVert_W}{\lVert \bm{v} \rVert_V}.\]
%     \end{proof}
%     \noindent Next, we prove that the value $\lVert T \rVert$ is the smallest bound $c \geq 0$ that satisfies $\lVert T(\bm{x}) \rVert_W \leq c \lVert \bm{x} \rVert_V$.
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a bounded linear operator. Define 
%         \[S = \{c \geq 0 \mid \lVert T(\bm{v}) \rVert_W \leq c \lVert \bm{v} \rVert_V \ \forall \bm{v} \in V\}.\]
%         Then,
%         \[\lVert T \rVert = \inf (S).\]
%     \end{proposition}
%     \begin{proof}
%         We know that for all $\bm{v} \in V$, $\lVert T(\bm{v}) \rVert \leq \lVert T \rVert \lVert \bm{v} \rVert_V$. So, $\lVert T \rVert \in S$. Now, let $c \in S$. We know that for all $\bm{v} \in V$, $c\lVert T(\bm{v}) \rVert_W \leq c \lVert \bm{v} \rVert_V$. In that case, for all $\bm{v} \in V$ with $\lVert \bm{v} \rVert_V$, we find that $\lVert T(\bm{v}) \rVert_W \leq c$. Since
%         \[\lVert T \rVert = \sup_{\substack{\bm{v} \in V \\ \lVert \bm{v} \rVert_V = 1}} \lVert T(\bm{v}) \rVert_W,\]
%         we find that $c \geq \lVert T \rVert$. Since $\lVert T \rVert \in S$, we must have $\lVert T \rVert = \inf (S)$.
%     \end{proof}

%     Now, we show that $L(V, W)$ is complete if $W$ is complete.
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $W$ be complete. Then, $L(V, W)$ is complete.
%     \end{proposition}
%     \begin{proof}
%         Let $(T_n)_{n=1}^\infty$ be a Cauchy sequence in $L(V, W)$. For all $\bm{v} \in V$, we have the sequence $(T_n(\bm{v}))_{n=1}^\infty$ in $W$. We show that $(T_n(\bm{v}))$ is Cauchy. If $\bm{v} = \bm{0}$, then we have $T_n(\bm{v}) = \bm{0}$ for all $n \in \mathbb{Z}_{\geq 1}$. So, the sequence $(T_n(\bm{v}))$ is Cauchy. Otherwise, we have $\bm{v} \neq \bm{0}$. Then, let $\varepsilon > 0$. Since $(T_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$ such that if $m, n \geq N$, then $\lVert T_m - T_n \rVert < \frac{\varepsilon}{\lVert \bm{v} \rVert_V}$. In that case, for $m, n \in \mathbb{Z}_{\geq 1}$, such that if $m, n \geq N$, then
%         \begin{align*}
%             \lVert T_m(\bm{v}) - T_n(\bm{v}) \rVert_W &= \lVert (T_m - T_n)(\bm{v}) \rVert_W \\
%             &\leq \lVert T_m - T_n \rVert \lVert \bm{v} \rVert_V  \\
%             &< \frac{\varepsilon}{\lVert \bm{v} \rVert_V} \lVert \bm{v} \rVert_V = \varepsilon.
%         \end{align*}
%         This implies that $(T_n(\bm{v}))$ is Cauchy. Since $W$ is complete, for each $\bm{v} \in V$, we can find a $\bm{w}_{\bm{v}}$ such that $T_n(\bm{v}) \to \bm{w}_{\bm{v}}$. Now, define the function $T: V \to W$ by $T(\bm{v}) = \bm{w}_{\bm{v}}$.

%         First, we claim that $T$ is linear. For all $\bm{v}_1, \bm{v}_2 \in V$ and $n \in \mathbb{Z}_{\geq 1}$,
%         \[T_n(\bm{v}_1 + \bm{v}_2) = T_n(\bm{v}_1) + T_n(\bm{v}_2).\]
%         We have $T_n(\bm{v}_1 + \bm{v}_2) \to T(\bm{v}_1 + \bm{v}_2)$, $T_n(\bm{v}_1) \to T(\bm{v}_1)$ and $T_n(\bm{v_2}) \to T(\bm{v}_2)$. Since limits are unique, this implies that $T(\bm{v}_1 + \bm{v}_2) = T(\bm{v}_1) + T(\bm{v}_2)$. Now, for $\bm{v} \in V$, $\lambda \in \mathbb{R}$ and $n \in \mathbb{Z}_{\geq 1}$,
%         \[T_n(\lambda \bm{v}) = \lambda T_n(\bm{v}).\]
%         Since $T_n(\lambda \bm{v}) \to T(\lambda \bm{v})$ and $T_n(\bm{v}) \to T(\bm{v})$, we find that $T(\lambda \bm{v}) = \lambda T(\bm{v})$. This implies that $T$ is linear.

%         Next, we claim that $T$ is bounded. Since $(T_n)$ is Cauchy, there exists an $N \in \mathbb{Z}_{\geq 1}$ such that for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m - T_n \rVert < 1$. In particular, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m(\bm{v}) - T_n(\bm{v}) \rVert_W \leq \lVert \bm{v} \rVert_V$ for all $\bm{v} \in V$. We know that $T_N$ is bounded. So, there exists a $c > 0$ such that for all $\bm{v} \in V$, $\lVert T_n(\bm{v}) \rVert_W \leq c \lVert \bm{v} \rVert_V$. Now, let $\bm{v} \in V$. Since $T_n(\bm{v}) \to T(\bm{v})$, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for all $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N'$, then $\lVert T_n(\bm{v}) - T(\bm{v}) \rVert_W \leq \lVert \bm{v} \rVert_V$. Now, fix $n = \max(N, N')$. In that case,
%         \begin{align*}
%             \lVert T(\bm{v}) \rVert_V &\leq \lVert T(\bm{v}) - T_n(\bm{v}) \rVert_W + \lVert T_n(\bm{v}) - T_N(\bm{v}) \rVert_W + \lVert T_N(\bm{v}) \rVert_W \\
%             &\leq (2 + c) \lVert \bm{v} \rVert_V.
%         \end{align*}
%         This implies that $T$ is bounded.

%         Finally, we show that $T_n \to T$. Let $\varepsilon > 0$. Since $(T_n)$ is Cauchy, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m - T_n \rVert < \frac{\varepsilon}{3}$. In particular, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then $\lVert T_m(\bm{v}) - T_n(\bm{v}) \rVert_W \leq \frac{\varepsilon}{3} \lVert \bm{v} \rVert_V$ for all $\bm{v} \in V$. Now, let $n \in \mathbb{Z}_{\geq 1}$ such that $n \geq N$. Moreover, let $\bm{v} \in V$ with $\lVert \bm{v} \rVert_V = 1$. Since $T_n(\bm{v}) \to T(\bm{v})$, we can find an $N' \in \mathbb{Z}_{\geq 1}$ such that for $m \in \mathbb{Z}_{\geq 1}$, if $m \geq N'$, then $\lVert T_m(\bm{v}) - T(\bm{v}) \rVert_W < \frac{\varepsilon}{3}$. Now, fix $m = \max(N, N')$. In that case,
%         \begin{align*}
%             \lVert T_n(\bm{v}) - T(\bm{v}) \rVert_W &\leq \lVert T_n(\bm{v}) - T_m(\bm{v})\rvert_W + \lVert T_m(\bm{v}) - T(\bm{v}) \rVert_W \\
%             &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \frac{2}{3} \varepsilon.
%         \end{align*}
%         That is, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then for all $\bm{v} \in V$ with $\lVert \bm{v} \rVert_V = 1$,
%         \[\lVert T_n(\bm{v}) - T(\bm{v}) \rVert_W < \frac{2}{3} \varepsilon.\]
%         This implies that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%         \[\lVert T_n - T \rVert = \sup_{\substack{\bm{v} \in V \\ \lVert \bm{v} \rVert_V = 1}} \lVert T_n(\bm{v}) - T(\bm{v}) \rVert_W \leq \frac{2}{3} \varepsilon < \varepsilon.\]
%         So, $T_n \to T$. In that case, $L(V, W)$ is complete.
%     \end{proof}
%     \newpage

%     \section{Banach theory}
%     \begin{definition}
%         Let $V$ be a normed vector space. Then, a bounded linear map $T: V \to \mathbb{R}$ is a \emph{linear functional}.
%     \end{definition}

%     \begin{definition}
%         Let $V$ be a normed vector space, and let $p: V \to \mathbb{R}$ be a function. Then, $p$ is a \emph{sub-linear functional} if:
%         \begin{itemize}
%             \item $p(\lambda \bm{v}) = \lambda p(\bm{v})$ for all $\bm{v} \in V$, $\lambda \in \mathbb{R}$, and
%             \item $p(\bm{u} + \bm{v}) \leq p(\bm{u}) + p(\bm{v})$ for all $\bm{u}, \bm{v} \in V$.
%         \end{itemize}
%     \end{definition}

%     \begin{theorem}[The Hahn-Banach Theorem]
%         Let $V$ be a normed vector space and $p: V \to \mathbb{R}$ be a sub-linear functional. Let $H$ be a subspace of $V$, and $f: H \to \mathbb{R}$ be a linear such that $f(\bm{x}) \leq p(\bm{x})$ for all $\bm{x} \in H$. Then, there exists a linear functional $F: V \to \mathbb{R}$ such that $F(\bm{x}) = f(\bm{x})$ for all $\bm{x} \in H$ and $F(\bm{x}) \leq p(\bm{x})$ for all $\bm{x} \in V$.
%     \end{theorem}
%     \begin{proof}
%         Let $\bm{y} \in V \setminus H$. We show that there exists a linear functional $G: S \to \mathbb{R}$ such that $G(\bm{x}) = f(\bm{x})$ for all $\bm{x} \in H$ and $G(\bm{x}) \leq p(\bm{x})$ for all $\bm{x} \in S$, where
%         \[S = \{\bm{x} + \lambda \bm{y} \mid \bm{x} \in H, \lambda \in \mathbb{R}\}.\]
%         Now, let $\bm{x}_1, \bm{x}_2 \in H$. We find that 
%         \begin{align*}
%             f(\bm{x}_1) + f(\bm{x}_2) &= f(\bm{x}_1 + \bm{x}_2) \\
%             &\leq p(\bm{x}_1 + \bm{x}_2) \\
%             &\leq p(\bm{x}_1 - \bm{y}) + p(\bm{x}_2 + \bm{y}).
%         \end{align*}
%         So, we find that for all $\bm{x}_1, \bm{x}_2 \in H$,
%         \[f(\bm{x}_1) - p(\bm{x}_1 - \bm{y}) \leq p(\bm{x}_2 + \bm{y}) - f(\bm{x}_2).\]
%         This implies that
%         \[\sup_{\bm{x} \in H} f(\bm{x}) - p(\bm{x} - \bm{y}) \leq \inf_{\bm{x} \in H} p(\bm{x} + \bm{y}) - f(\bm{x}).\]
%         Next, let $\alpha \in \mathbb{R}$ such that
%         \[\sup_{\bm{x} \in H} f(\bm{x}) - p(\bm{x} - \bm{y}) \leq \alpha \leq \inf_{\bm{x} \in H} p(\bm{x} + \bm{y}) - f(\bm{x}).\]
%         Define the function $G: S \to \mathbb{R}$ by $G(\bm{x} + \lambda \bm{y}) = f(\bm{x}) + \alpha \lambda$. Then, $G$ is linear, with $G(\bm{x}) = f(\bm{x})$ for all $\bm{x} \in H$. Now, we show that $G(\bm{x}) \leq p(\bm{x})$ for all $\bm{x} \in S$. So, let $\bm{x} + \lambda \bm{y} \in S$. If $\lambda = 0$, then we have 
%         \[G(\bm{x} + \lambda \bm{y}) = f(\bm{x}) \leq p(\bm{x}) = p(\bm{x} + \lambda \bm{y}).\]
%         Next, assume that $\lambda > 0$. Then,
%         \begin{align*}
%             G(\bm{x} + \lambda \bm{y}) &= f(\bm{x}) + \lambda \alpha \\
%             &\leq f(\bm{x}) + \lambda (p(\bm{x}/\lambda + \bm{y}) - f(\bm{x}/\lambda)) \\
%             &= f(\bm{x}) + p(\bm{x} + \lambda \bm{y}) - f(\bm{x}) \\
%             &= p(\bm{x} + \lambda \bm{y}).
%         \end{align*}
%         Otherwise, we have $\lambda < 0$. Then,
%         \begin{align*}
%             G(\bm{x} + \lambda \bm{y}) &= f(\bm{x}) + \lambda \alpha \\
%             &\leq f(\bm{x}) + \lambda (f(-\bm{x}/\lambda) - p(-\bm{x}/\lambda - y)) \\
%             &= f(\bm{x}) - f(\bm{x}) + p(\bm{x} + \lambda \bm{y}) \\
%             &= p(\bm{x} + \lambda \bm{y}).
%         \end{align*}
%         So, for all $\bm{x} + \lambda \bm{y} \in S$, $G(\bm{x} + \lambda \bm{y}) \leq p(\bm{x} + \lambda \bm{y})$. Now, we can keep extending the function $G$ from $S$ up to $V$, and get the required result.
%     \end{proof}

%     \begin{corollary}
%         Let $V$ be a normed vector space, $H \subseteq V$ be a closed subspace, $\bm{y} \in V \setminus H$, and let 
%         \[\delta = \inf_{\bm{x} \in H} \lVert \bm{y} - \bm{x} \rVert.\]
%         Then, we can find a non-trivial linear functional $F: V \to \mathbb{R}$ such that $H \subseteq \ker F$, $\lVert F \rVert = 1$ and $F(\bm{y}) = \delta$.
%     \end{corollary}
%     \begin{proof}
%         Let
%         \[S = \{\bm{x} + \lambda \bm{y} \mid \bm{y} \in H, \lambda \in \mathbb{R}\}.\]
%         Define the function $f: S \to \mathbb{R}$ by $f(\bm{x} + \lambda \bm{y}) = \lambda \delta$. By definition, it is a non-trivial linear functional. We find that for all $\bm{x} + \lambda \bm{y} \in S$,
%         \[|f(\bm{x} + \lambda \bm{y})| = |\lambda \delta| \leq |\lambda| \cdot \left\lVert \bm{y} - \left(-\frac{\bm{x}}{\lambda}\right) \right\rVert = \lVert \bm{x} + \lambda \bm{y}\rVert.\]
%         So, the Hahn-Banach theorem tells us that there exists an extension of $f$, given by $F: V \to \mathbb{R}$. 

%         \noindent We know that for all $\bm{x} \in H \subseteq S$,
%         \[F(\bm{x} + \lambda \bm{y}) = f(\bm{x}) = \bm{0}.\]
%         So, $H \subseteq \ker F$. Moreover, since $\bm{y} \in S$, we find that
%         \[F(\bm{y}) = f(\bm{y}) = f(\bm{0} + 1 \cdot \bm{y}) = \delta.\]
%         By the Hahn-Banach theorem, we know that for all $\bm{x} \in V$, $\lVert F(\bm{x}) \rVert \leq \lVert \bm{x} \rVert$. In that case, $\lVert F \rVert \leq 1$. 
%         % TODO: Show that $\lVert F \rVert = 1$
%     \end{proof}
%     \noindent Now, let $V$ be a normed vector space and let $\bm{x} \in V$ with $\bm{x} \neq \bm{0}$. Then, $\{\bm{0}\} \subseteq V$ is a closed subspace with $\bm{x} \not\in \{\bm{0}\}$. So, the result above tells us that there exists a non-trivial linear functional $f: V \to \mathbb{R}$ such that $\lVert f \rVert = 1$ and $\lVert f(\bm{x}) \rVert = \lVert \bm{x} \rVert$.

%     \begin{corollary}
%         Let $V$ be a normed vector space, and let $\bm{x}, \bm{y} \in V$ with $\bm{x} \neq \bm{y}$. Then, there exists a linear functional $f: V \to \mathbb{R}$ such that $f(\bm{x}) \neq f(\bm{y})$.
%     \end{corollary}
%     \begin{proof}
%         Since $\bm{x} \neq \bm{y}$, the result above tells us that there exists a linear functional $f: V \to \mathbb{R}$ such that 
%         \[\lVert f(\bm{x} - \bm{y})\rVert = \lVert \bm{x} - \bm{y} \rVert > 0.\]
%         This implies that $f(\bm{x} - \bm{y}) \neq \bm{0}$, and so $f(\bm{x}) \neq f(\bm{y})$.
%     \end{proof}
    
%     \begin{corollary}
%         Let $V$ be a normed vector space. For each $\bm{v} \in V$, define the map $ev_{\bm{v}}: V^* \to \mathbb{R}$ by $ev_{\bm{v}}(f) = f(\bm{v})$. Then, the map $\iota: V \to V^{**}$ given by $\iota(\bm{v}) = ev_{\bm{v}}$ is a linear isometry.
%     \end{corollary}
%     \begin{proof}
%         We find that for $\bm{v}_1, \bm{v}_2 \in V$ and $f \in V^*$,
%         \begin{align*}
%             \iota(\bm{v}_1 + \bm{v}_2)(f) &= ev_{\bm{v}_1 + \bm{v_2}}(f) \\
%             &= f(\bm{v}_1 + \bm{v}_2) \\
%             &= f(\bm{v}_1) + f(\bm{v}_2) \\
%             &= ev_{\bm{v}_1}(f) + ev_{\bm{v}_2}(f) \\
%             &= \iota(\bm{v}_1)(f) + \iota(\bm{v}_2)(f).
%         \end{align*}
%         This implies that $\iota(\bm{v}_1 + \bm{v}_2) = \iota(\bm{v}_1) + \iota(\bm{v}_2)$. Now, for $\bm{v} \in V$ and $f \in V^*$,
%         \begin{align*}
%             \iota(\lambda \bm{v})(f) &= ev_{\lambda \bm{v}}(f) \\
%             &= f(\lambda \bm{v}) \\
%             &= \lambda f(\bm{v}) \\
%             &= \lambda ev_{\bm{v}}(f) \\
%             &= \lambda \iota (\bm{v})(f).
%         \end{align*}
%         So, $\iota(\lambda \bm{v}) = \lambda \iota(\bm{v})$. This implies that $\iota$ is a linear map. 

%         \noindent Now, for $\bm{v} \in V$ and $f \in V^*$,
%         \[\lVert \iota(\bm{v})(f) \rVert = \lVert f(\bm{v}) \rVert \leq \lVert f \rVert \lVert \bm{v} \rVert.\]
%         This implies that $\lVert \iota \rVert = 1$, using the result above. So, $\iota$ is an isometry.
%         % TODO: Understand and explain
%     \end{proof}
    
%     \subsection{Open maps}
%     \begin{theorem}[Baire-Category Theorem]
%         Let $X$ be a complete metric space, and let $(U_n)_{n=1}^\infty$ be a collection of dense open sets in $X$. Then,
%         \begin{itemize}
%             \item the intersection
%             \[\bigcap_{n=1}^\infty U_n\]
%             is dense in $X$;
%             \item $X$ cannot be written as a countable union of nowhere dense sets.
%         \end{itemize}
%     \end{theorem}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Let $W \subseteq X$ be open and non-empty. We show that
%             \[W \cap \bigcap_{n=1}^\infty U_n\]
%             is not empty. So, let $V_0 = W$. We know that $U_1$ is dense, so $V_0 \cap U_1$ is not empty. Moreover, since $V_0$ and $U_1$ are open, we find that the intersection is open. So, there exists an $x_1 \in V_0 \cap U_1$ such that $B_X(x_n, r_n) \subseteq V_0 \cap U_1$. So, set $V_1 = B_X(x_1, r_1)$. We can iteratively define $V_n$ for $n \in \mathbb{Z}_{\geq 1}$. Without loss of generality, we may assume that $r_n < \frac{1}{2n}$ and 
%             \[\overline{B}_X(x_n, r_n) \subseteq V_{n-1} \cap U_n.\]
%             We claim that the sequence $(x_n)_{n=1}^\infty$ is Cauchy. Let $\varepsilon > 0$. Choose a natural number $N \in \mathbb{Z}_{\geq 1}$ such that $N > \frac{1}{\varepsilon}$. Let $m, n \in \mathbb{Z}_{\geq 1}$ with $m, n \geq N$. Then, we have $x_m, x_n \in V_N = B_X(x_N, \frac{1}{2N})$. This implies that
%             \[d(x_m, x_n) \leq d(x_m, x_N) + d(x_N, x_n) < \frac{1}{2N} + \frac{1}{2N} = \frac{1}{N} < \varepsilon.\]
%             So, $(x_n)$ is Cauchy. Since $X$ is complete, there exists an $x \in X$ such that $x_n \to x$. 

%             \noindent Finally, we claim that $x \in V_n$ for all $n \in \mathbb{Z}_{\geq 1}$. Let $n \in \mathbb{Z}_{\geq 1}$. For all $m \in \mathbb{Z}_{\geq 1}$, if $m > n$, then we know that $x_m \in V_{n+1}$. In that case, the sequence $(x_m)_{m=n+1}^\infty$ is in $V_{n+1}$. So, the limit $x$ must be in the closure, i.e.
%             \[x \in \overline{V_{n+1}} \subseteq V_n \cap U_{n+1} \subseteq V_n.\]
%             This implies that $x \in V_n$. Therefore,
%             \[x \in W \cap \bigcap_{n=1}^\infty U_n.\]
%             This implies that the intersection 
%             \[\bigcap_{n=1}^\infty U_n\]
%             is dense.
            
%             \item Assume, for a contradiction, that $X$ can be written as a countable union of nowhere dense sets. So, let $(V_n)_{n=1}^\infty$ be a collection of nowhere dense sets in $X$ such that
%             \[X = \bigcup_{n=1}^\infty V_n.\]
%             In that case,
%             \[\varnothing = X \setminus \bigcup_{n=1}^\infty \overline{V_n} = \bigcap_{n=1}^\infty X \setminus \overline{V_n}.\]
%             We know that for each $n \in \mathbb{Z}_{\geq 1}$, $X \setminus \overline{V_n}$ is open and dense. From the result above, we know that the intersection is dense, i.e. it is not empty. This is a contradiction. So, $V$ cannot be written as a countable union of nowhere dense sets.
%         \end{itemize}
%     \end{proof}

%     \begin{definition}
%         Let $X$ and $Y$ be topological spaces, and let $f: X \to Y$ be a function. Then, $f$ is an \emph{open map} if for all $U \subseteq X$, $f(U) \subseteq Y$ is open.
%     \end{definition}
    
%     \begin{proposition}
%         Let $X$ and $Y$ be metric spaces and let $f: X \to Y$ be a function. Then, $f$ is an open map if and only if for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $f$ is an open map. Let $x \in X$ and $\delta > 0$. Let
%             \[U = B_X(x, \delta).\]
%             Since $f$ is an open map, we know that $f(U)$ is open. We have $f(x) \in f(U)$. In that case, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then $f(y) \in f(B_X(x, \delta))$. So, there exists a $z \in X$ with $d_X(x, z) < \delta$ with $f(y) = f(z)$. That is, for all $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$.
            
%             \item Assume that for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon$, then there exists a $z \in X$ such that $d_X(x, z) < \delta$ with $f(y) = f(z)$. Let $U \subseteq X$ be open. We show that $f(U)$ is open. So, let $x \in U$. Since $U$ is open, there exists a $\delta_x > 0$ such that for all $y \in X$, if $d_X(x, y) < \delta_x$, then $y \in U$. Now, we can find an $\varepsilon_x > 0$ such that for $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon_x$, then there exists a $z \in X$ such that $d_X(x, z) < \delta_x$ with $f(y) = f(z)$. This implies that $z \in U$. So, $f(y) = f(z) \in f(U)$. In that case, for all $x \in X$, there exists an $\varepsilon_x$ such that for all $y \in X$, if $d_Y(f(x), f(y)) < \varepsilon_x$, then $f(y) \in f(U)$. This implies that $f(U)$ is open. In other words, $f$ is an open map.
%         \end{itemize}
%     \end{proof}
%     \noindent Another way of writing this is the following- $f: X \to Y$ is an open map if and only if for every $x \in X$ and $\delta > 0$, there exists an $\varepsilon > 0$ such that
%     \[B_Y(f(x), \varepsilon) \subseteq f(B_X(x, \delta)).\]

%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, and let $T: V \to W$ be a linear operator. Then, $T$ is an open map if and only if there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $T$ is an open map. Set $\bm{x} = \bm{0}$ and $\delta = 1$. In that case, there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) - T(\bm{x}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} - \bm{x} \rVert_V < \delta$ with $T(\bm{u}) = T(\bm{v})$. That is, there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$.
            
%             \item Assume that there exists an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v})$. We show that $T$ is an open map. Let $\bm{x} \in V$ and $\delta > 0$. We can find an $\varepsilon > 0$ such that for $\bm{v} \in V$, if $\lVert T(\bm{v} - \bm{x}) \rVert_W < \frac{\varepsilon}{\delta}$, then there exists a $\bm{u} \in V$ such that $\lVert \frac{1}{\delta}\bm{u} \rVert_V < 1$ with $T(\bm{u}) = T(\bm{v} - \bm{x})$. Using linearity and replacing $\bm{u}$ with $\bm{u} + \delta\bm{x}$; $\bm{v}$ with $\delta \bm{v}$; $\bm{x}$ with $\delta \bm{x}$, we find that for $\bm{v} \in V$, if $\lVert T(\bm{v}) - T(\bm{x}) \rVert_W < \varepsilon$, then there exists a $\bm{u} \in V$ such that $\lVert \bm{u} - \bm{x} \rVert_V < \delta$ with $T(\bm{u}) = T(\bm{v})$. So, $T$ is an open map.
%         \end{itemize}
%     \end{proof}
%     \noindent Another way of writing this is the following- $T: V \to W$ is an open map if and only if there exists an $\varepsilon > 0$ such that
%     \[B_W(0, \varepsilon) \subseteq f(B_V(0, 1)).\]

%     \begin{theorem}[Open Mapping Theorem]
%         Let $V$ and $W$ be Banach spaces, and let $T: V \to W$ be a surjective bounded linear operator. Then, $T$ is an open map.
%     \end{theorem}
%     \begin{proof}
%         % TODO
%     \end{proof}
%     % TODO: Counterexample

%     \begin{corollary}
%         Let $V$ and $W$ be Banach spaces, and let $T: V \to W$ be a bijective linear bounded operator. Then, $T$ is an isomorphism.
%     \end{corollary}
%     \begin{proof}
%         Since $T$ is surjective, the open mapping theorem tells us that $T$ is an open map. In that case, for all $U \subseteq V$ open, $f(U) \subseteq W$ is open. That is, for all $U \subseteq V$ open, the preimage of the inverse $(f^{-1})^{-1}(U) = f(U)$ is open. So, $T^{-1}$ is a bounded (linear) operator. Therefore, $T$ is an isomorphism.
%     \end{proof}

%     \subsection{Graphs}
%     \begin{definition}
%         Let $X$ and $Y$ be sets. Then, the \emph{graph of $f$} is the set
%         \[\operatorname{Graph} (f) = \{(x, f(x)) \mid x \in X\}.\]
%     \end{definition}

%     For normed vector spaces $V$ and $W$, we will use the following norm on $V \times W$:
%     \[\lVert (\bm{v}, \bm{w}) \rVert_\infty = \max(\lVert \bm{v} \rVert_V, \lVert \bm{w} \rVert_W).\]
%     So, $V \times W$ is a normed vector space as well. By this definition, we can preserve properties that $V$ and $W$ both have in $V \times W$.
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, let $(\bm{v}_n, \bm{w}_n)_{n=1}^\infty$ be a sequence in $V \times W$, and let $(\bm{v}, \bm{w}) \in V \times W$. Then, $(\bm{v}_n, \bm{w}_n) \to (\bm{v}, \bm{w})$ if and only if $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $(\bm{v}_n, \bm{w}_n) \to (\bm{v}, \bm{w})$. Let $\varepsilon > 0$. We can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%             \[\lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}, \bm{w}) \rVert_\infty < \varepsilon.\]
%             In that case, we have
%             \begin{align*}
%                 \max(\lVert \bm{v}_n - \bm{v} \rVert_V, \lVert \bm{w}_n - \bm{w} \rVert_W) &= \lVert (\bm{v}_n - \bm{v}, \bm{w}_n - \bm{w}) \rVert_\infty \\
%                 &= \lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}, \bm{w}) \rVert_\infty < \varepsilon.
%             \end{align*}
%             So, we have both $\lVert \bm{v}_n - \bm{v} \rVert_V < \varepsilon$ and $\lVert \bm{w}_n - \bm{w} \rVert_W < \varepsilon$. This implies that $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$.

%             \item Assume that $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$. Let $\varepsilon > 0$. We can find $N_1, N_2 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_1$, then 
%             \[\lVert \bm{v}_n - \bm{v} \rVert_V < \varepsilon,\]
%             and if $n \geq N_2$, then 
%             \[\lVert \bm{w}_n - \bm{w} \rVert_W < \varepsilon.\]
%             In that case, set $N = \max(N_1, N_2)$. Then, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%             \begin{align*}
%                 \lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}, \bm{w}) \rVert_\infty &= \lVert (\bm{v}_n - \bm{v}, \bm{w}_n - \bm{w}) \rVert_\infty \\
%                 &= \max(\lVert \bm{v}_n - \bm{v} \rVert_V, \lVert \bm{w}_n - \bm{w} \rVert_W) < \varepsilon.
%             \end{align*}
%             Therefore, $(\bm{v}_n, \bm{w}_n) \to (\bm{v}, \bm{w})$.
%         \end{itemize}
%     \end{proof}
    
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces, let $(\bm{v}_n, \bm{w}_n)_{n=1}^\infty$ be a sequence in $V \times W$. Then, $(\bm{v}_n, \bm{w}_n)$ is Cauchy if and only if $(\bm{v}_n)$ and $(\bm{w}_n)$ are Cauchy.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $(\bm{v}_n, \bm{w}_n)$ is Cauchy. Let $\varepsilon > 0$. We can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then
%             \[\lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}_m, \bm{w}_m) \rVert_\infty < \varepsilon.\]
%             In that case, we have
%             \begin{align*}
%                 \max(\lVert \bm{v}_n - \bm{v}_m \rVert_V, \lVert \bm{w}_n - \bm{w}_m \rVert_W) &= \lVert (\bm{v}_n - \bm{v}_m, \bm{w}_n - \bm{w}_m) \rVert_\infty \\
%                 &= \lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}_m, \bm{w}_m) \rVert_\infty < \varepsilon.
%             \end{align*}
%             So, we have both $\lVert \bm{v}_n - \bm{v}_m \rVert_V < \varepsilon$ and $\lVert \bm{w}_n - \bm{w}_m \rVert_W < \varepsilon$. This implies that $(\bm{v}_n)$ and $(\bm{v}_n)$ are Cauchy.

%             \item Assume that $(\bm{v}_n)$ and $(\bm{w}_n)$ are Cauchy. Let $\varepsilon > 0$. We can find $N_1, N_2 \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N_1$, then 
%             \[\lVert \bm{v}_n - \bm{v}_m \rVert_V < \varepsilon,\]
%             and if $m, n \geq N_2$, then 
%             \[\lVert \bm{w}_n - \bm{w}_m \rVert_W < \varepsilon.\]
%             In that case, set $N = \max(N_1, N_2)$. Then, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then
%             \begin{align*}
%                 \lVert (\bm{v}_n, \bm{w}_n) - (\bm{v}_m, \bm{w}_m) \rVert_\infty &= \lVert (\bm{v}_n - \bm{v}_m, \bm{w}_n - \bm{w}_m) \rVert_\infty \\
%                 &= \max(\lVert \bm{v}_n - \bm{v}_m \rVert_V, \lVert \bm{w}_n - \bm{w}_m \rVert_W) < \varepsilon.
%             \end{align*}
%             Therefore, $(\bm{v}_n, \bm{w}_n)$ is Cauchy.
%         \end{itemize}
%     \end{proof}
    
%     \begin{proposition}
%         Let $V$ and $W$ be normed vector spaces. Then, $V \times W$ is a Banach space if and only if $V$ and $W$ are both Banach spaces.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $V \times W$ is a Banach space. Let $(\bm{v}_n)_{n=1}^\infty$ and $(\bm{w}_n)_{n=1}^\infty$ be Cauchy sequences in $V$ and $W$ respectively. In that case, the sequence $(\bm{v}_n, \bm{w}_n)$ is a Cauchy sequence. Since $V \times W$ is complete, there exists a $(\bm{v}, \bm{w}) \in V \times W$ such that $(\bm{v}_n, \bm{w}_n) \to (\bm{v}, \bm{w})$. So, we must have $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$. This implies that $V$ and $W$ are complete.
            
%             \item Assume that $V$ and $W$ are Banach spaces. Let $(\bm{v}_n, \bm{w}_n)_{n=1}^\infty$ be a Cauchy sequence in $V \times W$. In that case, the sequences $(\bm{v}_n)$ and $(\bm{w}_n)$ are Cauchy sequences in $V$ and $W$ respectively. Since $V$ and $W$ are complete, there exists a $\bm{v} \in V$ and a $\bm{w} \in W$ such that $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$.
%         \end{itemize}
%     \end{proof}

%     \begin{definition}
%         Let $V$, $W$ be normed vector spaces and let $T: V \to W$ be a linear operator. We say that $T$ is \emph{closed} if $\operatorname{Graph} (T) \subseteq V \times W$ is closed.
%     \end{definition}

%     \begin{proposition}
%         Let $V$, $W$ be normed vector spaces and let $T: V \to W$ be a bounded linear operator. Then, $T$ is closed.
%     \end{proposition}
%     \begin{proof}
%         Let $(\bm{v}_n, T(\bm{v}_n))_{n=1}^\infty$ be a sequence in $\operatorname{Graph} (T)$, with $(\bm{v}_n, T(\bm{v}_n)) \to (\bm{v}, \bm{w})$, for some $(\bm{v}, \bm{w}) \in V \times W$. Under the $\lVert . \rVert_\infty$ norm, this implies that $\bm{v}_n \to \bm{v}$ and $T(\bm{v}_n) \to \bm{w}$. Since $T$ is bounded, it is continuous. So, $T(\bm{v}) \to T(\bm{v})$ as well. In that case, $T(\bm{v}) = \bm{w}$. This implies that $(\bm{v}, \bm{w}) = (\bm{v}, T(\bm{v})) \in \operatorname{Grap} (T)$. So, $\operatorname{Graph} (T) \subseteq V \times W$ is closed.
%     \end{proof}

%     \begin{theorem}[Closed Graph Theorem]
%         Let $V$, $W$ be Banach spaces and let $T: V \to W$ be a closed linear operator. Then, $T$ is bounded.
%     \end{theorem}
%     \begin{proof}
%         Since $T$ is closed, we know that $\operatorname{Graph} (T) \subseteq V \times W$ is closed. The spaces $V$ and $W$ are complete, so the product space $V \times W$ is also complete. So, the closed subspace $\operatorname{Graph} (T)$ is complete. In particular, it is a Banach space under the $\lVert . \rVert_\infty$ norm.

%         \noindent Now, define the projection maps $\pi_V: V \times W \to V$ and $\pi_W: V \times W \to W$ by $\pi_V(\bm{v}, \bm{w}) = \bm{v}$ and $\pi_W(\bm{v}, \bm{w}) = \bm{w}$. We know that for all $(\bm{v}, \bm{w}) \in V \times W$,
%         \[\lVert \pi_V(\bm{v}, \bm{w}) \rVert_V = \lVert \bm{v} \rVert_V \leq \lVert \bm{v}, \bm{w} \rVert_\infty.\]
%         This implies that $\pi_V$ is a bounded operator. Similarly, $\pi_W$ is also bounded.

%         \noindent Next, let $\pi: \operatorname{Graph}(T) \to V$ be the restriction of $\pi_V$. We claim that $\pi_V$ is bijective. Let $(\bm{v}_1, T(\bm{v}_1)), (\bm{v}_2, T(\bm{v}_2)) \in V \times W$ with $\pi(\bm{v}_1, T(\bm{v}_1)) = \pi(\bm{v}_2, T(\bm{v}_2))$. In that case,
%         \[\bm{v}_1 = \pi(\bm{v}_1, T(\bm{v}_1)) = \pi(\bm{v}_2, T(\bm{v}_2)) = \bm{v}_2.\]
%         So, $\pi$ is injective. Further, let $\bm{v} \in V$. We have $(\bm{v}, T(\bm{v})) \in \operatorname{Graph}(T)$. In that case,
%         \[\pi(\bm{v}, T(\bm{v})) = \bm{v}.\]
%         So, $\pi$ is surjective as well. This implies that $\pi$ is a bijective linear bounded operator. Since $\operatorname{Graph} (T)$ and $V$ are Banach spaces, this implies that the inverse map $\pi^{-1}$ is a linear bounded operator as well.

%         \noindent Finally, we claim that $T = \pi_W \circ \pi^{-1}$. Let $\bm{v} \in V$. We find that
%         \begin{align*}
%             (\pi_W \circ \pi^{-1})(\bm{v}) &= \pi_W(\pi^{-1}(\bm{v})) \\
%             &= \pi_W(\bm{v}, T(\bm{v})) \\
%             &= T(\bm{v}).
%         \end{align*}
%         So, $T = \pi_W \circ \pi^{-1}$. We know that both $\pi^{-1}$ and $\pi_W$ are bounded, so their composition $T$ is also bounded.
%     \end{proof}
%     % TODO: Counterexample

%     \subsection{Compact Operators}
%     \begin{definition}
%         Let $V, W$ be normed vector spaces and let $T: V \to W$ be a linear operator. Then, $T$ is \emph{compact} if for any bounded sequence $(\bm{v}_n)_{n=1}^\infty$ in $V$, the sequence $(T\bm(v)_n)$ in $W$ has a convergent subsequence.
%     \end{definition}
%     \noindent We can characterise the concept of a compact operator with a compact space.
%     \begin{proposition}
%         Let $V, W$ be normed vector spaces and let $T: V \to W$ be a linear operator. Then, $T$ is compact if and only if $T(\overline{B}_V(\bm{0}, 1))$ is compact.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item First, assume that $T$ is compact. Let $(\bm{x}_n)_{n=1}^\infty$ be a sequence in $\overline{B}_V(\bm{0}, 1)$. We know that $(\bm{x}_n)$ is bounded. So, we know that $(T(\bm{x}_n))$ has a convergent subsequence. This implies that $T(\overline{B}_V(\bm{0}, 1))$ is compact.
            
%             \item Now, assume that $T(\overline{B}_V(\bm{0}, 1))$ is compact. Let $(\bm{x}_n)_{n=1}^\infty$ be a bounded sequence. Without loss of generality, assume that for all $m, n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{x}_m - \bm{x}_n \rVert \leq 1$.\sidefootnote{Since the sequence is bounded, we can find a $K > 0$ such that for all $n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{x}_n \rVert \leq K$. In that case, we have $\lVert \bm{x}_m - \bm{x}_n \rVert \leq 2K$. So, we can scale by $\frac{1}{2K}$ to achieve this.} Next, define the sequence $(\bm{y}_n)_{n=1}^\infty$ in $V$ given by $\bm{y}_n = \bm{x}_n - \bm{x}_1$. We know that for all $n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{x}_m - \bm{x}_1 \rVert \leq 1$. So, the sequence $(\bm{y}_n)$ is in $\overline{B}_V(\bm{0}, 1)$. This implies that $(\bm{y}_n)$ has a convergent subsequence $(\bm{y}_{n_k})_{k=1}^\infty$. In that case, $(\bm{x}_{n_k})$ is also a convergent subsequence. This implies that $T$ is compact.
%         \end{itemize}
%     \end{proof}

%     We will now consider an example of a compact operator. Define the map $T: \ell^\infty \to \ell^\infty$ by
%     \[T(x_1, x_2, x_3, x_4, \dots) = (x_1, x_2, 0, 0, \dots).\]
%     This is a compact operator since for any $(x_n)_{n=1}^\infty$ in $\ell^\infty$, $T(\bm{x}_n)_{n=3}^\infty$ is a convergent subsequence of $(T(\bm{x}_n))_{n=1}^\infty$.

%     Now, we show that a compact operator must be bounded.
%     \begin{proposition}
%         Let $V, W$ be normed vector spaces and let $T: V \to W$ be a compact operator. Then, $T$ is bounded.
%     \end{proposition}
%     \begin{proof}
%         Assume that $T$ is not bounded. So, there exists a sequence $(\bm{v}_n)_{n=1}^\infty$ in $V$ such that for all $n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{v}_n \rVert \leq 1$ and $\lVert T(\bm{v}_n) \rVert_W \geq n$. Then, $(T(\bm{v}_n))$ cannot have a convergent subsequence, since the subsequence would need to be bounded. Therefore, $T$ cannot be compact. So, if $T$ is compact, then $T$ is bounded.
%     \end{proof}
%     \noindent The converse of this statement is however false. Let $T: \ell^\infty \to \ell^\infty$ be the identity function. This is clearly a bounded function. Now, define the sequence $(\bm{e}^{(k)})_{k=1}^\infty$ given by
%     \[\bm{e}^{(k)}_n = \begin{cases}
%         1 & n = k \\
%         0 & \text{otherwise}.
%     \end{cases}\]
%     Then, for all $k \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{e}_k \rVert_\infty = 1$. So, $(\bm{e}^{(k)})$ is bounded. However, it does not have a convergent subsequence- for all $k, m \in \mathbb{Z}_{\geq 1}$, if $k \neq m$, then 
%     \[\lVert \bm{e}^{(m)} - \bm{e}^{(k)} \rVert_\infty = 1.\]
%     In that case, any subsequence will not be Cauchy. This implies that $(T(\bm{e}^{(k)})) = (\bm{e}^{(k)})$ does not have a convergent subsequence. So, $T: V \to W$ is a bounded operator, but not compact.

%     \begin{proposition}
%         Let $V, W$ be Banach spaces, and let $(T_n)_{n=1}^\infty$ be a sequence of compact operators from $V$ to $W$, with $T_n \to T$. Then, $T$ is a compact operator.
%     \end{proposition}
%     \begin{proof}
%         Let $(\bm{v}_n)_{n=1}^\infty$ be a bounded sequence in $V$. Since $T_1$ is compact, we can find a subsequence $(\bm{v}_{1n})_{n=1}^\infty$ of $(\bm{v}_n)$ such that $(T_1(\bm{v}_{1n}))$ is convergent. Moreover, since $T_2$ is compact, we can find a subsequence $(\bm{v}_{2n})_{n=1}^\infty$ of $(\bm{v}_{1n})$ such that $(T_2(\bm{v}_{2n}))$ is convergent. Using this approach, we can inductively define the sequences $(\bm{v}_{kn})_{n=1}^\infty$ for all $k \in \mathbb{Z}_{\geq 1}$. 
        
%         \noindent Now, define the sequence $(\bm{x}_n)_{n=1}^\infty$ by $\bm{x}_n = \bm{v}_{nn}$. By definition, this is a subsequence of $(\bm{v}_n)$. Without loss of generality, assume that for all $n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{x}_n \rVert_V \leq 1$.\sidefootnote{We have to scale the vectors $(\bm{x}_n)$ so that the norm is always less than 1. Then, the original $(\bm{x}_n)$ is convergent if and only if the scaled $(\bm{x}_n)$ is convergent.} Next, we claim that $(T(\bm{x}_n))$ is Cauchy. So, let $\varepsilon > 0$. Since $T_n \to T$, we can find an $K \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq K$, then $\lVert T_n - T \rVert < \frac{\varepsilon}{3}$. In that case, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq K$, then $\lVert T_n(\bm{x}_n) - T(\bm{x}_n) \rVert_W < \frac{\varepsilon}{3}$ for all $n \in \mathbb{Z}_{\geq 1}$. By definition, $(\bm{x}_n)$ is a subsequence of $(\bm{v}_{Kn})$. We know that $(T_K(\bm{v}_{Kn}))$ is Cauchy, so $(T_K (\bm{x}_n))$ is also Cauchy. In that case, there exists an $N' \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N'$, then $\lVert T_K (\bm{x}_m) - T_K (\bm{x}_n) \rVert_W < \frac{\varepsilon}{3}$. Now, set $N = \max(K, N')$. Then, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then
%         \begin{align*}
%             \lVert T(\bm{x}_m) - T(\bm{x}_n) \rVert_W &\leq \lVert T(\bm{x}_n) - T_K(\bm{x}_n)\rVert_W + \lVert T_K(\bm{x}_n) - T_K(\bm{x}_m) \rVert_W \\
%             &+ \lVert T_K(\bm{x}_m) - T(\bm{x}_m) \rVert_W \\
%             &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon.
%         \end{align*}
%         This implies that $(T(\bm{x}_n))$ is Cauchy. Since $W$ is complete, $(T(\bm{x}_n))$ is convergent. So, $T$ is a compact operator.
%     \end{proof}

%     \newpage

%     \section{Hilbert Theory}
%     \begin{proposition}
%         Let $V$ be an inner product spaces and let $(\bm{v}_n)_{n=1}^\infty$ and $(\bm{w}_n)_{n=1}^\infty$ be sequences in $V$, with $\bm{v}_n \to \bm{v}$ and $\bm{w}_n \to \bm{w}$, for some $\bm{v}, \bm{w} \in W$. Then, $\langle \bm{v}_n, \bm{w}_n \rangle \to \langle \bm{v}, \bm{w} \rangle$.
%     \end{proposition}
%     \begin{proof}
%         We can find a $K_1 > 0$ such that $\lVert \bm{w} \rVert \leq K_1$. Since $\bm{v}_n \to \bm{v}$, the sequence $(\bm{v}_n)$ is bounded. So, there exists a $K_2 > 0$ such that for all $n \in \mathbb{Z}_{\geq 1}$, $\lVert \bm{x}_n \rVert \leq K_2$. 
        
%         \noindent Now, let $\varepsilon > 0$. Since $\bm{v}_n \to \bm{v}$, we can find an $N_1 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_1$, then $\lVert \bm{v} - \bm{v}_n \rVert < \frac{\varepsilon}{2K_1}$. Similarly, since $\bm{w}_n \to \bm{w}$, we can find an $N_2 \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N_2$, then $\lVert \bm{w} - \bm{w}_n \rVert < \frac{\varepsilon}{2K_2}$. Now, set $N = \max(N_1, N_2)$. In that case, for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then
%         \begin{align*}
%             |\langle \bm{v}, \bm{w} \rangle - \langle \bm{v}_n, \bm{w}_n \rangle| &= |\langle \bm{v}, \bm{w} \rangle - \langle \bm{v}_n, \bm{w} \rangle + \langle \bm{v}_n, \bm{w} \rangle - \langle \bm{v}_n, \bm{w}_n \rangle| \\
%             &= |\langle \bm{v} - \bm{v}_n, \bm{w} \rangle + \langle \bm{v}_n, \bm{w} - \bm{w}_n \rangle| \\
%             &\leq |\langle \bm{v} - \bm{v}_n, \bm{w} \rangle| + |\langle \bm{v}_n, \bm{w} - \bm{w}_n \rangle| \\
%             &\leq \lVert \bm{v} - \bm{v}_n \rVert \lVert \bm{w} \rVert + \lVert \bm{v}_n \rVert \lVert \bm{w} - \bm{w}_n \rVert \\
%             &< \frac{\varepsilon}{2K_1} \cdot K_1 + K_2 \cdot \frac{\varepsilon}{2K_2} = \varepsilon.
%         \end{align*}
%         This implies that $\langle \bm{v}_n, \bm{w}_n \rangle \to \langle \bm{v}, \bm{w} \rangle$.
%     \end{proof}

%     \begin{definition}
%         Let $V$ be an inner product space and let $E \subseteq V$ be a subspace. We define the \emph{orthogonal complement of $E$} by the set
%         \[E^\perp = \{\bm{v} \in V \mid \langle \bm{v}, \bm{w} \rangle = 0 \ \forall \bm{w} \in E\}.\]
%     \end{definition}
%     \noindent The set $E^\perp$ is always closed.
%     \begin{proposition}
%         Let $V$ be an inner product space and let $E \subseteq V$ be a subspace. Then, $E^\perp$ is closed.
%     \end{proposition}
%     \begin{proof}
%         Let $(\bm{v}_n)_{n=1}^\infty$ be a sequence in $E^\perp$ with $\bm{v}_n \to \bm{v}$, for some $\bm{v} \in V$. Let $\bm{w} \in E$. We know that for all $n \in \mathbb{Z}_{\geq 1}$, $\langle \bm{v}_n, \bm{w} \rangle = 0$. In that case,
%         \[\langle \bm{v}_n, \bm{w} \rangle \to 0.\]
%         Moreover, since $\bm{v}_n \to \bm{v}$, we know that $\langle \bm{v}_n, \bm{w} \rangle \to \langle \bm{v}, \bm{w} \rangle$. This implies that $\bm{v} \in E^\perp$. So, $E^\perp$ is closed.
%     \end{proof}

%     \begin{theorem}[Pythagoras' Theorem]
%         Let $V$ be an inner product space, and let $\bm{x}_1, \bm{x}_2, \dots , \bm{x}_n$ are vectors in $V$ that are mutually orthogonal. Then,
%         \[\left\lVert\sum_{k=1}^n \bm{x}_k \right\rVert^2 = \sum_{k=1}^n \lVert \bm{x}_k \rVert^2.\]
%     \end{theorem}
%     \begin{proof}
%         We find that
%         \begin{align*}
%             \left\lVert\sum_{k=1}^n \bm{x}_k \right\rVert^2 &= \left\langle \sum_{k=1}^n \bm{x}_k, \sum_{k=1}^n \bm{x}_k \right\rangle \\
%             &= \sum_{j=1}^n \sum_{k=1}^n \langle \bm{x}_j, \bm{x}_k \rangle \\
%             &= \sum_{k=1}^n \langle \bm{x}_k, \bm{x}_k \rangle \\
%             &= \sum_{k=1}^n \lVert \bm{x}_k \rVert^2.
%         \end{align*}
%     \end{proof}

%     \begin{proposition}
%         Let $V$ be a Hilbert space and let $H \subseteq V$ be a closed subspace. Then, for every $\bm{v} \in V$, there exists unique $\bm{x} \in H$ and $\bm{y} \in H^\perp$ such that $\bm{v} = \bm{x} + \bm{y}$.\sidefootnote{This is denoted by $V = H \oplus H^\perp$.}
%     \end{proposition}
%     \begin{proof}
%         Let
%         \[\delta = \inf_{\bm{x} \in H} \lVert \bm{v} - \bm{x} \rVert.\]
%         We know that there exists a sequence $(\bm{x}_n)_{n=1}^\infty$ in $H$ such that
%         \[\lVert \bm{v} - \bm{x}_n \rVert \to \delta.\]
%         We claim that $(\bm{x}_n)$ is Cauchy. Let $\varepsilon > 0$. Fix $K \geq 1$ such that $K \geq \frac{\delta}{\varepsilon} $. Since $\lVert \bm{v} - \bm{x}_n \rVert \to \delta$, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $n \in \mathbb{Z}_{\geq 1}$, if $n \geq N$, then 
%         \[\delta \leq \lVert \bm{v} - \bm{x}_n \rVert < \delta + \frac{\varepsilon}{16K}.\]
%         Now, let $m, n \in \mathbb{Z}_{\geq 1}$ with $m, n \geq N$. By the Parallelogram Law, we know that
%         \[\lVert \bm{x}_m - \bm{x}_n \rVert^2 = 2 \lVert \bm{x}_m - \bm{v} \rVert^2 + 2\lVert \bm{x}_n - \bm{v} \rVert^2 - 4 \lVert \tfrac{1}{2} (\bm{x}_m + \bm{x}_n) - \bm{x} \rVert^2.\]
%         Since $\bm{x}_m, \bm{x}_n \in H$, we find that $\frac{1}{2}(\bm{x}_m + \bm{x}_n) \in H$. Therefore,
%         \[\lVert \tfrac{1}{2} (\bm{x}_m + \bm{x}_n) - \bm{v} \rVert \geq \delta.\]
%         In that case,
%         \begin{align*}
%             \lVert \bm{x}_m - \bm{x}_n \rVert^2 &\leq  2 \lVert \bm{x}_m - \bm{v} \rVert^2 + 2\lVert \bm{x}_n - \bm{v} \rVert^2 - 4\delta^2 \\
%             &< 4 \left(\delta + \frac{\varepsilon}{16K}\right)^2 - 4\delta^2 \\
%             &= \frac{\delta \varepsilon}{2K} + \frac{1}{256K^2} \varepsilon^2 \\
%             &\leq \frac{1}{2} \varepsilon^2 + \frac{1}{256K^2} \varepsilon^2 \\
%             &= \left(\frac{1}{2} + \frac{1}{256K^2}\right) \varepsilon^2 \leq \varepsilon^2.
%         \end{align*}
%         So, for all $m, n \in \mathbb{Z}_{\geq 1}$, if $m, n \geq N$, then
%         \[\lVert \bm{x}_m - \bm{x}_n \rVert < \varepsilon.\]
%         This implies that $(\bm{x}_n)$ is Cauchy. Since $H \subseteq V$ is closed, we find that $H$ is complete. In that case, there exists an $\bm{x} \in H$ such that $\bm{x}_n \to \bm{x}$. Then, we have $\lVert \bm{v} - \bm{x} \rVert = \delta$.

%         \noindent Next, we show that the value $\bm{x} \in H$ is unique. So, let $\bm{z} \in H$ such that $\lVert \bm{v} - \bm{z} \rVert = \delta$. By the Parallelogram Law, we know that
%         \[\lVert \bm{x} - \bm{z} \rVert^2 = 2\lVert \bm{x} - \bm{v} \rVert^2 + 2\lVert \bm{z} - \bm{v} \rVert^2 - 4 \lVert \tfrac{1}{2}(\bm{x} + \bm{z}) - \bm{v} \rVert^2.\]
%         By construction, we have $\lVert \bm{x} - \bm{v} \rVert = \delta = \lVert \bm{v} - \bm{z} \rVert$. Moreover, since $\bm{x}, \bm{z} \in H$, we must find that
%         \[\lVert \bm{x} - \bm{z} \rVert^2 \leq 2\delta^2 + 2\delta^2 - 4\delta^2 = 0.\]
%         So, we have $\bm{x} = \bm{z}$.

%         \noindent Finally, set $\bm{y} = \bm{v} - \bm{x}$. We claim that $\bm{y} \in H^\perp$. So, let $\bm{w} \in H$. If $\bm{w} = \bm{0}$, then we know that $\langle \bm{w}, \bm{y} \rangle = 0$. Otherwise, we have $\bm{w} \neq \bm{0}$. In that case, define the function $f: \mathbb{R} \to \mathbb{R}$ by 
%         \[f(t) = \lVert \bm{y} + t \bm{w} \rVert^2 = \lVert \bm{y} \rVert^2 + 2t \langle \bm{w}, \bm{y} \rangle + t^2 \lVert \bm{w} \rVert^2.\]
%         Also,
%         \[f(t) = \lVert \bm{y} + t\bm{w} \rVert^2 = \lVert \bm{v} - (\bm{x} - t\bm{w}) \rVert^2 .\]
%         For $t \in \mathbb{R}$, we have $\bm{x}, \bm{w} \in H$, so $\bm{x} - t\bm{w} \in H$ as well. So, $f(t) \geq \delta^2$. Moreover, we saw that only $\bm{x} \in H$ satisfies $\lVert \bm{x} - \bm{v} \rVert = \delta$. So, we have $f(0) = \delta^2$, and $f(t) > \delta^2$ for $t \in \mathbb{R}^\times$. This implies that $f'(0) = 0$. We have
%         \[f'(t) = 2 \langle \bm{w}, \bm{y} \rangle + 2t \lVert \bm{w} \rVert.\]
%         So,
%         \[f'(0) = 2\langle \bm{w}, \bm{y} \rangle = 0.\]
%         This implies that $\langle \bm{w}, \bm{y} \rangle = 0$. In that case, $\bm{y} \in H^\perp$. By the uniqueness of $\bm{x}$, we find that $\bm{y} \in H^\perp$ is unique.
%     \end{proof}

%     \subsection{Linear functionals}
    
%     \begin{proposition}
%         Let $V$ be an inner product space, and let $\bm{v} \in V$. Then, the function $f_{\bm{v}}: V \to \mathbb{R}$ given by $f_{\bm{v}}(\bm{w}) = \langle \bm{w}, \bm{v} \rangle$ is a linear functional.
%     \end{proposition}
%     \begin{proof}
%         We know that for $\bm{w}_1, \bm{w}_2 \in V$,
%         \[f_{\bm{v}}(\bm{w}_1 + \bm{w}_2) = \langle \bm{w}_1 + \bm{w}_2, \bm{v} \rangle = \langle \bm{w}_1, \bm{v} \rangle + \langle \bm{w}_2, \bm{v} \rangle = f_{\bm{v}}(\bm{w}_1) + f_{\bm{v}}(\bm{w}_2).\]
%         Moreover, for $\bm{w} \in V$ and $\lambda \in \mathbb{R}$,
%         \[f_{\bm{v}}(\lambda \bm{w}) = \langle \lambda \bm{w}, \bm{v} \rangle = \lambda \langle \bm{w}, \bm{v} \rangle = \lambda f_{\bm{v}}(\bm{w}).\]
%         So, $f$ is a linear map. Furthermore, for $\bm{w} \in V$,
%         \[f_{\bm{v}}(\bm{w}) = \langle \bm{v}, \bm{w} \rangle \leq \lVert \bm{v} \rVert \lVert \bm{w} \rVert.\]
%         In that case, $f$ is a linear functional, with $\lVert f_{\bm{v}} \rVert \leq \lVert \bm{v} \rVert$.
%     \end{proof}

%     \begin{proposition}
%         Let $V$ be a Hilbert space, and let $f: V \to \mathbb{R}$ be a linear functional. Then, there exists a unique $\bm{v} \in V$ such that for all $\bm{w} \in V$, $f(\bm{w}) = \langle \bm{w}, \bm{v} \rangle$.
%     \end{proposition}
%     \begin{proof}
%         If $f$ is the trivial map, then we know that for all $\bm{w} \in V$,
%         \[f(\bm{w}) = 0 = \langle \bm{w}, \bm{0} \rangle.\]

%         \noindent Now, assume that $f$ is a non-trivial map. Since $f$ is bounded, we find that
%         \[\ker (f) = f^{-1}(0)\]
%         is a closed subspace. Moreover, since $V \setminus \ker (f)$ is non-empty, there exists a $\bm{z} \in \ker (f)^\perp$ such that $\lVert \bm{z} \rVert = 1$.\sidefootnote{There exists a $\bm{v} \in V \setminus \ker (f)$. So, $\bm{v} = \bm{x} + \bm{y}$ for $\bm{x} \in \ker (f)$ and $\bm{y} \in \ker (f)^\perp$. Then, we must have $\bm{y} \neq \bm{0}$, so we can normalise $\bm{y}$ to get $\bm{z}$.} Now, let $\bm{v} \in V$. Define
%         \[\bm{u} = f(\bm{v}) \bm{z} - \bm{v} f(\bm{z}).\]
%         We have
%         \[f(\bm{u}) = f(\bm{v}) f(\bm{z}) - f(\bm{v}) f(\bm{z}) = 0,\]
%         so $\bm{u} \in \ker (f)$. This implies that $\langle \bm{z}, \bm{u} \rangle = 0$. In that case,
%         \[f(\bm{z}) \langle \bm{v}, \bm{z} \rangle = f(\bm{v})\langle \bm{z}, \bm{z} \rangle = f(\bm{v}).\]
%         So, for all $\bm{v} \in V$, 
%         \[f(\bm{v}) =  \langle \bm{v}, f(\bm{z}) \bm{z} \rangle.\]

%         \noindent Now, we show that the value $\bm{v} \in V$ is unique. So, assume that there exist $\bm{x}, \bm{y} \in V$ such that for all $\bm{w} \in V$, 
%         \[\langle \bm{x}, \bm{w} \rangle = \langle \bm{y}, \bm{w} \rangle.\]
%         In that case, $\langle \bm{x} - \bm{y}, \bm{w}\rangle = 0$ for all $\bm{w} \in V$. In particular, 
%         \[\lVert \bm{x} - \bm{y} \rVert^2 = \langle \bm{x} - \bm{y}, \bm{x} - \bm{y} \rangle = 0.\]
%         Therefore, $\bm{x} = \bm{y}$. So, the value $\bm{v} \in V$ is unique.
%     \end{proof}

%     \subsection{Linear algebra}
%     \begin{definition}
%         Let $V$ be an inner product space. Then, a subset $E \subseteq V$ is an \emph{orthogonal set} if $\bm{0} \not\in E$ and for all $\bm{u}, \bm{v} \in V$, if $\bm{u} \neq \bm{v}$, then $\langle \bm{u}, \bm{v} \rangle = 0$.
%     \end{definition}
    
%     \begin{definition}
%         Let $V$ be an inner product space. Then, a subset $E \subseteq V$ is an \emph{orthonormal set} if $\bm{0} \not\in E$ and for all $\bm{u}, \bm{v} \in V$, if $\bm{u} \neq \bm{v}$, then $\langle \bm{u}, \bm{v} \rangle = 0$, and if $\bm{u} = \bm{v}$, then $\langle \bm{u}, \bm{v} \rangle = 1$.
%     \end{definition}

%     \begin{lemma}
%         Let $V$ be an inner product space and let $E \subseteq V$ be an orthogonal set. Then, $E$ is linearly independent.
%     \end{lemma}
%     \begin{proof}
%         Let
%         \[c_1 \bm{x}_1 + c_2 \bm{x}_2 + \dots + c_n \bm{x}_n = \bm{0},\]
%         for $c_1, c_2, \dots, c_n \in \mathbb{R}$ and $\bm{x}_1, \bm{x}_2, \dots, \bm{x}_n \in E$. We find that for all $i \in \{1, 2, \dots, n\}$,
%         \[c_i \lVert \bm{x}_i \rVert^2 = c_i \langle \bm{x}_i, \bm{x}_i \rangle = \sum_{j=1}^n c_j \langle \bm{x}_i, \bm{x}_j \rangle = \left\langle \bm{x}_i, \sum_{j=1}^n c_j \bm{x}_j \right\rangle = \langle \bm{x}_i, \bm{0} \rangle = 0.\]
%         Since $\bm{x}_i \neq \bm{0}$, we must have $c_i = 0$. So, $E$ is linearly independent.
%     \end{proof}

%     We can use the Gram-Schmidt process to convert a (countable) collection of linearly independent vectors into an orthonormal set of vectors with the same span. Let $V$ be an inner product space, and let
%     \[E = \{\bm{x}_1, \bm{x}_2, \dots\} \subseteq V\]
%     be a linearly independent set. We will construct the set 
%     \[F = \{\bm{y}_1, \bm{y}_2, \dots\} \subseteq V\]
%     of orthonormal sets such that $\operatorname{span} (E) = \operatorname{span} (F)$. For $n \in \mathbb{Z}_{\geq 1}$, we define
%     \[\bm{y}_n' = \bm{x}_n - \sum_{k=1}^n \langle \bm{x}_n, \bm{y}_k \rangle \bm{y}_k,\]
%     and $\bm{y}_n$ is the normalised vector of $\bm{y}_n'$.
%     % TODO: Show orthonormal
%     % The resulting set is an orthonormal set of vectors- let $m \in \mathbb{Z}_{\geq 2}$. For $n \in \{1, 2, \dots, m-1\}$, we show that $\langle \bm{y}_m', \bm{y}_n\rangle = 0$ by induction. We have
%     % \[\]

%     % The resulting set is an orthonormal set of vectors, since we remove any projections that a vector $\bm{x}_n$ has to $\bm{x}_i$ for $i \in \{1, 2, \dots, n\}$ and then normalise it.
%     It also has the same span since there is a bijection from the linearly independent set and the orthonormal set, and we can write all the $\bm{x}_n$ vectors as a linear combination of $\bm{y}_i$, for $i \in \{1, 2, \dots, n\}$.
    
%     We illustrate the Gram-Schmidt process in $\mathbb{R}^3$. Consider the set
%     \[\{(1, 0, 0), (0, 1, 1), (1, 0, 1)\}.\]
%     This is a linearly independent set, but not orthonormal. To construct the set of orthonormal vectors, we first set $\bm{y}_1' = \bm{x}_1$. Since $\bm{y}_1'$ is a unit vector, we set $\bm{y}_1 = \bm{x}_1$. Now, we set
%     \[\bm{y}_2' = (0, 1, 1) - \langle (1, 0, 0), (0, 1, 1) \rangle (1, 0, 0) = (0, 1, 1).\]
%     Therefore, we normalise $\bm{y}_2'$ to get:
%     \[\bm{y}_2 = \frac{1}{\lVert (0, 1, 1) \rVert_2} (0, 1, 1) = \frac{1}{\sqrt{2}} (0, 1, 1).\]
%     Next, we set
%     \begin{align*}
%         \bm{y}_3' &= (1, 0, 1) - \langle (1, 0, 0), (1, 0, 1) \rangle (1, 0, 0) - \frac{1}{2} \langle (0, 1, 1), (1, 0, 1) \rangle (0, 1, 1) \\
%         &= \frac{1}{2} (0, -1, 1).
%     \end{align*}
%     Finally, we normalise $\bm{y}_3'$ to get:
%     \[\bm{y}_3 = \frac{1}{\lVert (0, -1, 1) \rVert_2} (0, -1, 1) = \frac{1}{\sqrt{2}} (0, -1, 1).\]
%     Then, the set
%     \[\{\bm{y}_1, \bm{y}_2, \bm{y}_3\}\]
%     has equal span and is orthonormal.

%     \begin{proposition}[Bessel's Inequality]
%         Let $V$ be a Hilbert space and let $(\bm{x}_\alpha)_{\alpha \in A}$ be an orthonormal collection in $V$, for some indexing set $A$. Then, for all $\bm{v} \in V$,
%         \[\sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%         In particular, the set of $\alpha$ such that $\langle \bm{v}, \bm{x}_\alpha \rangle \neq 0$ is countable.
%     \end{proposition}
%     \begin{proof}
%         Let $F \subseteq A$ be finite. Then, for all $\bm{v} \in V$,
%         \begin{align*}
%             0 &\leq \left\lVert \bm{v} - \sum_{\alpha \in F} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \right\rVert^2 \\
%             &= \lVert \bm{v} \rVert^2 - 2 \sum_{\alpha \in F} \langle \bm{v}, \bm{x}_\alpha \rangle \cdot \langle \bm{v}, \bm{x}_\alpha \rangle + \sum_{\alpha \in F} \sum_{\beta \in F} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \cdot |\langle \bm{v}_\alpha, \bm{x}_\beta \rangle|^2 \\
%             &= \lVert \bm{v} \rVert^2 - 2 \sum_{\alpha \in F} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 + \sum_{\alpha \in F} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \\
%             &= \lVert \bm{v} \rVert^2 - \sum_{\alpha \in F} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2.
%         \end{align*}
%         Therefore,
%         \[\sum_{\alpha \in F} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%         Now, let
%         \[A^\times = \{\alpha \in A \mid \langle \bm{v}, \bm{x}_\alpha \rangle \neq 0\},\]
%         and for $n \in \mathbb{Z}_{\geq 1}$, let
%         \[A_n = \{\alpha \in A \mid \langle \bm{v}, \bm{x}_\alpha \rangle > 1/n\}.\]
%         We claim that $|A_n| \leq n^2 \lVert \bm{y} \rVert^2$. Assume, for a contradiction, that $|A_n| > n^2 \lVert \bm{y} \rVert^2$. In that case, for a finite subset $A_n' \subseteq A_n$ with $|A_n'| > n^2 \lVert \bm{y} \rVert^2$,
%         \[\sum_{\alpha \in A_n'} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 > \sum_{\alpha \in A_n} \frac{1}{n^2} \geq \frac{1}{n^2} \cdot n^2 \lVert \bm{y} \rVert^2 = \lVert \bm{y} \rVert^2.\]
%         This is a contradiction. So, we must have that $A_n$ is finite. Therefore, the countable union
%         \[A = \bigcup_{n=1}^\infty A_n\]
%         is also countable.

%         \noindent Finally, enumerate
%         \[A = \{\bm{x}_1, \bm{x}_2, \dots\}.\]
%         We have shown that for all $n \in \mathbb{Z}_{\geq 1}$,
%         \[\sum_{\alpha=1}^n |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%         Therefore,
%         \[\sum_{\alpha=1}^\infty |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%         This implies that
%         \[\sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 = \sum_{\alpha=1}^\infty |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%     \end{proof}

%     \begin{proposition}
%         Let $V$ be a Hilbert space and let $(\bm{x}_\alpha)_{\alpha \in A}$ be an orthonormal collection in $V$, for some indexing set $A$. Then, the following are equivalent:
%         \begin{enumerate}
%             \item for all $\bm{v} \in V$, if $\langle \bm{v}, \bm{x}_\alpha \rangle = 0$ for all $\alpha \in A$, then $\bm{v} = \bm{0}$;
%             \item for all $\bm{v} \in V$,
%             \[\lVert \bm{v} \rVert^2 = \sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2;\]
%             \item for all $\bm{v} \in V$,
%             \[\bm{v} = \sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha.\]
%         \end{enumerate}
%         If the collection $(\bm{x}_\alpha)$ satisfies any of the conditions above, then we say that it forms an \emph{orthonormal basis for $V$}.
%     \end{proposition}
%     \begin{proof}
%         We show $(1) \implies (3) \implies (2) \implies (1)$.
%         \begin{itemize}            
%             \item Assume that for all $\bm{v} \in V$, if $\langle \bm{v}, \bm{x}_\alpha \rangle = 0$ for all $\alpha \in A$, then $\bm{v} = \bm{0}$. Let $\bm{v} \in V$. By Bessel's inequality, we know that
%             \[\sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \leq \lVert \bm{v} \rVert^2.\]
%             So, the series 
%             \[\sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2\]
%             is Cauchy. Moreover, we know that the set of $\alpha \in A$ such that $\langle \bm{v}, \bm{x}_\alpha \rangle \neq 0$ is countable. So, let $(\bm{x}_\alpha)_{\alpha=1}^\infty$ be a collection of such values. Now, let $\varepsilon > 0$. Since the series is Cauchy, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
%             \[\sum_{\alpha=n+1}^m |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 = \left|\sum_{\alpha=1}^m |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 - \sum_{\alpha=1}^n |\langle \bm{v}, \bm{x}_\alpha \rangle|^2\right| < \varepsilon^2.\]
%             By Pythagoras' Theorem, we know that for $m, n \in \mathbb{Z}$ with $m \geq n$,
%             \[\left\lVert\sum_{\alpha=n+1}^m \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \right\rVert^2 = \sum_{\alpha=n+1}^m \lVert \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \rVert^2 = \sum_{\alpha=n+1}^m |\langle \bm{v}, \bm{x}_\alpha \rangle|^2.\]
%             Therefore, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
%             \begin{align*}
%                 \left\lVert \sum_{\alpha=1}^m \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha - \sum_{\alpha=1}^n \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \right\rVert &= \left\lVert\sum_{\alpha=n+1}^m \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \right\rVert \\
%                 &= \sqrt{\sum_{\alpha=n+1}^m |\langle \bm{v}, \bm{x}_\alpha \rangle|^2} < \varepsilon.
%             \end{align*}
%             This implies that the series 
%             \[\sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha \sum_{\alpha=1}^\infty \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha\]
%             converges. Now, let
%             \[\bm{z} = \bm{v} - \sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha.\]
%             We find that for all $\beta \in A$,
%             \begin{align*}
%                 \langle \bm{z}, \bm{x}_\beta \rangle &= \langle \bm{v}, \bm{x}_\beta \rangle - \sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \cdot \langle \bm{x}_\alpha, \bm{x}_\beta \rangle \\
%                 &= \langle \bm{v}, \bm{x}_\beta \rangle - \langle \bm{v}, \bm{x}_\beta \rangle = 0.
%             \end{align*}
%             This implies that $\bm{z} = 0$. So, we find that
%             \[\bm{v} = \sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha.\]
            
%             \item Assume that for all $\bm{v} \in V$,
%             \[\bm{v} = \sum_{\alpha \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \bm{x}_\alpha.\]
%             In that case, for all $\bm{v} \in V$,
%             \begin{align*}
%                 \lVert \bm{v} \rVert^2 &= \langle \bm{v}, \bm{v} \rangle \\
%                 &= \sum_{\alpha \in A} \sum_{\beta \in A} \langle \bm{v}, \bm{x}_\alpha \rangle \cdot \langle \bm{v}, \bm{x}_\beta \rangle \cdot |\langle \bm{x}_\alpha, \bm{x}_\beta \rangle|^2 \\
%                 &= \sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 \cdot |\langle \bm{x}_\alpha, \bm{x}_\alpha \rangle|^2 \\
%                 &= \sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2.
%             \end{align*}
            
%             \item Assume that for all $\bm{v} \in V$,
%             \[\lVert \bm{v} \rVert^2 = \sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2.\]
%             Now, fix $\bm{v} \in V$ such that $\langle \bm{v}, \bm{x}_\alpha \rangle = 0$ for all $\alpha \in A$. Then,
%             \[\lVert \bm{v} \rVert^2 = \sum_{\alpha \in A} |\langle \bm{v}, \bm{x}_\alpha \rangle|^2 = \sum_{\alpha \in A} 0 = 0.\]
%             This implies that $\bm{v} = \bm{0}$.
%         \end{itemize}
%     \end{proof}

%     \begin{proposition}
%         Let $V$ be a Hilbert space. Then, it is separable if and only if it has a countable orthonormal basis. Moreover, if $V$ has a countable orthonormal basis, then any orthonormal basis of $V$ is countable.
%     \end{proposition}
%     \begin{proof}
%         % TODO
%     \end{proof}
    
%     \subsection{Unitary operators}
%     \begin{definition}
%         Let $V$ and $W$ be inner product spaces, and let $T: V \to W$ be a linear operator. Then, $T$ is \emph{unitary} if it is surjective and for all $\bm{u}, \bm{v} \in V$,
%         \[\langle \bm{u}, \bm{v} \rangle_V = \langle T(\bm{u}), T(\bm{v}) \rangle_W.\]
%     \end{definition}

%     \begin{proposition}
%         Let $V$ and $W$ be inner product spaces, and let $T: V \to W$ be a linear operator. Then, $T$ is unitary if and only if $T$ is a surjective isometry.
%     \end{proposition}
%     \begin{proof}
%         \hspace*{0pt}
%         \begin{itemize}
%             \item Assume that $T$ is unitary. In that case, for all $\bm{v} \in V$,
%             \[\lVert T(\bm{v}) \rVert^2 = \langle T(\bm{v}), T(\bm{v}) \rangle = \langle \bm{v}, \bm{v} \rangle = \lVert \bm{v} \rVert^2.\]
%             So, $\lVert T(\bm{v}) \rVert = \lVert \bm{v} \rVert$. This implies that $T$ is a (surjective) isometry.

%             \item Assume that $T$ is a surjective isometry. Let $\bm{u}, \bm{v} \in V$. We find that
%             \begin{align*}
%                 \langle T(\bm{u}), T(\bm{v}) \rangle &= \frac{1}{4} \lVert T(\bm{u}) + T(\bm{v}) \rVert^2 - \frac{1}{4} \lVert T(\bm{u}) - T(\bm{v}) \rVert^2 \\
%                 &= \frac{1}{4} \lVert \bm{u} + \bm{v} \rVert^2 - \frac{1}{4} \lVert \bm{u} - \bm{v} \rVert^2 \\
%                 &= \langle \bm{u}, \bm{v} \rangle.
%             \end{align*}
%             Therefore, $T$ is unitary.
%         \end{itemize}
%     \end{proof}

%     \begin{proposition}
%         Let $V$ be a separable Hilbert space, with a countable orthonormal basis $(\bm{x}_k)_{k=1}^\infty$. For each $\bm{v} \in V$, define the sequence $(v_k)_{k=1}^\infty$ in $\mathbb{R}$ by $v_k = \langle \bm{v}, \bm{x}_k \rangle$, and define the function $f: V \to \ell^2$ by $f(\bm{v}) = (\bm{v}_k)$. Then, $f$ is a unitary map.
%     \end{proposition}
%     \begin{proof}
%         Since $(\bm{x}_k)$ forms an orthonormal basis, we know that
%         \[\lVert (\bm{v}_k) \rVert_2^2 = \sum_{k=1}^\infty |\langle \bm{v}, \bm{x}_k \rangle|^2 = \lVert \bm{v} \rVert_V^2.\]
%         This implies that $(\bm{v}_k)$ is in $\ell^2$- the function $f$ is well-defined. Moreover, it is an isometry.
        
%         \noindent Next, we show that $f$ is linear. Let $\bm{v}_1, \bm{v}_2 \in V$. We find that for all $k \in \mathbb{Z}_{\geq 1}$,
%         \[f(\bm{v}_1 + \bm{v}_2)_k = \langle \bm{v}_1, \bm{v}_2, \bm{x}_k \rangle = \langle \bm{v}_1, \bm{x}_k \rangle + \langle \bm{v}_2, \bm{x}_k \rangle = f(\bm{v}_1)_k + f(\bm{v}_2)_k.\]
%         So, $f(\bm{v}_1 + \bm{v}_2) = f(\bm{v}_1) + f(\bm{v}_2)$. Now, let $\bm{v} \in V$ and $\lambda \in \mathbb{R}$. We find that for all $k \in \mathbb{Z}_{\geq 1}$,
%         \[f(\lambda \bm{v})_k = \langle \lambda \bm{v}, \bm{x}_k \rangle = \lambda \langle \bm{v}, \bm{x}_k \rangle = \lambda f(\bm{v})_k.\]
%         So, $f(\lambda \bm{v}) = \lambda f(\bm{v})$. This implies that $f$ is linear.

%         \noindent Finally, we show that $f$ is surjective. Let $(x_n)_{n=1}^\infty$ be a sequence in $\ell^2$. Consider the series
%         \[\sum_{n=1}^\infty a_n \bm{x}_n.\]
%         We claim that the series is Cauchy. Since $(x_n)_{n=1}^\infty$ is in $\ell^2$, we can find an $N \in \mathbb{Z}_{\geq 1}$ such that for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
%         \[\sum_{k=n+1}^m |a_k|^2 = \left| \sum_{k=1}^m |a_k|^2 - \sum_{k=1}^n |a_k|^2 \right| < \varepsilon.\]
%         Since $(\bm{x}_n)$ is an orthonormal collection, Pythagoras' Theorem tells us that for $m, n \in \mathbb{Z}_{\geq 1}$ with $m \geq n$,
%         \[\left\lVert \sum_{k=n+1}^m a_k \bm{x}_k \right\rVert^2 = \sum_{k=n+1}^m \lVert a_k \bm{x}_k \rVert^2 = \sum_{k=n+1}^m |a_k|^2.\]
%         In that case, for $m, n \in \mathbb{Z}_{\geq 1}$, if $m \geq n \geq N$, then
%         \[\left|\sum_{k=1}^m \lVert a_k \bm{x}_k \rVert^2 - \sum_{k=1}^n \lVert a_k \bm{x}_k \rVert^2 \right| = \sum_{k=n+1}^m |a_k|^2 < \varepsilon.\]
%         Therefore, the series is Cauchy. Since $V$ is complete, we can find a $\bm{v} \in V$ such that 
%         \[\sum_{n=1}^\infty a_n \bm{x}_n = \bm{v}.\]
%         In that case, for all $n \in \mathbb{Z}_{\geq 1}$,
%         \[f(\bm{v})_k = \langle \bm{v}, \bm{x}_k  \rangle = \sum_{n=1}^\infty a_n \langle \bm{x}_n, \bm{x}_k \rangle  = a_k \langle \bm{x}_k, \bm{x}_k \rangle = a_k.\]
%         This implies that $f(\bm{v}) = (\bm{x}_n)$. So, $f$ is a surjective isometry- $f$ is unitary.
%     \end{proof}
    
%     % TODO: Spectral Theorem
% \end{document}